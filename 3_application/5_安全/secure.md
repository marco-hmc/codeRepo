# 断路器

断路器是一种设计模式，用于检测故障并封装防止在维护、临时外部系统故障或意外系统困难期间不断重复故障的逻辑。

![circuit-breaker](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/circuit-breaker/circuit-breaker.png)

断路器的基本思想非常简单。我们将受保护的函数调用包装在一个断路器对象中，该对象监视故障。一旦故障达到一定阈值，断路器就会跳闸，所有进一步的对断路器的调用都会返回错误，而不会进行受保护的调用。通常，我们还希望在断路器跳闸时有某种监控警报。

## 为什么我们需要断路器？

软件系统通常会通过网络对运行在不同进程中的软件进行远程调用。内存调用和远程调用之间的一个大区别是，远程调用可能会失败，或者在达到某个超时限制之前挂起而没有响应。更糟糕的是，如果我们有许多调用者在一个无响应的供应商上，那么我们可能会耗尽关键资源，导致多个系统之间的级联故障。

## 状态

让我们讨论断路器的状态：

### 关闭

当一切正常时，断路器保持关闭状态，所有请求正常通过服务。如果故障次数超过阈值，断路器就会跳闸并进入打开状态。

### 打开

在这种状态下，断路器立即返回错误，甚至不调用服务。断路器在经过一定的超时时间后进入半开状态。通常，它会有一个监控系统，其中指定了超时时间。

### 半开

在这种状态下，断路器允许服务通过有限数量的请求并调用操作。如果请求成功，则断路器将进入关闭状态。然而，如果请求继续失败，则它会回到打开状态。

# 速率限制

速率限制是指防止操作频率超过定义的限制。在大规模系统中，速率限制通常用于保护底层服务和资源。速率限制通常用作分布式系统中的防御机制，以便共享资源能够保持可用性。它还通过限制在给定时间内可以到达我们的 API 的请求数量来保护我们的 API 免受意外或恶意的过度使用。

![rate-limiting](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/rate-limiting/rate-limiting.png)

## 为什么我们需要速率限制？

速率限制是任何大规模系统的重要组成部分，它可以用于实现以下目标：

- 避免因拒绝服务 (DoS) 攻击导致的资源枯竭。
- 通过对资源的自动扩展设置虚拟上限来控制运营成本，如果不加监控，可能会导致指数级的账单。
- 速率限制可以用作防御或缓解一些常见攻击的手段。
- 对于处理大量数据的 API，速率限制可以用来控制数据流量。

## 算法

有多种 API 速率限制算法，每种算法都有其优点和缺点。让我们简要讨论一些这些算法：

### 漏桶算法

漏桶算法通过队列提供一种简单直观的速率限制方法。当注册请求时，系统将其附加到队列的末尾。队列中的第一个项目按固定间隔或先进先出 (FIFO) 进行处理。如果队列已满，则丢弃（或泄漏）额外的请求。

### 令牌桶算法

这里我们使用一个“桶”的概念。当请求到来时，必须从桶中取出一个令牌并进行处理。如果桶中没有令牌，请求将被拒绝，请求者必须稍后再试。因此，令牌桶在一定时间后会刷新。

### 固定窗口算法

系统使用一个 [`n`](command:_github.copilot.openSymbolFromReferences?%5B%22%22%2C%5B%7B%22uri%22%3A%7B%22scheme%22%3A%22file%22%2C%22authority%22%3A%22%22%2C%22path%22%3A%22%2Fhome%2Fmarco%2FgitRepo%2FcodeRepo%2F3_application%2F5_%E5%AE%89%E5%85%A8%2Fsecure.md%22%2C%22query%22%3A%22%22%2C%22fragment%22%3A%22%22%7D%2C%22pos%22%3A%7B%22line%22%3A57%2C%22character%22%3A34%7D%7D%5D%2C%22e30d53fd-702d-4644-8de6-a804eec273a0%22%5D "Go to definition") 秒的窗口大小来跟踪固定窗口算法的速率。每个传入请求都会增加窗口的计数器。如果计数器超过阈值，则丢弃请求。

### 滑动日志算法

滑动日志速率限制涉及跟踪每个请求的时间戳日志。系统将这些日志存储在时间排序的哈希集或表中。它还会丢弃超过阈值时间戳的日志。当新请求到来时，我们计算日志的总和以确定请求速率。如果请求超过阈值速率，则将其保持。

### 滑动窗口算法

滑动窗口是一种混合方法，结合了固定窗口算法的低处理成本和滑动日志的改进边界条件。与固定窗口算法类似，我们为每个固定窗口跟踪一个计数器。接下来，我们根据当前时间戳计算前一个窗口请求速率的加权值，以平滑流量突发。

## 分布式系统中的速率限制

当涉及分布式系统时，速率限制变得复杂。分布式系统中的速率限制有两个主要问题：

### 不一致性

当使用多个节点的集群时，我们可能需要实施全局速率限制策略。因为如果每个节点都跟踪其速率限制，消费者在向不同节点发送请求时可能会超过全局速率限制。节点数量越多，用户越有可能超过全局限制。

解决此问题的最简单方法是使用负载均衡器中的粘性会话，以便每个消费者都被发送到一个节点，但这会导致缺乏容错和扩展问题。另一种方法可能是使用集中式数据存储，如 [Redis](https://redis.io)，但这会增加延迟并导致竞争条件。

### 竞争条件

当我们使用一种简单的“获取-然后-设置”方法时，会发生这个问题，其中我们检索当前的速率限制计数器，递增它，然后将其推回数据存储。这个模型的问题是，在执行完整的读取-递增-存储周期的时间内，可能会有额外的请求通过，每个请求都试图存储带有无效（较低）计数器值的递增计数器。这允许消费者发送大量请求以绕过速率限制控制。

避免此问题的一种方法是使用某种分布式锁定机制围绕键，防止任何其他进程访问或写入计数器。尽管锁定会成为一个显著的瓶颈，并且扩展性不佳。更好的方法可能是使用“设置-然后-获取”方法，允许我们快速递增和检查计数器值，而不会让原子操作妨碍。

# 服务发现

服务发现是计算机网络中服务的检测。服务发现协议 (SDP) 是一种通过识别资源来实现网络检测的网络标准。

## 为什么我们需要服务发现？

在单体应用程序中，服务通过语言级方法或过程调用相互调用。然而，现代基于微服务的应用程序通常运行在虚拟化或容器化环境中，其中服务实例的数量及其位置动态变化。因此，我们需要一种机制，使服务的客户端能够向动态变化的一组临时服务实例发出请求。

## 实现

有两种主要的服务发现模式：

### 客户端发现

![client-side-service-discovery](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/service-discovery/client-side-service-discovery.png)

在这种方法中，客户端通过查询服务注册表来获取另一个服务的位置，服务注册表负责管理和存储所有服务的网络位置。

### 服务器端发现

![server-side-service-discovery](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/service-discovery/server-side-service-discovery.png)

在这种方法中，我们使用一个中间组件，如负载均衡器。客户端通过负载均衡器向服务发出请求，然后负载均衡器将请求转发给可用的服务实例。

## 服务注册表

服务注册表基本上是一个包含服务实例网络位置的数据库，客户端可以联系这些实例。服务注册表必须高度可用并保持最新。

## 服务注册

我们还需要一种获取服务信息的方法，通常称为服务注册。让我们看看两种可能的服务注册方法：

### 自注册

使用自注册模型时，服务实例负责在服务注册表中注册和注销自己。此外，如果需要，服务实例会发送心跳请求以保持其注册状态。

### 第三方注册

注册表通过轮询部署环境或订阅事件来跟踪运行实例的变化。当它检测到新可用的服务实例时，会将其记录在数据库中。服务注册表还会注销已终止的服务实例。

## 服务网格

服务到服务的通信在分布式应用程序中至关重要，但随着服务数量的增加，跨应用程序集群路由这种通信变得越来越复杂。服务网格使得各个服务之间的通信可管理、可观察和安全。它与服务发现协议一起工作以检测服务。[Istio](https://istio.io/latest/about/service-mesh) 和 [envoy](https://www.envoyproxy.io) 是一些最常用的服务网格技术。

## 示例

以下是一些常用的服务发现基础设施工具：

- [etcd](https://etcd.io)
- [Consul](https://www.consul.io)
- [Apache Thrift](https://thrift.apache.org)
- [Apache Zookeeper](https://zookeeper.apache.org)

# 灾难恢复

灾难恢复 (DR) 是在自然灾害、网络攻击或业务中断等事件后恢复基础设施访问和功能的过程。

灾难恢复依赖于在不受灾害影响的异地位置复制数据和计算处理。当服务器因灾难而宕机时，企业需要从备份数据的第二位置恢复丢失的数据。理想情况下，组织还可以将其计算处理转移到该远程位置，以继续运营。

_灾难恢复在系统设计面试中通常不会被积极讨论，但了解这一主题的一些基本知识很重要。你可以从 [AWS Well-Architected Framework](https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/plan-for-disaster-recovery-dr.html) 中了解更多关于灾难恢复的信息。_

## 为什么灾难恢复很重要？

灾难恢复可以带来以下好处：

- 最小化中断和停机时间
- 限制损害
- 快速恢复
- 更好的客户保留

## 术语

让我们讨论一些与灾难恢复相关的重要术语：

![disaster-recovery](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/disaster-recovery/disaster-recovery.png)

### 恢复时间目标 (RTO)

恢复时间目标 (RTO) 是服务中断和服务恢复之间的最大可接受延迟。这决定了服务不可用时的可接受时间窗口。

### 恢复点目标 (RPO)

恢复点目标 (RPO) 是自上次数据恢复点以来的最大可接受时间量。这决定了从上次恢复点到服务中断之间的可接受数据丢失量。

## 策略

灾难恢复 (DR) 策略可以成为灾难恢复计划的一部分。

### 备份

这是最简单的灾难恢复类型，涉及将数据存储在异地或可移动驱动器上。

### 冷站点

在这种类型的灾难恢复中，组织在第二个站点设置基本基础设施。

### 热站点

热站点始终保持最新的数据副本。热站点的设置耗时且比冷站点更昂贵，但它们显著减少了停机时间。

# 虚拟机 (VM) 和容器

在讨论虚拟化与容器化之前，让我们了解什么是虚拟机 (VM) 和容器。

## 虚拟机 (VM)

虚拟机 (VM) 是一个虚拟环境，具有自己的 CPU、内存、网络接口和存储，作为虚拟计算机系统运行在物理硬件系统上。称为虚拟机监控程序 (hypervisor) 的软件将机器的资源与硬件分离，并适当地分配它们，以便虚拟机可以使用这些资源。

虚拟机与系统的其他部分隔离，可以在单个硬件上存在多个虚拟机，如服务器。它们可以根据需求在主机服务器之间移动，以更有效地使用资源。

### 什么是虚拟机监控程序？

虚拟机监控程序 (hypervisor) 有时称为虚拟机监视器 (VMM)，将操作系统和资源与虚拟机隔离，并启用这些虚拟机的创建和管理。虚拟机监控程序将 CPU、内存和存储等资源视为资源池，可以在现有客户机或新虚拟机之间轻松重新分配。

### 为什么使用虚拟机？

服务器整合是使用虚拟机的主要原因。大多数操作系统和应用程序部署仅使用可用物理资源的一小部分。通过虚拟化服务器，我们可以将许多虚拟服务器放置在每个物理服务器上，以提高硬件利用率。这使我们不需要购买额外的物理资源。

虚拟机提供了一个与系统其他部分隔离的环境，因此在虚拟机内运行的任何内容都不会干扰主机硬件上运行的其他内容。由于虚拟机是隔离的，它们是测试新应用程序或设置生产环境的良好选择。我们还可以运行单一用途的虚拟机以支持特定用例。

## 容器

容器是一种标准的软件单元，它将代码及其所有依赖项（如特定版本的运行时和库）打包在一起，以便应用程序能够在不同的计算环境中快速可靠地运行。容器提供了一种逻辑打包机制，可以将应用程序从其实际运行的环境中抽象出来。这种解耦使基于容器的应用程序能够轻松且一致地部署，无论目标环境如何。

### 为什么我们需要容器？

让我们讨论一下使用容器的一些优势：

**职责分离**

容器化提供了明确的职责分离，开发人员专注于应用程序逻辑和依赖项，而运维团队则专注于部署和管理。

**工作负载可移植性**

容器几乎可以在任何地方运行，大大简化了开发和部署。

**应用程序隔离**

容器在操作系统级别虚拟化 CPU、内存、存储和网络资源，为开发人员提供了一个与其他应用程序逻辑隔离的操作系统视图。

**敏捷开发**

容器允许开发人员更快地移动，避免了对依赖项和环境的担忧。

**高效操作**

容器是轻量级的，只使用我们需要的计算资源。

## 虚拟化 vs 容器化

![virtualization-vs-containerization](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/virtual-machines-and-containers/virtualization-vs-containerization.png)

在传统虚拟化中，虚拟机管理程序（Hypervisor）虚拟化物理硬件。结果是每个虚拟机包含一个客户操作系统、操作系统所需的虚拟硬件副本、应用程序及其相关的库和依赖项。

容器不虚拟化底层硬件，而是虚拟化操作系统，因此每个容器只包含应用程序及其依赖项，使其比虚拟机轻量得多。容器还共享操作系统内核，使用的内存只是虚拟机所需的一小部分。

# OAuth 2.0 和 OpenID Connect (OIDC)

## OAuth 2.0

OAuth 2.0，代表开放授权，是一种标准，旨在代表用户提供对资源的同意访问，而无需共享用户的凭据。OAuth 2.0 是一种授权协议，而不是身份验证协议，主要设计为授予对一组资源的访问，例如远程 API 或用户数据。

### 概念

OAuth 2.0 协议定义了以下实体：

- **资源所有者**：拥有受保护资源并可以授予访问权限的用户或系统。
- **客户端**：需要访问受保护资源的系统。
- **授权服务器**：接收来自客户端的访问令牌请求，并在资源所有者成功认证和同意后发放令牌。
- **资源服务器**：保护用户资源并接收来自客户端的访问请求。它接受并验证来自客户端的访问令牌，并返回相应的资源。
- **范围**：用于指定授予访问资源的具体原因。可接受的范围值及其相关资源取决于资源服务器。
- **访问令牌**：代表授权访问资源的一个数据片段。

### OAuth 2.0 如何工作？

让我们了解 OAuth 2.0 的工作原理：

![oauth2](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/oauth2-and-openid-connect/oauth2.png)

1. 客户端向授权服务器请求授权，提供客户端 ID 和密钥作为标识。它还提供范围和一个用于发送访问令牌或授权码的端点 URI。
2. 授权服务器认证客户端并验证请求的范围是否被允许。
3. 资源所有者与授权服务器交互以授予访问权限。
4. 授权服务器重定向回客户端，带有授权码或访问令牌，具体取决于授权类型。可能还会返回刷新令牌。
5. 客户端使用访问令牌向资源服务器请求访问资源。

### 缺点

以下是 OAuth 2.0 的一些常见缺点：

- 缺乏内置的安全功能。
- 没有标准实现。
- 没有通用的范围集。

## OpenID Connect

OAuth 2.0 仅设计用于_授权_，用于授予一个应用程序对另一个应用程序的数据和功能的访问。OpenID Connect (OIDC) 是一个位于 OAuth 2.0 之上的薄层，添加了有关登录用户的登录和个人信息。

当授权服务器支持 OIDC 时，有时称为身份提供者 (IdP)，因为它向客户端提供有关资源所有者的信息。OpenID Connect 相对较新，与 OAuth 相比，采用率和行业最佳实践的实施较低。

### 概念

OpenID Connect (OIDC) 协议定义了以下实体：

- **依赖方**：当前应用程序。
- **OpenID 提供者**：这是一个中间服务，向依赖方提供一次性代码。
- **令牌端点**：接受一次性代码 (OTC) 并提供有效期为一小时的访问代码的 Web 服务器。OIDC 和 OAuth 2.0 的主要区别在于令牌使用 JSON Web Token (JWT) 提供。
- **用户信息端点**：依赖方与此端点通信，提供安全令牌并接收有关最终用户的信息。

OAuth 2.0 和 OIDC 都易于实现，并且基于 JSON，支持大多数 Web 和移动应用程序。然而，OpenID Connect (OIDC) 规范比基本 OAuth 更严格。

# 单点登录 (SSO)

单点登录 (SSO) 是一种身份验证过程，用户使用一组登录凭据即可访问多个应用程序或网站。这避免了用户需要分别登录不同应用程序的需求。

用户凭据和其他身份信息由一个称为身份提供者 (IdP) 的集中系统存储和管理。身份提供者是一个受信任的系统，提供对其他网站和应用程序的访问。

基于单点登录 (SSO) 的身份验证系统通常用于企业环境中，员工需要访问组织的多个应用程序。

## 组件

让我们讨论单点登录 (SSO) 的一些关键组件。

### 身份提供者 (IdP)

用户身份信息由一个称为身份提供者 (IdP) 的集中系统存储和管理。身份提供者认证用户并提供对服务提供者的访问。

身份提供者可以通过验证用户名和密码直接认证用户，或者通过验证由单独的身份提供者提供的关于用户身份的声明来认证用户。身份提供者处理用户身份的管理，以免服务提供者承担这一责任。

### 服务提供者

服务提供者向最终用户提供服务。他们依赖身份提供者来断言用户的身份，通常由身份提供者管理用户的某些属性。服务提供者还可能为用户维护一个本地账户以及其服务独有的属性。

### 身份代理

身份代理充当中介，将多个服务提供者与各种不同的身份提供者连接起来。使用身份代理，我们可以在任何应用程序上执行单点登录，而无需处理其遵循的协议。

## SAML

安全断言标记语言 (SAML) 是一种开放标准，允许客户端在不同系统之间共享有关身份、认证和权限的安全信息。SAML 使用可扩展标记语言 (XML) 标准来共享数据。

SAML 特别支持身份联合，使身份提供者 (IdP) 能够无缝且安全地将认证身份及其属性传递给服务提供者。

## 单点登录如何工作？

现在，让我们讨论单点登录的工作原理：

![sso](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/single-sign-on/sso.png)

1. 用户向其所需的应用程序请求资源。
2. 应用程序将用户重定向到身份提供者 (IdP) 进行认证。
3. 用户使用其凭据（通常是用户名和密码）登录。
4. 身份提供者 (IdP) 向客户端应用程序发送单点登录响应。
5. 应用程序授予用户访问权限。

## SAML vs OAuth 2.0 和 OpenID Connect (OIDC)

SAML、OAuth 和 OIDC 之间有许多区别。SAML 使用 XML 传递消息，而 OAuth 和 OIDC 使用 JSON。OAuth 提供了更简单的体验，而 SAML 针对企业安全。

OAuth 和 OIDC 广泛使用 RESTful 通信，这就是为什么移动和现代 Web 应用程序发现 OAuth 和 OIDC 为用户提供了更好的体验。另一方面，SAML 在浏览器中放置一个会话 cookie，允许用户访问某些网页。这对于短期工作负载非常有用。

OIDC 对开发人员友好且易于实现，这扩大了其可能的用例。它可以通过所有常见编程语言中的免费库快速从头开始实现。SAML 可能复杂且难以安装和维护，只有企业规模的公司才能很好地处理。

OpenID Connect 本质上是 OAuth 框架之上的一层。因此，它可以提供一个内置的权限层，要求用户同意服务提供者可能访问的内容。尽管 SAML 也能够允许同意流程，但它通过开发人员进行硬编码实现，而不是作为其协议的一部分。

_这两种身份验证协议在各自的领域都表现出色。正如往常一样，很多取决于我们的具体用例和目标受众。_

## 优点

以下是使用单点登录的一些好处：

- 用户只需记住一组凭据，使用方便。
- 访问便捷，无需经过冗长的授权过程。
- 强制安全和合规性，保护敏感数据。
- 简化管理，降低 IT 支持成本和管理时间。

## 缺点

以下是单点登录的一些缺点：

- 单一密码漏洞，如果主 SSO 密码被泄露，所有支持的应用程序都会受到影响。
- 使用单点登录的身份验证过程比传统身份验证更慢，因为每个应用程序都必须请求 SSO 提供者进行验证。

## 示例

以下是一些常用的身份提供者 (IdP)：

- [Okta](https://www.okta.com)
- [Google](https://cloud.google.com/architecture/identity/single-sign-on)
- [Auth0](https://auth0.com)
- [OneLogin](https://www.onelogin.com)

# SSL, TLS, mTLS

让我们简要讨论一些重要的通信安全协议，如 SSL、TLS 和 mTLS。从_“大局”_系统设计的角度来看，这个话题不是非常重要，但仍然值得了解。

## SSL

SSL 代表安全套接字层，是一种用于加密和保护互联网通信的协议。它于 1995 年首次开发，但后来被弃用，取而代之的是传输层安全 (TLS)。

### 为什么它仍被称为 SSL 证书？

大多数主要的证书提供商仍将证书称为 SSL 证书，这就是为什么这种命名约定仍然存在。

### 为什么 SSL 如此重要？

最初，网络上的数据是以明文传输的，任何人都可以读取截获的消息。SSL 被创建来解决这个问题并保护用户隐私。通过加密用户和 Web 服务器之间的任何数据，SSL 还通过防止攻击者篡改传输中的数据来阻止某些类型的网络攻击。

## TLS

传输层安全 (TLS) 是一种广泛采用的安全协议，旨在促进互联网通信的隐私和数据安全。TLS 从以前的加密协议安全套接字层 (SSL) 演变而来。TLS 的主要用例是加密 Web 应用程序和服务器之间的通信。

TLS 协议实现了三个主要功能：

- **加密**：隐藏第三方传输的数据。
- **认证**：确保交换信息的各方是他们声称的身份。
- **完整性**：验证数据未被伪造或篡改。

## mTLS

双向 TLS (mTLS) 是一种双向认证方法。mTLS 确保网络连接两端的各方通过验证它们都拥有正确的私钥来证明它们的身份。各自的 TLS 证书中的信息提供了额外的验证。

### 为什么使用 mTLS？

mTLS 有助于确保客户端和服务器之间的双向通信是安全和可信的。这为登录到组织网络或应用程序的用户提供了额外的安全层。它还验证不遵循登录过程的客户端设备的连接，如物联网 (IoT) 设备。

如今，mTLS 通常由微服务或分布式系统在[零信任安全模型](https://en.wikipedia.org/wiki/Zero_trust_security_model)中使用，以相互验证。