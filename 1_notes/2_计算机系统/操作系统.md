# 操作系统基本概念

## 用户态和内核态

* 用户态和内核态的区别
  * 用户态和内核态是操作系统的两种运行级别，两者最大的区别就是特权级不同
  * 用户态拥有最低的特权级，内核态拥有较高的特权级
  * **运行在用户态的程序不能直接访问操作系统内核数据结构和程序**
  * 操作系统的**数据都是存放于系统空间的**，**用户进程的数据是存放于用户空间的**。 分开来存放，就让系统的数据和用户的数据**互不干扰**，**保证系统的稳定性**
  * 分开存放，管理上很方便，而更重要的是，**将用户的数据和系统的数据隔离开**，就可以**对两部分的数据的访问进行控制**。这样就可以确保用户程序不能随便操作系统的数据，这样**防止用户程序误操作或者是恶意破坏系统**
  
* [用户态和内核态可以通过指针传递数据吗？](http://blog.chinaunix.net/uid-26611973-id-3190018.html)
  * **用户态不能访问内核态的指针**
    - 为了实现内存的保护，**防止越界访问而造成受保护内存的被非法修改**，甚至造成系统的崩溃，这种直接传递数据指针来传递数据的方式是被禁止的。
  * 内核态可以访问用户态的指针(**有前提**)
    - **必须保证用户态虚拟空间的指针**（虚拟空间的地址），**已经分配物理地址**，**否则指针传入内核态中将不会引发缺页异常而报错**
  * **内核中访问用户进程的地址的时候用copy_from_user，而不是用memcpy直接拷贝**(或者说使用用户态指针)
    - copy_from_user主要是这个函数提供了两个功能
      - 对用户进程传过来的地址范围进行合法性检查
      - 当用户传来的地址没有分配物理地址时，定义了缺页处理后的异常发生地址，保证程序顺利执行
      - **对于用户进程访问虚拟地址，如果还未分配物理地址，就会触发内核缺页异常，接着内核会负责分配物理地址，并修改映射页表**。这个过程对于用户进程是完全透明的。**但是在内核空间发生缺页时，必须显式处理，否则会导致内核出现错误**
    - 直接使用memcpy时为什么没有出现异常
      - **只有用户传来的地址空间没有分配对应的物理地址时才会进行修复，如果用户进程之前已经使用过这段空间，代表已经分配了物理地址，自然不会发生缺页异常**
  
* **两种状态转换**
  - **系统调用**
    - 用户进程**主动要求切换**到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完成工作
  - **异常**
    - 当CPU在执行运行在用户态的程序时，发现了**某些事件不可知的异常**，这是会**触发由当前运行进程切换到处理此异常的内核相关程序**中，也就到了内核态，比如缺页异常
  - **外围设备中断**
    - 当外围设备完成用户请求的操作之后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的指令，转而去执行中断信号的处理程序
    - 比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等
  
* 当发生用户态到内核态的切换时，会发生如下过程（本质上是从“用户程序”切换到“内核程序”）

  - trap指令设置处理器至内核态
  - 保存当前寄存器（栈指针、程序计数器、通用寄存器）
  - 将栈指针设置指向内核栈地址(用户栈切换为内核栈)
  - 将程序计数器设置为一个事先约定的地址上，该地址上存放的是**系统调用处理程序的起始(入口)地址**

  而之后从内核态返回用户态时，又会进行类似的工作

*  如何避免频繁切换

  用户态和内核态之间的切换有一定的开销，如果频繁发生切换势必会带来很大的开销，所以要想尽一切办法来减少切换。这也是面试常考的问题。

  * 减少线程切换：因为线程的切换会导致用户态和内核态之间的切换，所以减少线程切换也会减少用户态和内核态之间的切换

  - 无锁并发编程。多线程竞争锁时，加锁、释放锁会导致比较多的上下文切换
  - CAS算法。使用CAS避免加锁，避免阻塞线程
  - 使用最少的线程。避免创建不需要的线程
  - 协程。在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换
  - 使用用户进程缓冲区：buffer，减少系统调用的调用次数

* 用户进程缓冲区和内核缓冲区

  * 用户进程缓冲区
    * 你看一些程序在读取文件时，会先申请一块内存数组，称为buffer，然后每次调用read，读取设定字节长度的数据，写入buffer。之后的程序都是从buffer中获取数据，当buffer使用完后，在进行下一次调用，填充buffer。所以说：用户缓冲区的目的就是是为了减少系统调用次数，从而降低操作系统在用户态与核心态切换所耗费的时间。除了在进程中设计缓冲区，内核也有自己的缓冲区。

  * 内核缓冲区
    * 当一个用户进程要从磁盘读取数据时，内核一般不直接读磁盘，而是将内核缓冲区中的数据复制到进程缓冲区中。但若是内核缓冲区中没有数据，内核会把对数据块的请求，加入到请求队列，然后把进程挂起，为其它进程提供服务。等到数据已经读取到内核缓冲区时，把内核缓冲区中的数据读取到用户进程中，才会通知进程，当然不同的IO模型，在调度和使用内核缓冲区的方式上有所不同

* 程序计数器PC和指令指针寄存器IP
  * 程序计数器PC
    - 用指令事先编好的程序连续存放在内存程序区中，靠地址+1的方法连续取指执行”。在八位机8080CPU中是采用先取指后执行的串行操作的原理，而其中执行地址+1指令寻址的部件就是程序计数器PC。那么在程序的执行过程中，PC始终是指向下一条要执行的指令
    - 结论：PC中的地址就是需要转移、循环、调用子程序和中断子程序等操作时的断点
  * 指令指针寄存器IP
    - 在向上兼容的十六位机8086CPU中首先分为两个功能部件，即总线接口部件BIU和执行部件EU，BIU负责取指令，EU负责译码执行。并且当BIU执行指令排队栈中的六个字节装满后，（8088CPU是4个字节），EU开始从指令排队栈的出栈口，取指令进行译码执行，同时BIU并行操作向入栈口补充一条取指令命令
    - 指令指针IP则是指向下个条要取指的指令，而不是EU要执行的指令。而断点则应该是要执行的指令内存地址，而不是IP内的下一条要取指的指令地址
  * **PC是模型机中的概念，IP是实际使用的，调试时我们发现，IP实现的就是PC的功能**

## 系统调用

* 什么是系统调用

  OS 提供给用户编程时的一些公共子程序，一般为函数或方法

* 为什么要使用系统调用？

  OS **为了安全的管理计算机软硬件资源，不允许程序员直接操作系统资源**，比如（进程、内存、I/O、文件），但是用户可以通过系统调用向 OS 请求相关资源的服务，比如：I/O 的请求和释放、设备启动、文件的创建、读写、删除、进程的创建、撤销、阻塞、唤醒进程间的消息传递、内存的配备和回收等

* 程序员如何使用系统调用，OS 如何响应？

  程序员在代码中首先传递系统调用参数，然后由陷入（trap）指令负责将用户态转换为核心态，从用户栈切换到内核栈，并将返回地址压栈备用，然后 CPU 执行相应的内核服务程序，最后返回用户态

* `int 0x80`指令会让cpu陷入中断，执行对应的0x80中断处理函数。不过在这之前，cpu还需要进行**栈切换**

  因为在linux中，**用户态和内核态使用的是不同的栈**（可以看看这篇[文章](https://blog.csdn.net/yangkuanqaz85988/article/details/52403726)），两者负责各自的函数调用，互不干扰。在执行`int $0x80`时，程序需要由用户态切换到内核态，所以程序当前栈也要**从用户栈切换到内核栈**。与之对应，当中断程序执行结束返回时，当前栈要**从内核栈切换回用户栈**

  这里说的当前栈指的就是ESP寄存器的值所指向的栈。ESP的值位于用户栈的范围，那程序的当前栈就是用户栈，反之亦然。此外寄存器SS的值指向当前栈所在的页。因此，将用户栈切换到内核栈的过程是：

  1. 将当前ESP、SS等寄存器的值存到内核栈上
  2. 将ESP、SS等值设置为内核栈的相应值

  反之，从内核栈切换回用户栈的过程：恢复ESP、SS等寄存器的值，也就是用保存在内核栈的原ESP、SS等值设置回对应寄存器

* 为什么需要单独的进程内核栈？

  所有进程运行的时候，都可能通过系统调用陷入内核态继续执行。假设第一个进程 A 陷入内核态执行的时候，需要等待读取网卡的数据，主动调用 schedule() 让出 CPU；此时调度器唤醒了另一个进程 B，碰巧进程 B 也需要系统调用进入内核态。那问题就来了，如果内核栈只有一个，那进程 B 进入内核态的时候产生的压栈操作，必然会破坏掉进程 A 已有的内核栈数据；一但进程 A 的内核栈数据被破坏，很可能导致进程 A 的内核态无法正确返回到对应的用户态了

## 中断

* 操作系统一般是通过中断来从用户态切换到内核态

* 中断一般有两个属性，一个是**中断号**，一个是**中断处理程序**。不同的中断有不同的中断号，每个中断号都对应了一个中断处理程序。在内核中有一个叫**中断向量表**的数组来映射这个关系。当中断到来时，cpu会暂停正在执行的代码，根据中断号去中断向量表找出对应的中断处理程序并调用。中断处理程序执行完成后，会继续执行之前的代码
* 中断分为硬件中断和软件中断，我们这里说的是软件中断，软件中断通常是一条指令，使用这条指令用户可以手动触发某个中断。例如在i386下，对应的指令是int，在int指令后指定对应的中断号，如int 0x80代表你调用第0x80号的中断处理程序
* 中断号是有限的，所有不会用一个中断来对应一个系统调用（系统调用有很多）。**Linux下用int 0x80触发所有的系统调用**，那如何区分不同的调用呢？**对于每个系统调用都有一个系统调用号，在触发中断之前，会将系统调用号放入到一个固定的寄存器，0x80对应的中断处理程序会读取该寄存器的值，然后决定执行哪个系统调用的代码**

# 进程管理

## 进程和线程

* **进程的概念**：**进程是程序在某个数据集合上的一次运行活动，也是操作系统进行资源分配和保护的基本单位**。通俗来说，**「进程就是程序的一次执行过程」**，程序是静态的，它作为系统中的一种资源是永远存在的。而进程是动态的，它是动态的产生，变化和消亡的，拥有其自己的生命周期

* 进程的组成

  * **进程控制块 PCB**。包含如下几个部分：
    - 进程描述信息，如pid，gid
    - 进程控制和管理信息，如进程状态，优先级，未决信号集，信号屏蔽字
    - 资源分配清单，如页表，打开文件列表
    - CPU 相关信息，如寄存器，状态寄存器，堆栈指针
  * **数据段**。即进程运行过程中各种数据（比如程序中定义的变量）
  * **程序段**。就是程序的代码（指令序列）

* 进程上下文切换

  * 首先，将进程 A 的运行环境信息存入 PCB，这个运行环境信息就是进程的上下文（Context）
  * 然后，将 PCB 移入相应的进程队列
  * 选择另一个进程 B 进行执行，并更新其 PCB 中的状态为运行态
  * 当进程 A 被恢复运行的时候，根据它的 PCB 恢复进程 A 所需的运行环境

* 线程的概念：线程是独立调度的基本单位。一个进程中可以有多个线程，它们共享进程资源

* 线程的实现可以分为两类：

  * 用户级线程：不需要内核支持而在**用户程序中实现的线程**，其不依赖于操作系统核心，在语言层面利用线程库提供创建、同步、调度和管理线程的函数来控制用户线程。**不需要用户态/内核态切换，速度快，操作系统内核不知道多线程的存在，因此一个线 程阻塞将使得整个进程（包括它的所有线程）阻塞**。由于这里的**处理器时间片分配是以进程为基本单位，所以每个线程执行的时间相对减少**
  * 内核线线程：又称为内核支持的线程或轻量级进程，所以线程切换时需要进入到内核态

* **同一进程中线程资源共享情况**
  * 线程共享的资源包括：**进程代码段、进程的公有数据**(利用这些共享的数据，线程很容易的实现相互之间的通讯)、**进程打开的文件描述符**、**信号的处理函数**、**进程的当前目录和进程用户ID与进程组ID**
  * 线程不共享的资源包括：
    * **线程ID**：每个线程都有自己的线程ID，这个ID在本进程中是唯一的。进程用此来标识线程
    * **寄存器组的值**：由于线程间是并发运行的，**每个线程有自己不同的运行线索**，当从一个线程切换到另一个线程上 时，必须将原有的线程的寄存器集合的状态保存，以便将来该线程在被重新切换到时能得以恢复
    * **线程的堆栈**：堆栈是保证线程独立运行所必须的。线程函数可以调用函数，而被调用函数中又是可以层层嵌套的，所以线程必须拥有自己的函数堆栈，使得函数调用可以正常执行，不受其他线程的影响
    * **错误返回码(errno)**：由于同一个进程中有很多个线程在同时运行，可能某个线程进行系统调用后设置了errno值，而在该线程还没有处理这个错误，另外一个线程就在此时被调度器投入运行，这样错误值就有可能被修改。所以，不同的线程应该拥有自己的错误返回码变量
    * **线程的信号屏蔽码**：由于**每个线程所感兴趣的信号不同**，所以**线程的信号屏蔽码应该由线程自己管理**。**但所有的线程都共享同样的信号处理器**
    * **线程的优先级**：由于线程需要像进程那样能够被调度，那么就必须要有可供调度使用的参数，这个参数就是线程的优先级
  
* 线程的优缺点

  * 优点：
    * 一个进程中可以同时存在多个线程，这些线程共享该进程的资源。**进程间的通信必须请求操作系统服务**（因为 CPU 要切换到内核态），开销很大。而同进程下的线程间通信，无需操作系统干预，开销更小。不过，需要注意的是：**从属于不同进程的线程间通信，也必须请求操作系统服务**
    * **线程间的并发比进程的开销更小**，**系统并发性提升**。同样，需要注意的是：**从属于不同进程的线程间切换，它是会导致进程切换的，所以开销也大**
  * 缺点：
    * 当进程中的一个线程奔溃时，会导致其所属进程的所有线程奔溃。举个例子，**对于游戏的用户设计，就不应该使用多线程的方式，否则一个用户挂了，会影响其他同个进程的线程**

* **进程和线程的区别**
  * 拥有资源
    * 进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源
  * 调度
    * 线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换
  * 系统开销
      * 进程在创建、切换和销毁时开销比较大，而线程比较小。进程创建的时候需要分配系统资源，而销毁的的时候需要释放系统资源。**进程切换需要分两步**：**切换页目录、刷新TLB以使用新的地址空间**；**切换内核栈和硬件上下文（寄存器）**；**而同一进程的线程间逻辑地址空间是一样的，线程切换时不需要切换页目录、刷新TLB，只需保存和设置少量寄存器内容、堆栈指针，开销较小**
    * **进程在创建、销毁时开销比较大，而线程比较小**。进程创建的时候需要分配**虚拟地址空间、IO设备**等系统资源，而**销毁的的时候需要释放系统资源**；线程只需要**创建栈，栈指针，程序计数器，通用目的寄存器和条件码**等，**不需要创建独立的虚拟地址空间**等系统资源
  * 通信方面
    * **线程间可以通过直接读写同一进程中的数据进行通信**，但是进程通信需要借助 IPC
  
* 多进程和多线程

  * 多线程
    * **多线程就是指一个进程中同时有多个线程正在执行**
    * 多线程原因
      * 在一个程序中，**有很多的操作是非常耗时的**，如**数据库读写操作，IO操作**等，如果使用单线程，那么程序就必须等待这些操作执行完成之后才能执行其他操作。**使用多线程，可以在将耗时任务放在后台继续执行的同时，同时执行其他操作**，可以提高程序的效率
    * 多线程优点
      * 创建速度快，方便高效的数据共享
      * **共享数据**：多线程间可以共享同一虚拟地址空间；多进程间的数据共享就需要用到共享内存、信号量等IPC技术
      * **较轻的上下文切换开销**：**不用切换地址空间(页表)**，不用更改CR3寄存器，**不用刷新TLB**
      * **提供非均质的服务**：如果全都是计算任务，但每个任务的耗时不都为1s，而是1ms-1s之间波动；这样，多线程相比多进程的优势就体现出来，它能有效降低“简单任务被复杂任务压住”的概率
    * 多线程的缺点
      * **使用太多线程，是很耗系统资源，因为线程需要开辟内存。更多线程需要更多内存**
      * **影响系统性能，因为操作系统需要在线程之间来回切换**
      * 需要考虑线程操作对程序的影响，如线程挂起，中止等操作对程序的影响，**某个线程的崩溃会导致整个程序崩溃**
    * 多线程是异步的，但这不代表多线程真的是几个线程是在同时进行，实际上是**系统不断地在各个线程之间来回的切换**（因为系统切换的速度非常的快，所以给我们在同时运行的错觉）
    * 适用场景
      * **线程间有数据共享**，并且数据是需要修改的（不同任务间需要大量共享数据或频繁通信时）
      * 提供**非均质的服务**（有优先级任务处理）事件响应有优先
      * **单任务并行计算**，在非CPU Bound的场景下提高响应速度，降低时延
      * 与人**有IO交互的应用**，良好的用户体验（键盘鼠标的输入，立刻响应)
  * 多进程
    * 多进程就是指**计算机同时执行多个进程**，一般是同时运行多个软件
    * 优点
      * 编程相对容易，通常不需要考虑锁和同步资源的问题
      * 更强的容错性：比起多线程的一个好处是一个进程崩溃了不会影响其他进程
      * 有内核保证的隔离：数据和错误隔离
      * 对于使用如C/C++这些语言编写的本地代码，错误隔离是非常有用的：**采用多进程架构的程序一般可以做到一定程度的自恢复**；（如Nginx，master守护进程监控所有worker进程，发现进程挂掉后将其重启）
  * 应用场景
    * 多进程模型的优势是CPU
    * 多线程模型主要优势为**线程间切换代价较小**，因此**适用于I/O密集型的工作场景**，因此I/O密集型的工作场景经常会**由于I/O阻塞导致频繁的切换线程**。同时，**多线程模型也适用于单机多核分布式场景**
    * 多进程模型，**适用于CPU密集型**。同时，**多进程模型也适用于多机分布式场景中，易于多机扩展**
    * 进程线程间创建的开销不足作为选择的依据，因为一般我们都是使用线程池或者进程池，在系统启动时就创建了固定的线程或进程，不会频繁的创建和销毁
    * 首先，根据工作集（需要共享的内存）的大小来定；**如果工作集较大，就用多线程，避免cpu cache频繁的换入换出**；比如memcached缓存系统
    * 其次，选择的依据根据以上多线程适用的场景来对比自身的业务场景，是否有这样场景需求：**数据共享、提供非均质的服务，单任务拆散并行化等**；
    * 如果没有必要，或者多进程就可以很好的胜任，就**多用多进程，享受单线程编程带来便利**
  
* 高并发

  * 高并发指的是是一种系统运行过程中遇到的一种“**短时间内遇到大量操作请求**”的情况，主要发生在web系统集中大量访问或者socket端口集中性收到大量请求（例如：12306的抢票情况；天猫双十一活动）。该情况的发生会导致系统在这段时间内执行大量操作，例如对资源的请求，数据库的操作等。如果高并发处理不好，不仅仅降低了用户的体验度（请求响应时间过长），同时可能导致系统宕机，严重的甚至导致OOM异常，系统停止工作等

* 多线程与高并发的联系

  * 多线程只是在同/异步角度上解决高并发问题的其中的一个方法手段，是**在同一时刻利用计算机闲置资源的一种方式**
  * 多线程在高并发问题中的作用就是**充分利用计算机资源**，**使计算机的资源在每一时刻都能达到最大的利用率**，不至于浪费计算机资源使其闲置

* 操作系统的设计，**从进程和线程的角度来说**，可以归结为三点：

  - **以多进程形式，允许多个任务同时运行**
  - **以多线程形式，允许单个任务分成不同的部分运行**
  - **提供协调机制，一方面防止进程之间和线程之间产生冲突，另一方面允许进程之间和线程之间共享资源**


## 协程

* 基本概念：**协程，英文Coroutines，是一种比线程更加轻量级的存在。**正如一个进程可以拥有多个线程一样，一个线程也可以拥有多个协程

  <img src="imgs/os/corotines.png" alt="corotines" style="zoom:60%;" />

* 进程，线程，协程的上下文切换

  * 进程的切换者是操作系统，切换时机是根据操作系统自己的切换策略，用户是无感知的。进程的切换内容包括**页全局目录、内核栈、硬件上下文，切换内容保存在内存**中。进程切换过程是由“**用户态到内核态到用户态**”的方式，**切换效率低**
  * 线程的切换者是操作系统，切换时机是根据操作系统自己的切换策略，用户无感知。线程的切换内容**包括内核栈和硬件上下文**。线程切换内容保存在内核栈中。线程切换过程是由“用户态到内核态到用户态”， **切换效率中等**
  * 协程的切换者是用户（编程者或应用程序），**切换时机是用户自己的程序所决定的**。协程的**切换内容是硬件上下文**，**切换内存保存在用户自己的变量**（用户栈或堆）中。**协程的切换过程只有用户态，即没有陷入内核态，因此切换效率高**
  * **协程是轻量级线程，拥有自己的寄存器上下文和栈**。**协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈**
  * 协程能保留上一次调用时的状态，即所有局部状态的一个特定组合，每次过程重入时，就相当于进入上一次调用的状态

* 协程相比进程和线程的优势

  * 协程拥有极高的执行效率。因为**子程序切换不是线程切换，协程不是被操作系统内核所管理，而是由程序自身完全控制(完全运行在用户态)，因此，没有线程切换的开销**，和多线程比，线程数量越多，协程的性能优势就越明显
  * 不需要多线程的锁机制，因为**只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多**

* 协程分类：

  * **按照控制传递机制**

    - **非对称式协程**：通过yield, 将控制权返回给调用方, 如达夫设备 就是一种非对称式协程，这种协程更像是一个可以返回多次的子例程(函数)，因此代码可读性会较高

    - **对称式协程**：通过resum, 将控制权交给任意协程, 这种协程更像goto 可以任意的跳转 返回，如果滥用会导致代码可读性较低

  * **按调实现分类**

    - **stackfull 有栈协程**：**每个协程都拥有自己的栈，协程上下文保存在自己的栈中**，切换协程就是切换栈然后恢复栈中的上下文，这种方法实现的协程更像是用户态的线程

    - **stackcopy 共享栈协程**：stackfull 的缺点显而易见，**十分浪费内存，当协程数量过多时会导致内存开销过大**。stackcopy 就是用来解决此问题的，**所有协程公用一个运行栈，当协程发生切换的时候，将协程数据copy到自身的独立栈中，独立栈可以进行动态的扩充**

    - **stackless 无栈协程**：stackless 协程公用一个栈，但是与stackcopy 不同，**协程切换的时候仅会将所需的上下文保存在堆中**, 可以将部分无用局部变量提前释放，通常这需要编译器的支持。stackless 协程通常只有顶层例程可以被挂起

* **应用场景**

  - I/O 密集型任务
    - 这一点与多线程有些类似，**但协程调用是在一个线程内进行的，是单线程，切换的开销小，因此效率上略高于多线程**
    - 当程序在执行 I/O 时操作时，CPU 是空闲的，此时可以充分利用 CPU 的时间片来处理其他任务。在单线程中，一个函数调用，一般是从函数的第一行代码开始执行，结束于 return 语句、异常或者函数执行（也可以认为是隐式地返回了 None ）
    - **有了协程，我们在函数的执行过程中，如果遇到了耗时的 I/O 操作，函数可以临时让出控制权，让 CPU 执行其他函数，等 I/O 操作执行完毕以后再收回控制权**
  - 当今无数的 Web 服务和互联网服务，**本质上大部分都是 IO 密集型服务**，什么是 IO 密集型服务？意思是处理的任务大多是和**网络连接或读写相关的高耗时任务**，高耗时是相对 CPU 计算逻辑处理型任务来说，两者的处理时间差距不是一个数量级的
    - **IO 密集型服务的瓶颈不在 CPU 处理速度，而在于尽可能快速的完成高并发、多连接下的数据读写**
  - **以前有两种解决方案：**
    -  如果用多线程，**高并发场景的大量 IO 等待会导致多线程被频繁挂起和切换**，非常消耗系统资源，同时多线程访问共享资源存在竞争问题
    -  如果用多进程，不仅存在频繁调度切换问题，同时还会存在每个进程资源不共享的问题，需要**额外引入进程间通信机制来解决**

  * **协程出现给高并发和 IO 密集型服务开发提供了另一种选择。**当然，世界上没有技术银弹，在这里我想把协程这把钥匙交到你手中，但是它也不是万能钥匙，最好的解决方案是贴合自身业务类型做出最优选择，不一定就选择一种模型，有时候是几种模型的组合，比如**多线程搭配协程是常见的组合**

* 因为协程是在一个线程执行，那怎么利用多核CPU呢？最简单的方法是**多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能**

* python协程完成生产者-消费者问题例子（Python对协程的支持还非常有限，用在generator中的**yield**可以一定程度上实现协程）

  ```python
  import time
  
  def consumer():
      r = ''
      while True:
          n = yield r
          if not n:
              return
          print('[CONSUMER] Consuming %s...' % n)
          time.sleep(1)
          r = '200 OK'
  
  def produce(c):
      c.next()
      n = 0
      while n < 5:
          n = n + 1
          print('[PRODUCER] Producing %s...' % n)
          r = c.send(n)
          print('[PRODUCER] Consumer return: %s' % r)
      c.close()
  
  if __name__=='__main__':
      c = consumer()
      produce(c)
  ```

  注意到consumer函数是一个generator（生成器），把一个consumer传入produce后：

  1. 首先调用c.next()启动生成器；
  2. 然后，一旦生产了东西，通过c.send(n)切换到consumer执行；
  3. consumer通过yield拿到消息，处理，又通过yield把结果传回；
  4. produce拿到consumer处理的结果，继续生产下一条消息；
  5. produce决定不生产了，通过c.close()关闭consumer，整个过程结束。

  整个流程**无锁**，由一个线程执行，produce和consumer**协作完成任务**，所以称为“协程”，而非线程的抢占式多任务

* 支持协程的编程语言

  * **Lua语言**
  * **Python语言**
  * **Go语言**
  * **Java语言(Kilim框架)**

## 同步互斥

* [详见1](https://www.jianshu.com/p/6526078a1fab)

* [详见2](https://blog.csdn.net/qicheng777/article/details/77432129)

* 生产者-消费者问题(C++11实现)

  ```c++
  #include <thread>
  #include <mutex>
  #include <condition_variable>
  #include <queue>
  #include <cstdlib>
  #include <iostream>
  
  std::mutex mtx;
  std::condition_variable prodCond;
  std::condition_variable consCond;	
  const int QSIZE = 50;
  std::queue<int> blockQueue;
  volatile bool isClose = false;
  
  void producer(int id){
      while(!isClose) {
          long item = 1 + rand() % 99;  // produce item in range [1,100] 
          std::unique_lock<std::mutex> locker(mtx);
          while(blockQueue.size() >= QSIZE)
              prodCond.wait(locker);		// 释放锁，等待，醒来时获得锁
          std::cout<<"Producer " << id <<" produces item "<< item <<std::endl;
          blockQueue.push(item);	// insert item
          locker.unlock();
          consCond.notify_all();
      }
      std::cout<<"Producer " << id <<" finished!"<<std::endl;
  }
  
  void consumer(int id) {
      while(!isClose){
          std::unique_lock<std::mutex> locker(mtx);
          while(blockQueue.size() == 0)
              consCond.wait(locker);	
          int item = blockQueue.front();	// consumes item
          std::cout<<"Consumer " << id <<" cosumes item "<< item << std::endl;
          blockQueue.pop();			// remove item
          locker.unlock();
          prodCond.notify_all();
      }
      std::cout<<"Consumer " << id <<" finished!"<<std::endl;
  }
  
  int main(int argc, char * argv[]){
      const int num = 2;
      std::vector<std::thread> producers(num);
      std::vector<std::thread> consumers(num);
      
      for(int i = 0; i < num; i++){
          producers[i] = std::thread(producer, i+1);
          consumers[i] = std::thread(consumer, i+1);
      }
  	
      sleep(1);
      
    	isClose = true;
      
      for(int i = 0; i < num; i++){
          producers[i].join();
          consumers[i].join();
      }
      
      return 0;
  }
  ```

* 读者-写者问题

  ```c++
  #include <thread>
  #include <mutex>
  #include <iostream>
  
  std::mutex mtx;
  std::mutex cntMtx;
  
  size_t readCount = 0;  // std::atomic<size_t> readCount;
  
  volatile bool isClose = false;
  
  void reader(int id){
    while(!isClose){
          std::unique_lock<std::mutex> cntLock(cntMtx);	// 用于读者互斥计数
          readCount++;
          if(readCount == 1)
          	mtx.lock();			// 第一个读者，加锁
  		cntLock.unlock();
          
          std::cout<<"Reader " << id <<" reads "<< item <<std::endl;
          
          cntLock.lock();
          readCount--;
          if(readCount == 0)		// 已无读者，解锁唤醒写者
          	mtx.unlock();
          cntLock.unlock();
      }
      std::cout<<"Reader " << id <<" finished!"<<std::endl;
  }
  
  void writer(int id){
    while(!isClose){
          mtx.lock();		// 读写互斥锁
          
          std::cout<<"Writer " << id <<" writes "<< item << std::endl;
          
        	mtx.unlock();	// 解锁
      }
      std::cout<<"Writer " << id <<" finished!"<<std::endl;
  }
  
  int main(int argc, char * argv[]){
      const int num = 2;
      std::vector<std::thread> writers(num);
      std::vector<std::thread> readers(num);
      
      for(int i = 0; i < num; i++){
          writers[i] = std::thread(writer, i+1);
      	readers[i] = std::thread(reader, i+1);
      }
  	
      sleep(1);
      
    	isClose = true;
      
      for(int i = 0; i < num; i++){
          writers[i].join();
        	readers[i].join();
      }
    
      return 0;
  }
  ```

## 死锁

* 死锁

  * 死锁是多线程中最差的一种情况，**多个线程相互占用对方的资源的锁，而又相互等对方释放锁**，此时若无外力干预，这些线程则一直处理阻塞的假死状态，形成死锁

* 死锁检测与避免

  * **产生死锁的四大必要条件**

    * **资源互斥/资源不共享**：每个资源要么已经分配给了一个进程，要么是可用的，只有这两种状态，资源不可以被共享使用，所以所谓的互斥是指：资源不共享，如果被使用，只能被一个进程使用
    * **占有和等待/请求并保持**：已经得到资源的进程还能继续请求新的资源
    * **资源不可剥夺**：当一个资源分配给了一个进程后，其它需要该资源的进程不能强制性获得该资源，除非该资源的当前占有者显示地释放该资源
    * **环路等待**：死锁发生时，系统中一定有由两个或两个以上的进程组成的一条环路，环路上的每个进程都在等待下一个进程所占有的资源

  * 编程中避免死锁：

    * 避免多次锁定。**尽量避免同一个线程对多个 Lock 进行锁定**。例如上面的死锁程序，主线程要对 A、B 两个对象的 Lock 进行锁定，副线程也要对 A、B 两个对象的 Lock 进行锁定，这就埋下了导致死锁的隐患。
    * **具有相同的加锁顺序**。如果多个线程需要对多个 Lock 进行锁定，则应该保证它们以相同的顺序请求加锁。比如上面的死锁程序，主线程先对 A 对象的 Lock 加锁，再对 B 对象的 Lock 加锁；而副线程则先对 B 对象的 Lock 加锁，再对 A 对象的 Lock 加锁。这种加锁顺序很容易形成嵌套锁定，进而导致死锁。如果让主线程、副线程按照相同的顺序加锁，就可以避免这个问题。
    * **使用定时锁**。程序在调用 acquire() 方法加锁时可指定 timeout 参数，该参数指定超过 timeout 秒后会自动释放对 Lock 的锁定，这样就可以解开死锁了。
    * 死锁检测。死锁检测是一种依靠算法机制来实现的死锁预防机制，它主要是针对那些不可能实现按序加锁，也不能使用定时锁的场景的。
    * **无锁编程**：cas、原子变量、原子操作等

  * 预防死锁

    * 预防死锁的发生**只需破坏死锁产生的四个必要条件之一**即可
    * 下面的方法开销非常之大，目前没有一个操作系统可以实现
      * **破坏互斥条件**：如果允许系统资源都能共享使用，则系统不会进入死锁状态； **缺点**：有些资源根本不能同时访问，如打印机等临界资源只能互斥使用。所以，**破坏互斥条件而预防死锁的方法不太可行**，而且在有的场合应该保护这种互斥性
      * **破坏请求并保持条件**：釆用**预先静态分配**方法，即**进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前，不把它投入运行**。一旦投入运行后，这些资源就一直归它所有，也不再提出其他资源请求，这样就可以保证系统不会发生死锁。**缺点**：**系统资源被严重浪费**，其中有些资源可能仅在运行初期或运行快结束时才使用，甚至根本不使用。而且还会**导致“饥饿”**现象，**当由于个别资源长期被其他进程占用时，将致使等待该资源的进程迟迟不能开始运行**
      * **破坏不可剥夺条件**：当一个已保持了某些不可剥夺资源的进程，**请求新的资源而得不到满足时**，它**必须释放已经保持的所有资源，待以后需要时再重新申请**。这意味着，一个进程已占有的资源会被暂时释放，或者说是被剥夺了，或从而破坏了不可剥夺条件。**缺点**：该策略**实现起来比较复杂**，**释放已获得的资源可能造成前一阶段工作的失效，反复地申请和释放资源会增加系统开销，降低系统吞吐量**。这种方法**常用于状态易于保存和恢复的资源**，如CPU的寄存器及内存资源，一般不能用于打印机之类的资源
      * **破坏循环等待条件**：为了**破坏循环等待条件**，可釆用**顺序资源分配法**。首先**给系统中的资源编号**，规定每个进程，必须**按编号递增的顺序请求资源，同类资源一次申请完**。也就是说，只要进程提出申请分配资源Ri，则该进程在以后的资源申请中，只能申请编号大于Ri的资源。**缺点**： 这种方法存在的问题是，编号必须相对稳定，这就限制了新类型设备的增加；尽管在为资源编号时已考虑到大多数作业实际使用这些资源的顺序，但也经常会发生作业使用资源的顺序与系统规定顺序不同的情况，造成资源的浪费；此外，这种**按规定次序申请资源的方法，也必然会给用户的编程带来麻烦**
    * 因此，目前使用的方法是避免死锁，而不是预防死锁

  * 避免死锁的算法

    * 判断“**系统安全状态**”法：**在进行系统资源分配之前，先计算此次资源分配的安全性**。若此次分配不会导致系统进入不安全状态，则将资源分配给**进程； 否则，让进程**等待

      ![safe_status](imgs/os/safe_status.png)

      * **图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数**。从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得**所有进程都能成功运行**，因此可以称图 a 所示的状态是安全的
      * 定义：**如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的**
      * 安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比

    * 银行家算法

      * 申请的贷款额度不能超过银行现有的资金总额
      * 分批次向银行提款，但是贷款额度不能超过一开始最大需求量的总额
      * 暂时不能满足客户申请的资金额度时，在有限时间内给予贷款
      * 客户要在规定的时间内还款

    * 单个资源银行家算法

      * 一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，**算法要做的是判断对请求的满足是否会进入不安全状态**，如果是，就拒绝请求；否则予以分配

        ![bank](imgs/os/bank.png)

        上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态

    * 多个资源银行家算法

      ![multi_bank](imgs/os/multi_bank.png)

      * 上图中有**五个进程，四个资源**。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：**总资源、已分配资源以及可用资源**，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0
      * 检查一个状态是否安全的算法如下：
        * **查找右边的矩阵是否存在一行小于等于向量 A**。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的
        * 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中
        * 重复以上两步，直到所有进程都标记为终止，则状态是安全的
      * 如果一个状态不是安全的，需要拒绝进入这个状态

* 活锁

  * 活锁恰恰与死锁相反，死锁是大家都拿不到资源都占用着对方的资源，而活锁是拿到资源却又相互释放不执行。**当多线程中出现了相互谦让**，都主动将资源释放给别的线程使用，这样这个资源在多个线程之间跳动而又得不到执行，这就是活锁

* 饥饿

  * 优先级高的线程能够插队并优先执行，这样如果**优先级高的线程一直抢占优先级低线程的资源，导致低优先级线程无法得到执行**，这就是饥饿。当然还有一种饥饿的情况，**一个线程一直占着一个资源不放而导致其他线程得不到执行**，与死锁不同的是饥饿在以后一段时间内还是能够得到执行的，如那个占用资源的线程结束了并释放了资源

* 无锁

  * 无锁，即没有对资源进行锁定，即所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。**无锁典型的特点就是一个修改操作在一个循环内进行，线程会不断的尝试修改共享资源，如果没有冲突就修改成功并退出否则就会继续下一次循环尝试。所以，如果有多个线程修改同一个值必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功**

## CAS技术

* 概念

  * 比较并交换(compare and swap, CAS)，是原子操作的一种。**在多线程没有锁的状态下，可以保证多个线程对同一个值的更新**。CAS可用于在多线程编程中实现不被打断的数据交换操作，从而避免多线程同时改写某一数据时由于执行顺序不确定性以及中断的不可预知性，产生的数据不一致问题。该操作通过将内存中的值与指定数据进行比较，当数值一样时将内存中的数据替换为新的值

* 原理

  * 执行函数：CAS(V，E，N) ，CAS有3个操作数，内存值`V`，旧的期望值 `E`，要修改的新值 `N`。当且仅当预期值`E`和内存值`V`相同时（比较），它就认为这个期间没有人来访问过这个贡献资源，所以就把`V`值改为新值`N`（交换）
  * **如果多个线程同时使用CAS操作一个变量的时候，只有一个线程能够修改成功。其余的线程提供的期望值已经与共享变量的值不一样了，所以均会失败**
  * 由于CAS操作属于乐观派，它总是认为自己能够操作成功，所以操作失败的线程将会再次发起操作，而不是被OS挂起。所以说，即使CAS操作没有使用同步锁，其它线程也能够知道对共享变量的影响
  * 因为其它线程没有被挂起，并且将会再次发起修改尝试，所以无锁操作即CAS操作天生免疫死锁
  * **CAS是系统原语，CAS操作是一条CPU的原子指令（cmpxchg），这个指令是给数据总线进行加锁，所以不会有线程安全问题**

* 特点

  * CAS结合`volatile`可以实现无锁并发，**适用于线程数少，多核CPU场景下**(线程数不要超过CPU核数)
  * CAS是**基于乐观锁实现**（本身并无锁，区别于synchronized）
  * CAS体现的是**无锁并发、无阻塞并发**
    * CAS的原子性 + `volatile`的可见性，不断的【比较与交换】保证线程安全
    * 没有用锁来保证线程安全，所以不会阻塞
    * 如果竞争激烈，会导致**重试**频繁发生，效率下降

* 自旋–比较和交换

  * **自旋：** 就是不停的判断比较，看能否将值交换

  * 多个线程在访问共享资源的时候，会产生同步问题，所以需要加锁来保证安全。但是，一旦加了锁，同一时刻只能有一个线程获取锁对象，效率自然变低了

  * 不加锁的情况下来修改值，CAS是怎么自旋如下图

    <img src="imgs/os/cas.png" alt="cas" style="zoom: 67%;" />

  * 现在`Data`中存放的是`num=0`，线程A将`num=0`拷贝到自己的工作内存中计算（做+1操作）`E=0`，计算的结果为`V=1`

  * 由于是在多线程不加锁的场景下操作，所以可能此时`num`会被别的线程修改为其他值。此时需要再次读取`num`看其是否被修改，记再次读取的值为`N`

  * 如果被修改，即`E != N`，说明被其他线程修改过。那么此时工作内存中的E已经和主存中的`num`不一致了，根据EMSI协议，保证安全需要重新读取`num`的值。直到`E = N`才能修改

  * 如果没被修改，即`E = N`，说明没被其他线程修改过。那么将工作内存中的`E=0`改为`E=1`，同时写回主存。将`num=0`改为`num=1`

* CAS三大问题

  * **ABA问题**
    * CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。这就是CAS的ABA问题
    * 常见的解决思路是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么`A-B-A` 就会变成`1A-2B-3A`，由于每个过程值都会有对应的版本，所以我们在修改过程中需要传入期望版本和当前的值，数据库的多版本并发控制也类似
    * 添加时间戳：添加世时间戳也可以解决。查询的时候把时间戳一起查出来，对的上才修改并且更新值的时候一起修改更新时间，这样也能保证，方法很多但是跟版本号都是异曲同工之妙
  * 无限循环问题（自旋）
    * 如果CAS不成功，则会原地自旋，如果长时间自旋会**给CPU带来非常大且没必要的开销**
    * 可以使用java8中的LongAdder，分段CAS和自动分段迁移
    * 自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率
  * **只能保证一个共享变量的原子操作**
    * 只能保证一个共享变量的原子操作。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是**把多个共享变量合并成一个共享变量来操作**。比如有两个共享变量 i=2，j=a，合并一下 ij=2a，然后用CAS来操作
    * 可以用AtomicReference (java)，这个是封装自定义对象的，多个变量可以放一个自定义对象里，然后他会检查这个对象的引用是不是同一个。如果多个线程同时对一个对象变量的引用进行赋值，用AtomicReference的CAS操作可以解决并发冲突问题

## [IPC](https://mp.weixin.qq.com/s/b6HLr348-v7ibntuWs1yRA)

* 进程间通信(IPC)，[详见](https://www.cnblogs.com/zgq0/p/8780893.html)


### 管道

* 通常指无名管道，是 UNIX 系统IPC最古老的形式

* 它是**半双工**的（即数据只能在一个方向上流动），具有固定的读端和写端
* 它只能用于**具有亲缘关系的进程之间的通信**（也是父子进程或者兄弟进程之间）
* 它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并**不属于其他任何文件系统**，并且**只存在于内存**中
* 原型

```c
1 #include <unistd.h>
2 int pipe(int fd[2]);    // 返回值：若成功返回0，失败返回-1
```

### FIFO

* 也称为命名管道，它是一种文件类型

* FIFO可以在无关的进程之间交换数据，与无名管道不同
* FIFO有路径名与之相关联，它以一种**特殊设备文件形式存在于文件系统**中
* FIFO的通信方式类似于在进程中使用文件来传输数据，只不过FIFO类型文件同时具有管道的特性。**在数据读出时，FIFO管道中同时清除数据，并且“先进先出”**
* 原型

```c
1 #include <sys/stat.h>
2 // 返回值：成功返回0，出错返回-1
3 int mkfifo(const char *pathname, mode_t mode);
```

* 其中的` mode `参数与`open`函数中的 `mode `相同。一旦创建了一个 FIFO，就可以用一般的文件I/O函数操作它

  * 当 open 一个FIFO时，是否设置非阻塞标志（`O_NONBLOCK`）的区别：
    * 若没有指定`O_NONBLOCK`（默认），只读 open 要阻塞到某个其他进程为写而打开此 FIFO。类似的，只写 `open` 要阻塞到某个其他进程为读而打开它
    * 若指定了`O_NONBLOCK`，则只读` open `立即返回。而只写` open `将出错返回 -1 如果没有进程已经为读而打开该 FIFO，其`errno`置`ENXIO`。


### 消息队列

* **是消息的链接表，存放在内核中**。一个消息队列由一个标识符（即队列ID）来标识

* 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级
  * 消息队列独立于发送与接收进程。**进程终止时，消息队列及其内容并不会被删除**
  * **消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取,也可以按消息的类型读取**
  * 原型

```c
#include <sys/msg.h>
// 创建或打开消息队列：成功返回队列ID，失败返回-1
int msgget(key_t key, int fslag);
// 添加消息：成功返回0，失败返回-1
int msgsnd(int msqid, const void *ptr, size_t size, int flag);
// 读取消息：成功返回消息数据的长度，失败返回-1
int msgrcv(int msqid, void *ptr, size_t size, long type,int flag);
// 控制消息队列：成功返回0，失败返回-1
int msgctl(int msqid, int cmd, struct msqid_ds *buf);
```

* 在以下两种情况下，`msgget`将创建一个新的消息队列：

  - 如果没有与键值key相对应的消息队列，并且flag中包含了`IPC_CREAT`标志位。
  - key参数为`IPC_PRIVATE`。

  * 函数`msgrcv`在读取消息队列时，`type`参数有下面几种情况：
    * `type == 0`，返回队列中的第一个消息
    * `type > 0`，返回队列中消息类型为 `type` 的第一个消息
    * `type < 0`，返回队列中消息类型值小于或等于` type `绝对值的消息，如果有多个，则取类型值最小的消息
  * 可以看出，type值非 0 时用于以非先进先出次序读消息。也可以把` type` 看做优先级的权值

### [信号(signal)](https://blog.csdn.net/h___q/article/details/84245317)

* 信号是一种比较复杂的通信方式，**用于通知接收进程某个事件已经发生**

* 程序不可捕获、阻塞或忽略的信号有：**SIGKILL(9)，SIGSTOP(19)**

  - 它们向超级用户提供一种使进程终止或停止的可靠方法
  - 如果忽略某些由硬件异常产生的信号（例如非法存储访问或除以0），则进程的行为是未定义的

* 常见信号表

  ![signal_tab](imgs/os/signal_tab.png)

* 信号产生方式

  * [信号可以通过六个函数产生](https://www.jianshu.com/p/e4ce1f6488af):

    - **kill函数**
    - **raise函数**
    - **sigqueue函数**
    - **alarm函数**
    - **setitimer函数**
    - **abort函数**
    
  * 键盘产生
  
    * 如ctrl+c，ctrl+z，ctrl+/等
  
  * 程序异常
  
    * 除0错误。除0错误会导致硬件错误
    * core dumped（核心转储）：**当进程异常退出时，操作系统会将该进程发生异常退出之前在内存中的数据存储至硬盘上**
    * **2、9号信号不会产生core文件**
  
  * 使用kill命令
  
    * **kill 在无指定时默认发送2号信号，可将指定程序终止**。若仍无法终止该程序，可使用 SIGKILL(9) 信息尝试强制删除程序。程序或工作的编号可利用 ps 指令或 jobs 指令查看
  
    ```shell
    kill [-s <信息名称或编号>][程序]　或　
    kill [-l <信息编号>]
    
    -l <信息编号> 　若不加<信息编号>选项，则 -l 参数会列出全部的信息名称
    -s <信息名称或编号> 　指定要送出的信息
    [程序] 　[程序]可以是程序的PID或是PGID，也可以是工作编号
    
    最常用的信号是：
    1 (HUP)：重新加载进程
    9 (KILL)：杀死一个进程
    15 (TERM)：正常停止一个进程
    ```
  
  * 通过系统调用接口给特定进程发送信号
  
    ```c++
    #include<signal.h>
    
    int kill(pid_t pid, int signo);
    //向特定进程发送特定信号;成功返回0;失败返回-1
    
    int raise(int signo);
    //向当前进程发送特定信号;成功返回0;失败返回-1
    
    #include<stdlib.h>
    void abort(void);
    //使当前进程收到信号而异常终止；就像exit()函数一样，abort()函数总是会成功的，所以没有返回值
    ```
  
  * 由软件条件发送信号
  
    * SIGPIPE：SIGPIPE是一种由软件条件产生的信号，**当一个管道的读端被关闭时，这时候操作系统就会检测到该管道中写入的数据不会在有人来管道内读文件了，操作系统会认为该管道的存在会造成内存资源的极大浪费，则操作系统就会向写端对应的目标进程发送SIGPIPE信号**
  
    * 定时器
  
      ```c++
      #include<unistd.h>
      unsigned int alarm(unsigned int seconds);
      //调用alarm函数可以对当前进程设置一个闹钟，也就是告诉操作系统在seconds秒之后对当前进程发送SIGALRM信号，该信号的默认处理动作是终止当前进程
      ```
  
* **信号集操作函数**

  ```c++
  #include<signal.h>
  
  //注意：在使用sigset_t类型的变量前，一定要调用sigemptyset或sigfillset进行初始化，使信号集处于某种确定的状态，初始化之后就可以调用sigaddset或sigdelset在信号集中添加或删除某种有效信号
  
  int sigemptyset(sigset_t *set);
  //初始化set所指向的信号集，使其中所有信号对应的比特位清零，表示该信号集不包含任何信号
  
  int sigfillset(sigset_t *set);
  //初始化set所指向的信号集，将其中所有信号对应的比特位置1，表示该信号集的有效信号包括系统支持的所有信号
  
  int sigaddset(sigset_t *set, int signo);
  //表示将set所指向的信号集中的signo信号置1
  
  int sigdelset(sigset_t *set, int signo);
  //表示将set所指向的信号集中的signo信号清零
  
  int sigismember(const sigset_t *set, int signo);
  //用来判断set所指向的信号集的有效信号中是否包含signo信号，包含返回1，不包含返回0，出错返回-1
  
  int sigpending(sigset_t *set);
  // 获取进程的pending信号集
  // 成功返回0；失败返回-1
  ```

* **设置/修改进程的信号屏蔽字（block表）**

  ```c++
  #include<signal.h>
  
  int sigprocmask(int how, const sigset_t *set, sigset_t *oset);
  
  /*
    int how：
    	SIG_BLOCK：set包含了用户希望添加到当前信号屏蔽字的信号，即就是在老的信号屏蔽字中添加上新的信号。相当于：mask=mask|set
    	SIG_UNBLOCK：set包含了用户希望从当前信号屏蔽字中解除阻塞的信号，即就是在老的信号屏蔽字中取消set表中的信号。相当于：mask=mask&~set
    	SIG_SETMASK：设置当前进程的信号屏蔽字为set所指向的信号集。相当于：mask=set
    const sigset_t *set：
    	将要设置为进程block表的信号集
    sigset_t *oset：
    	用来保存进程旧的block表
    	若无需保存进程旧的block表，传递空指针即可
  */
  ```

* **自定义信号处理方式**

  ```c++
  #include<signal.h>
  
  struct sigaction
  {
      void (*sa_handler)(int);	//指向信号处理对应的函数
      void (*sa_sigaction)(int, siginfo_t *, void *);
      sigset_t sa_mask; //当在处理所收到信号时，想要附带屏蔽的其他普通信号，当不需要屏蔽其他信号时，需要使用sigemptyset初始化sa_mask
      int sa_flags;
      void (*sa_restorer)(void);
  };
  
  int sigaction(int signo, const struct sigaction *act, struct sigaction *oact);
  /*
  int signo：
  	指定的信号编号
  const struct sigaction *act：
  	若该act指针非空，则根据act指针来修改进程收到signo信号的处理动作
  struct sigaction *oact：
  	若oact指针非空，则使用oact来保存信号旧的处理动作
  */
  ```

* **信号处理过程**

  <img src="imgs/os/sig_cap.png" alt="sig_cap" style="zoom:80%;" />

* 信号接收

  * **接收信号的任务是由内核代理的，但内核接收到信号后，会将其放到对应进程的PCB的未决信号集中，同时向进程发送一个中断，使其陷入内核态**
  
* **此时信号只是在未决信号集中，对进程来说是不知道信号到来的**
  
* 信号的检测

  * 进程陷入内核后，**有两种场景会对信号集进行检测**：
    * 进程**从内核态返回到用户态前进行信号检测**
    * 进程在内核态中，**从睡眠状态被唤醒的时候进行信号检测**
  * 当发现有新信号后，便会进入下一步，信号处理

* 信号的处理

  * 如果用户**未注册信号处理函数**，则内核按照信号的**默认处理方式**处理
  * **如果用户注册了信号处理函数，则信号处理函数是运行在用户态的**，调用处理函数前，**内核会将当前内核栈的内容备份拷贝到用户栈上，并且修改指令寄存器(eip)将其指向信号处理函数**
  * **接下来进程返回到用户态中，执行相应的信号处理函数**
  * **信号处理函数执行完成后，还需要返回内核态，检查是否还有其他信号未处理**
  * **如果所有信号都处理完成了，就会将内核栈回复(从用户栈的备份拷贝回来)，同时恢复指令寄存器(eip)将其指向中断前的运行位置，最后回到用户态继续执行进程**
  * 如果同时有多个信号到达，处理流程为上面1，2，3，4步骤间重复进行，直到所有信号处理完毕

* **处理信号的时机**

  * 进程收到一个信号时，**并不会立即就去处理这个信号，而是先将收到的信号保存下来，并在合适的时候对信号进行处理**，**操作系统会在进程进入了内核态并从内核态返回用户态时，检测进程中可以进行处理的信号，并进行处理**

* 用户写好的代码会在什么情况下进入内核态呢？

  - 调用系统调用接口
  - 异常
  - 中断

### 信号量

* 与已经介绍过的 IPC 结构不同，它是**一个计数器**。信号量**用于实现进程间的互斥与同步，而不是用于存储进程间通信数据**

* 信号量用于进程间同步，若要在进程间传递数据需要结合共享内存
  * 信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作
  
  * 每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数
  
  * 支持信号量组
  
  * 原型
  
    ```c
    #include <sys/sem.h>
    // 创建或获取一个信号量组：若成功返回信号量集ID，失败返回-1
    int semget(key_t key, int num_sems, int sem_flags);
    // 对信号量组进行操作，改变信号量的值：成功返回0，失败返回-1
    int semop(int semid, struct sembuf semoparray[], size_t numops);  
    // 控制信号量的相关信息
    int semctl(int semid, int sem_num, int cmd, ...);
    ```
  
* 当`semget`创建新的信号量集合时，必须指定集合中信号量的个数（即`num_sems`），通常为1； 如果是引用一个现有的集合，则将`num_sems`指定为 0 。在`semop`函数中，`sembuf`结构的定义如下：

  ```
  struct sembuf 
  {
      short sem_num; // 信号量组中对应的序号，0～sem_nums-1
      short sem_op;  // 信号量值在一次操作中的改变量
      short sem_flg; // IPC_NOWAIT, SEM_UNDO
  }
  ```

* 其中` sem_op` 是一次操作中的信号量的改变量：

  - 若`sem_op > 0`，表示进程释放相应的资源数，将 sem_op 的值加到信号量的值上。如果有进程正在休眠等待此信号量，则换行它们
    - 若`sem_op < 0`，请求 `sem_op `的绝对值的资源
      - 如果相应的资源数可以满足请求，则将该信号量的值减去sem_op的绝对值，函数成功返回。
      - 当相应的资源数不能满足请求时，这个操作与`sem_flg`有关
        - `sem_flg `指定`IPC_NOWAIT`，则semop函数出错返回`EAGAIN`
        - `sem_flg` 没有指定`IPC_NOWAIT`，则将该信号量的`semncnt`值加1，然后进程挂起直到下述情况发生：
          1. 当相应的资源数可以满足请求，此信号量的`semncnt`值减1，该信号量的值减去sem_op的绝对值。成功返回；
          2. 此信号量被删除，函数`smeop`出错返回`EIDRM`；
          3. 进程捕捉到信号，并从信号处理函数返回，此情况下将此信号量的`semncnt`值减1，函数`semop`出错返回`EINTR`
    - 若`sem_op == 0`，进程阻塞直到信号量的相应值为0：
      - 当信号量已经为0，函数立即返回。
      - 如果信号量的值不为0，则依据`sem_flg`决定函数动作：
        - `sem_flg`指定`IPC_NOWAIT`，则出错返回`EAGAIN`。
        - `sem_flg`没有指定`IPC_NOWAIT`，则将该信号量的`semncnt`值加1，然后进程挂起直到下述情况发生：
          1. 信号量值为0，将信号量的`semzcnt`的值减1，函数`semop`成功返回；
          2. 此信号量被删除，函数`smeop`出错返回`EIDRM`；
          3. 进程捕捉到信号，并从信号处理函数返回，在此情况将此信号量的`semncnt`值减1，函数`semop`出错返回`EINTR`

  - 在`semctl`函数中的命令有多种，这里就说两个常用的：
    - `SETVAL`：用于初始化信号量为一个已知的值。所需要的值作为联合`semun`的`val`成员来传递。在信号量第一次使用之前需要设置信号量。
    - `IPC_RMID`：删除一个信号量集合。如果不删除信号量，它将继续在系统中存在，即使程序已经退出，它可能在你下次运行此程序时引发问题，而且信号量是一种有限的资源。

### 共享内存

* 指两个或多个进程共享一个给定的存储区

* **共享内存是最快的一种 IPC，因为进程是直接对内存进行存取**

* **因为多个进程可以同时操作，所以需要进行同步**

* **信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问**

* **共享内存实现原理**：共享内存是通过**把同一块内存分别映射到不同的进程空间**中实现进程间通信。而共享内存本身不带任何互斥与同步机制，但当多个进程同时对同一内存进行读写操作时会破坏该内存的内容，所以，在实际中，同步与互斥机制需要用户来完成

* 在**/proc/sys/kernel/**目录下，记录着共享内存的一些限制，如一个共享内存区的**最大字节数shmmax**，系统范围内最大共享内存区标识符数shmmni等，可以手工对其调整，但不推荐这样做

* 共享内存使用
  * 进程必须首先分配它
  * 随后需要访问这个共享内存块的每一个进程都必须将这个共享内存绑定到自己的地址空间中
  * 当完成通信之后，所有进程都将脱离共享内存，并且由一个进程释放该共享内存块

* 原型

  ```c
  #include <sys/shm.h>
  // 创建或获取一个共享内存：成功返回共享内存ID，失败返回-1
  int shmget(key_t key, size_t size, int flag);
  // 连接共享内存到当前进程的地址空间：成功返回指向共享内存的指针，失败返回-1
  void *shmat(int shm_id, const void *addr, int flag);
  // 断开与共享内存的连接：成功返回0，失败返回-1
  int shmdt(void *addr); 
  // 控制共享内存的相关信息：成功返回0，失败返回-1
  int shmctl(int shm_id, int cmd, struct shmid_ds *buf);
  ```

* 当用`shmget`函数创建一段共享内存时，必须指定其 size；而如果引用一个已存在的共享内存，则将 size 指定为0 
  * **当一段共享内存被创建以后，它并不能被任何进程访问。必须使用`shmat`函数连接该共享内存到当前进程的地址空间，连接成功后把共享内存区对象映射到调用进程的地址空间，随后可像本地空间一样访问**
  * `shmdt`函数是用来断开`shmat`建立的连接的。注意，**这并不是从系统中删除该共享内存，只是当前进程不能再访问该共享内存而已**
  * `shmctl`函数可以对共享内存执行多种操作，根据参数 cmd 执行相应的操作。常用的是`IPC_RMID`（从系统中删除该共享内存）

* **mmap实现共享内存**
  
  * mmap系统调用并不是完全为了用于共享内存而设计的。它本身提供了不同于一般对普通文件的访问方式，进程可以像读写内存一样对普通文件的操作。而Posix或系统V的共享内存IPC则纯粹用于共享目的，**当然mmap()实现共享内存也是其主要应用之一**
  * **mmap系统调用使得进程之间通过映射同一个普通文件实现共享内存**。普通文件被映射到进程地址空间后，进程可以像访问普通内存一样对文件进行访问，不必再调用read()，write（）等操作。
  * mmap并不分配空间，只是**将文件映射到调用进程的地址空间里**，然后你就可以用memcpy等操作写文件，而不用write()了。写完后用msync()同步一下，你所写的内容就保存到文件里了。 **不过这种方式没办法增加文件的长度**，**因为要映射的长度在调用mmap()的时候就决定了**
  * 简单说就是把一个文件的内容在内存里面做一个映像，内存比磁盘快些

## 线程间通信

* 线程是共享同一进程的地址空间的，拟线程间的通信将会很容易，直接就可以通过全局变量来交换数据。但这种访问的便利性也带来了一些风险，通常当有多个线程访问相同的共享数据时需要**同步**或**互斥锁**

* 线程同步：同步指的是多个任务按照事先约定的顺序先后地完成一件事情

* 线程间同步机制

  * 互斥量

    * 互斥量是最基础的加锁原语。**确保同一时间只有一个线程访问数据**，**通过在访问共享资源前对互斥量加锁，阻塞其他试图再次加锁的线程直到互斥锁被释放**。互斥的具体实现有多种方法，例如开关中断，使用原子的机器指令

    * 互斥量常用函数

      ```c++
      #include <pthread.h>
      pthread_mutex_t mutex=PTHREAD_MUTEX_INITIALIZER;
      // 定义互斥量
      int pthread_mutex_init(pthread_mutex_t *__mutex,__const pthread_mutexattr_t *__mutexattr);
      // 初始化互斥量，使用第二互斥量来初始化第一个互斥量，如果第二个为空，则使用默认参数初始化互斥量,也可以使用宏来初始化
      
      int pthread_mutex_destroy(pthread_mutex_t *__mutex);
      // 功能：销毁互斥量
      // 注意：互斥量是一个结构体，里面有成员是指针，指向了堆内存数据，需要显式初始化函数以及销毁函数。
      // 如果使用堆内存存储互斥量，需要在调用了销毁函数后，再进行free
      
      int pthread_mutex_lock(pthread_mutex_t *__mutex);
      // 功能：锁定互斥量，当互斥量是锁定状态，此函数则阻塞（直到互斥量在其它线程中解锁，调用者者线程加锁成功才返回）
      // 注意：互斥量一旦加锁，只有它自己能解
      
      int pthread_mutex_trylock(pthread_mutex_t *__mutex);
      //  功能：尝试锁定互斥量，能锁就锁，不能锁就立即返回，不阻塞线程
      
      int pthread_mutex_timedlock (pthread_mutex_t *__restrict __mutex,const struct timespec *__restrict_abstime);
      // 功能：在指定时间内锁定一个互斥量(使用的系统时间)。
      struct timespec
      {
        	time_t tv_sec;        /* Seconds.  */
        	long int tv_nsec;       /* Nanoseconds.  */
      };
      
      int pthread_mutex_unlock (pthread_mutex_t *__mutex);
      // 功能：解锁
      ```

  * **自旋锁** 

    * 自旋锁与互斥量类似，在任何时刻同样只能有一个线程访问对象。但是**当获取锁操作失败时，不会进入睡眠，而是会在原地自旋**，循环检测锁的保持者是否释放，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源

  * **屏障** 

    * 屏障主要用于多个线程之间的并行工作的协调。**屏障允许每个线程等待，直到所有的合作线程都达到某个点，然后从该点继续执行**

  * 信号量

    * 信号量可以决定线程当前是继续运行还是等待

    * 信号量代表某一类资源，其值表示系统中该资源的数量。因此它是一个非负数的值

    * 信号量是一个受保护的变量，只能通过三种操作来访问：

      * 初始化
      * P操作（申请资源）
        * 当进行P操作时，它会去**判断当前信号量的值是否大于0**，**若是，则申请P操作的任务继续运行，同时信号量的值减一**。**若否，则阻塞**
      * V操作（释放资源）
        * V操作则是**先让信号量的值加一**，**再判断当前是否有正在等待资源的任务以让它继续运行**

    * pthread库信号量常用函数

      ```c++
      #include <semaphore.h>
      
      int sem_init(sem_t *sem, int pshared, unsigned int value); // 信号量的初始化。
      // 执行成功返回0，失败返回EOF，并设置 errno。第一个参数指向要初始化的信号量对象第二个参数表示是进程间还是线程间，0表示线程间，1表示进程间。第三个参数则是信号量的初值了
      
      int sem_wait(sem_t *sem); // P操作
      
      int sem_post(sem_t *sem); // V操作
      ```

  * 条件变量

    * 条件变量是一种“事件通知机制”，它本身不提供、也不能够实现“互斥”的功能。因此，条件变量通常（也必须）配合互斥量来一起使用，其中互斥量实现对“共享数据”的互斥（即同步），而条件变量则去执行 “通知共享数据状态信息的变化”的任务。比如通知队列为空、非空，或任何其他需要由线程处理的共享数据的状态变化

    * 条件变量原则

      * 等待条件变量总是返回被锁住的互斥量
      * 条件变量的作用是发信号，而不是互斥
      * 一个条件变量应该只与一个“状态描述（也有称呼为“谓词”，所谓谓词，即：描述代码所需不变量的状态的语句）”相关联
      * 所有并发地（同时）去等待一个条件变量的线程必须指定同一个“互斥量”
      * 条件变量提供了“信号单播（signal，注意：这里的所谓信号并非Linux下的SIGxxx）”和“信号广播(broadcast)”两种方式，**基于更安全、高效等因素，优先考虑使用“广播信号”方式**
      * 注意区分signal和broadcast：“**broadcast通常用于表明状态变化，signal通常用于表示资源可用**”
      * 线程发信号或广播条件变量时候看到的内存数据，同样也可以被唤醒的其他线程看到。而在发信号或广播之后写入内存的数据不会被唤醒的线程看到，即使写操作发生在线程被唤醒之前
      * 一个内存地址一次只能保持一个值；不要让线程竞争以优先获得访问权
      * 在等待线程醒来时候，检查其“状态”是否为真是个不错的主意；**同时应该总是在一个循环中等待条件变量**(防止伪唤醒，spurious wakeup)
      * 条件变量是程序用来等待某个“状态”为真的机制

    * 条件变量常用函数

      ```c++
      #include <pthread.h>
      
      /**@fn            pthread_cond_init
       * @brief         初始化条件变量cond(attr创建可选的条件变量属性)
       * @param[in]     pthread_cond_t *cond 条件变量   
       * @param[in]     pthread_condattr_t *attr 条件变量高级属性
       * @param[out]    NONE
       * @description   常见错误码：[ENOMEN]内存不足,[EAGAIN]资源不足,[EBUSY]cond已经初始化,[EINVAL]attr无效
       * @return        int
      **/
      int pthread_cond_init (pthread_cond_t *cond,
      			      const pthread_condattr_t *attr);
          
      /**@fn            pthread_cond_signal
       * @brief         信号通知条件变量cond，唤醒一个等待者
       * @param[in]     pthread_cond_t *cond  待唤醒的条件变量
       * @param[out]    NONE
       * @description   常见错误码：[EINVAL] cond无效。
       * @return        int
      **/
      int pthread_cond_signal (pthread_cond_t *cond);
      	
      /**@fn            pthread_cond_broadcast
       * @brief         广播条件变量(唤醒所有等待该条件变量的线程,即等待者)
       * @param[in]     pthread_cond_t *cond 条件变量   
       * @param[out]    NONE
       * @description   常见错误码：[EINVAL] cond无效
       * @return        int
      **/
      int pthread_cond_broadcast (pthread_cond_t *cond);
      	
      /**@fn            pthread_cond_timedwait
       * @brief         等待条件变量被唤醒(等待条件变量cond被唤醒,直到由一个信号或广播，或绝对时间abstime到
       *				  才唤醒该线程)
       * @param[in]     pthread_cond_t *cond   条件变量 
       * @param[in]     pthread_mutex_t *mutex 互斥量 
       * @param[in]     const struct timespec *abstime 等待被唤醒的绝对超时时间  
       * @param[out]    NONE
       * @description   常见错误码：[EINVAL] 同时等待不同的互斥量；/cond,mutex/abstime无效；互斥量没有被主线程占有    
       *             	  [ETIMEDOUT] abstime指定绝对时间超时 
       * @return        int
      **/
      int pthread_cond_timedwait (pthread_cond_t  *cond,
      							pthread_mutex_t *mutex,
      							const struct timespec *abstime);
      	
      /**@fn            pthread_cond_wait
       * @brief         等待条件变量cond被唤醒(由一个信号或者广播)
       * @param[in]     pthread_cond_t *cond   条件变量 
       * @param[in]     pthread_mutex_t *mutex 互斥量 
       * @param[out]    NONE
       * @description   常见错误码：[EINVAL] cond或mutex无效, [EINVAL] 同时等待不同的互斥量 [EINVAL] 主调线程没有占有互斥量
       * @return        int
      **/	
      int pthread_cond_wait (pthread_cond_t *cond,
      					   pthread_mutex_t *mutex);
      
      /**@fn            pthread_cond_destroy
       * @brief         释放/销毁条件变量
       * @param[in]     pthread_cond_t *cond 待销毁的条件变量 
       * @param[out]    NONE
       * @description   常见错误码：[EBUSY] cond正在使用 [EINVAL]cond无效
       * @return        int
      **/	
      int pthread_cond_destroy (pthread_cond_t *cond)
      
      ```


# 内存管理

* [详见1](http://mp.weixin.qq.com/s?__biz=MzIwNTc4NTEwOQ==&mid=2247491042&idx=1&sn=6a27149508df23d5414d279feac1c304&chksm=972acc98a05d458e5a147f1fd8306ca4f384903ec5b18560b67b15849f43942e60563f0ce5bf&mpshare=1&scene=24&srcid=0321sCT49uCvhw9cMJGzFOic&sharer_sharetime=1616262001659&sharer_shareid=0722ed5128948b6436f8552f291f9b0b#rd)

## 虚拟内存

* 虚拟内存概念
  * 虚拟内存技术是操作系统的一种扩容技术，它使得不同进程在运行过程中，它所看到的是**自己独自占有了当前系统的4G内存**。所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。 
  * 事实上，在每个进程创建加载时，内核只是为进程“创建”了虚拟内存的布局，具体就是初始化进程控制表中内存相关的链表，**实际上并不立即就把虚拟内存对应位置的程序数据和代码**（比如.text .data段）**拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好**（叫做存储器映射），**等到运行到对应的程序时，才会通过缺页异常，来拷贝数据**
  * 还有进程运行过程中，要动态分配内存，比如**malloc时，也只是分配了虚拟内存**，即为这块虚拟内存对应的页表项做相应设置，**当进程真正访问到此数据时，才引发缺页异常**
  * 请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换
* **虚拟内存的好处**
  * 扩大地址空间
  * **内存保护**：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改
  * 公平内存分配。采用了虚存之后，每个进程都相当于有同样大小的虚存空间
  * 当进程通信时，可采用虚存共享的方式实现
  * **方便内存映射：当不同的进程使用同样的代码时，比如动态库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存。还有COW**
  * 虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高
  * **惰性分配**：在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，首次使用这块内存时才分配物理内存，可以利用碎片
* **虚拟内存的代价**
  * **虚存的管理需要建立很多数据结构(如页表等)，这些数据结构要占用额外的内存**
  * **虚拟地址到物理地址的转换，增加了指令的执行时间**
  * **页面的换入换出需要磁盘I/O，这是很耗时的**
  * 如果一页中只有一部分数据，会浪费内存
* 颠簸(thrashing)
  * 分页(Page)写入磁盘的过程被称作Page-Out，分页(Page)从磁盘重新回到内存的过程被称作Page-In。当内核需要一个分页时，但发现此分页不在物理内存中(因为已经被Page-Out了)，此时就发生了分页错误（Page Fault）
  * 当系统内核发现**可运行内存变少**时，就会通过Page-Out来释放一部分物理内存。经管Page-Out不是经常发生，但是如果**Page-out频繁不断的发生**，直到当内核管理分页的时间超过运行程式的时间时，**系统效能会急剧下降**。这时的**系统已经运行非常慢或进入暂停状态**，这种状态亦被称作thrashing(颠簸)
  * 解决策略
    * 如果是因为页面置换策略失误，可以修改置换算法来解决这个问题
    * 如果是因为运行的程序太多，造成程序无法同时将所有频繁访问的页面调入内存，则要降低多道程序的数量
    * 否则，还剩下两个办法：1. 终止该进程；2. 增加物理内存容量
* TLB
  * TLB( Translation Look- aside buffer)**专门用于缓存内存中的页表项**，一般**在MMU单元内部**，页表一般存储在物理内存中。**当处理器要访问一个虚拟地址时，首先会在TLB中查询**。如果TLB表项中没有相应的表项，称为TLB Miss，那么就需要访问页表来计算出相应的物理地址。如果TLB表项中有相应的表项，那么直接从TLB表项中获取物理地址，称为TLB命中

## 缺页中断

* 在请求分页系统中，可以**通过查询页表中的状态位来确定所要访问的页面是否存在于内存中**。每当所要访问的页面不在内存时(缓存不命中)，会产生一次缺页中断，此时**操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存**
* 缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤
  * 保护CPU现场
  * 分析中断原因
  * 转入缺页中断处理程序进行处理
  * 恢复CPU现场，继续执行
* 但是缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，**与一般的中断存在区别**
  * **在指令执行期间产生和处理缺页中断信号**
  * **一条指令在执行期间，可能产生多次缺页中断**
  * **缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令**

* 缺页中断就是要访问的页不在主存，需要操作系统将其调入主存后再进行访问
  当进程执行过程中发生缺页中断时，需要进行页面换入，步骤如下：
  1. 首先**硬件会陷入内核，在堆栈中保存程序计数器。大多数机器将当前指令的各种状态信息保存在CPU中特殊的寄存器中**
  2. 启动一个汇编代码例程保存通用寄存器及其它易失性信息，以免被操作系统破坏。这个例程将操作系统作为一个函数来调用。（在页面换入换出的过程中可能会发生上下文换行，**导致破坏当前程序计数器及通用寄存器中本进程的信息**）
  3. 当操作系统发现是一个页面中断时，查找出来发生页面中断的虚拟页面（进程地址空间中的页面）。这个虚拟页面的信息通常会保存在一个硬件寄存器中，如果没有的话，操作系统必须检索程序计数器，取出这条指令，用软件分析该指令，通过分析找出发生页面中断的虚拟页面
  4. **检查虚拟地址的有效性及安全保护位。如果发生保护错误，则杀死该进程**
  5. 操作系统查找一个**空闲的页框**(物理内存中的页面)，如果**没有空闲页框则需要通过页面置换算法找到一个需要换出的页框**
  6. **如果找的页框中的内容被修改了，则需要将修改的内容保存到磁盘上**，此时会引起一个写磁盘调用，发生上下文切换（在等待磁盘写的过程中让其它进程运行）（注：此时需要将页框置为忙状态，以防页框被其它进程抢占掉）
  7. 页框干净后，操作系统根据虚拟地址对应磁盘上的位置，将保持在磁盘上的页面内容复制到“干净”的页框中，此时会引起一个读磁盘调用，发生上下文切换
  8. 当磁盘中的页面内容全部装入页框后，向操作系统发送一个中断。操作系统更新内存中的页表项，将虚拟页面映射的页框号更新为写入的页框，并将页框标记为正常状态
  9. 恢复缺页中断发生前的状态，将程序指令器重新指向引起缺页中断的指令
  10. 调度引起页面中断的进程，操作系统返回汇编代码例程
  11. 汇编代码例程恢复现场，**将之前保存在通用寄存器中的信息恢复**

* 缺页中断的过程涉及了**用户态和内核态之间的切换**，**虚拟地址和物理之间的转换**（这个转换过程需要使用MMU和TLB）

## 页面置换算法

* 为提高内存利用率，解决内存供不应求的问题，更加合理的使用内存，人们创造了**分页式内存抽象**。同时有一个**虚拟内存**的概念，是指将内存中暂时不需要的部分写入硬盘，看上去硬盘扩展了内存的容量，所以叫做“虚拟”内存。使用虚拟内存，应用程序可以使用比实际物理内存更大的内存空间。可以认为这个更大的内存空间就在硬盘上，只有将某一部分需要被用到时，才被写入真实内存；当它暂时不再被用到时，又被写回硬盘。分页式内存管理将物理内存分为等大的小块，每块大小通常为1K、2K、4K等，称为**页帧；**逻辑内存（使用虚拟内存技术扩大的内存，可认为其位于硬盘上）也被分为等大的小块，称为**页**；且**页和页帧**的大小一定是一样的，它是写入真实内存和写回硬盘最小单位
* 重要概念：
  * 使用位：每个页帧都有一个使用位，记录此页帧是否被使用
  * 修改位（脏位）：每个页帧都有一个脏位，记录此页帧是否被更改。调出真实内存时，被更改过的页帧要写回硬盘，未被更改过的页帧直接扔掉即可，因为硬盘上此页帧的副本仍然有效
  * 逻辑地址：使用虚拟内存技术扩大后的内存的地址
  * 物理地址：真实内存的地址
* 当然，进程载入到真实内存才可以运行，而进程代码使用的是逻辑地址，所以牵扯到一个**地址转换**的问题，将逻辑地址转换为物理地址。逻辑地址可分为两段，前半段代表页号，后半段代表页内偏移，物理地址也可分为两段，前半段代表页帧号，后半段代表页内偏移。地址转换的方法即，将逻辑地址的页号对应为物理地址的页帧号（对应关系记录在一张表中，比如页号为5，对应到真实内存中页帧号为3），页内偏移不同变化（页和页帧的大小是一样的）

假设某一时刻内存页帧已经被写满了，但这时又需要将一个页写到物理内存中，就需要将原本在物理内存中的某一页换出来。如果置换不当，就会导致刚刚被换出到硬盘的页又要被写回内存，减慢系统运行的速度。页面置换算法就是考虑将哪一页换出来以获得优良性能的方法。

### Optimal算法（最优算法）

　　首先介绍最优算法，它需要知道以后要被用到的页，然后将不会被用到的页换出内存；如果所有页都会被用到，就把需要使用时间离现在最长的页换出，以尽量使不好的情况晚发生。这种方法能使系统获得最佳性能，但是，它是不可能实现的......因为当前无法获知以后哪些页要被用到。不过最优算法还是能够作为其他算法优秀程度的衡量

### FIFO（First-In First-Out，先进先出）算法

　　FIFO算法的思想很简单，就是置换出当前已经待在内存里时间最长的那个页。FIFO算法的运行速度很快，不需要考虑其他的因素，需要的开销很少。但是正是由于没有考虑页面的重要性的问题，FIFO算法很容易将重要的页换出内存

### Second Chance（二次机会）算法

　　为了避免FIFO算法将重要的页换出内存，Second Chance算法提供了一些改进。Second Chance算法在**将页面换出内存前检查其使用位（使用位前文有介绍），如果其使用位为1，证明此页最近有被使用，猜测它还可能被使用，于是不把它置换出内存，但是把其使用位置为0，随后检查下一个页面，直到发现某页的使用位为0，将此页置换出内存**

### Clock算法（时钟轮转法）

　　为了节约Second Chance算法一个接着一个检查使用位的开销，时钟轮转法又提出了改进。**时钟轮转法将所有的页组成一个圆**，圆心的指针指向下一个要被置换的页面，**置换前同样检查使用位，如果使用位为1，同样将其使用位置为0，随后将顺指针旋转，检查下一个页面，直到发现某页的使用位为0，将此页置换出内存**。很容易理解此算法为什么叫“时钟”轮转法

### LRU（Least Recent Used, 最近最少使用）算法

　　为获得对最优算法的模拟，提出了LRU算法。由于当前时间之后需要用到哪些页无法提前获知，于是记录当前时间之前页面的使用情况，认为之前使用过的页面以后还会被用到。在置换时，将最近使用最少的页面换出内存。此种方法的开销比较大

### NRU（Not Recent Used， 最近未使用）算法

　　前面提到修改位和使用位，NRU算法利用这两个标志位将所有页帧分为4组：

　　	第0组：修改位和使用位都为0；

　　	第1组：修改位为0，使用位为1；

　　	第2组：修改位为1，使用位为0；

　　	第3组：修改位和使用位都为1。

　　NRU算法从组数最小的一组中随机选择一个页面将其移出内存。可能有人会发现第2组这种情况根本不会出现，如果一个页帧被修改，其修改位会被置1，同时它也被使用了，其使用位也会被置1；即不会出现被修改但是没有被使用的情况。真实情况是，页帧的使用位会被定时清零，这样第3组经过一次清零就会变成第2组。这也符合“最近”未使用，即很久以前被使用的页帧被清零了，不在统计范围内，只要“最近”没有被使用，就很有可能被移出。

　　NRU算法不是最好的，但是它使用起来开销很小，用较小的代价就得到了不错的效果，不失为一种不错的算法
