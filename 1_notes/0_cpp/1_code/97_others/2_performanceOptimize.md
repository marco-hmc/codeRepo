## 性能优化

### 1. concepts
#### 1.1 这些是一些常见操作的成本的数量级的概念:
时钟频率表示CPU每秒钟可以执行的周期数。时钟频率越高，CPU每秒钟可以执行的周期数就越多，处理速度也就越快。现代家用CPU的时钟频率通常在几GHz范围内。例如，3 GHz的CPU表示每秒钟有30亿个周期。

以3 GHz的CPU为例：
$ T = 1/f $
$ T= 1/(3*10e9)=1/3 ns $

时间单位换算：
1 s = 10e3 ms = 10e6 μs = 10e8 ns

| 操作类型                                   | CPU时钟周期范围 | 时间范围（纳秒）    |
|------------------------------------------|------------|----------------|
| 简单寄存器-寄存器操作（例如 ADD、OR 等）       | <1         | <3ns            |
| 内存写入                                   | 1          | 3ns             |
| 绕过延迟：在整数和浮点单元之间切换           | 0-3        | 0-9ns           |
| 正确的 if 分支                               | 1-2        | 3-6ns           |
| char的比较                                | 1-3        | 3-6ns           |
| 浮点/向量加法                                | 1-3        | 3-9ns           |
| 乘法（整数/浮点/向量）                       | 1-7        | 3-21ns          |
| 返回错误和检查                               | 1-7        | 3-21ns          |
| L1 缓存读取                                 | 3-4        | 9-12ns          |
| TLB 未命中                                  | 7-21       | 21-63ns         |
| L2 缓存读取                                 | 10-12      | 30-36ns         |
| 错误的 if 分支（分支错误预测）                 | 10-20      | 30-60ns         |
| 浮点除法                                   | 10-40      | 30-120ns        |
| 128 位向量除法                              | 10-70      | 30-210ns        |
| 原子操作/CAS                               | 15-30      | 45-90ns         |
| C 函数直接调用                              | 15-30      | 45-90ns         |
| 整数除法                                   | 15-40      | 45-120ns        |
| C 函数间接调用                              | 20-50      | 60-150ns        |
| C++ 虚函数调用                              | 30-60      | 90-180ns        |
| L3 缓存读取                                 | 30-70      | 90-210ns        |
| 主内存读取                                  | 100-150    | 300-450ns       |
| NUMA（不同插槽的原子操作/CAS，估计值）         | 100-300    | 300-900ns       |
| NUMA（不同插槽的 L3 缓存读取）                | 100-300    | 300-900ns       |
| 分配+释放配对（小对象）                       | 200-500    | 600-1500ns      |
| NUMA（不同插槽的主内存读取）                  | 300-500    | 900-1500ns      |
| 内核调用                                   | 1000-1500  | 3-4.5μs     |
| 线程上下文切换（直接成本）                    | 2000       | 6μs         |
| C++ 异常抛出并捕获                           | 5000-50000 | 15-150μs  |
| 线程上下文切换（总成本，包括缓存失效）         | 10000 - 100万 | 30μs - 3ms |
| 磁盘访问（SSD）                              | 100000 - 1000000 | 30μs - 300μs |
| 磁盘访问（HDD）                              | 1000000 - 10000000 | 300μs - 3ms |
| 线程创建                                    | 1000000 - 10000000 | 300μs - 3ms |
| 线程销毁                                    | 1000000 - 10000000 | 300μs - 3ms |
| 网络消息（本地网络）                          | 100000 - 1000000 | 30μs - 300μs |
| 网络消息（广域网）                            | 1000000 - 1000000000 | 300μs - 300ms |

#### 1.2 优化原则
1. **二八原则**：
   - 80% 的性能问题通常来自 20% 的代码。
2. **先正确运行，再优化**：
   - 确保程序正确运行，然后再进行性能优化。
3. **不要太提前优化**：
   - 避免过早优化，先确保代码的正确性和可维护性。
4. **优化需要数据支持**：
   - 进行性能优化时需要有数据支持，编译器的优化能力很强，看上去有效的优化不一定实际有效。

#### 1.3 代码优化主要思路
* **性能优化原则**
  1. **二八原则**：
    - 80% 的性能问题通常来自 20% 的代码。
  2. **先正确运行，再优化**：
    - 确保程序正确运行，然后再进行性能优化。
  3. **不要太提前优化**：
    - 避免过早优化，先确保代码的正确性和可维护性。
  4. **优化需要数据支持**：
    - 进行性能优化时需要有数据支持，编译器的优化能力很强，看上去有效的优化不一定实际有效。

* **CPU 密集任务**
  1. **多线程**：
    - 使用多线程并行化计算任务，充分利用多核处理器的计算能力。
    - 使用 `wait` 机制协调线程间的同步。
  2. **优化算法实现**：
    - 避免不必要的递归，使用迭代替代递归。
    - 避免不必要的参数复制，使用引用传递参数。
    - 避免不必要的计算，减少重复计算。
    - 正确使用高效的算法和数据结构。

* **I/O 密集任务**
  1. **内存 I/O 密集**：
    - 使用对象池，避免重复构造和销毁对象。
    - 优化内存访问模式，使用顺序访问提高缓存命中率。
  2. **硬盘 I/O 密集**：
    - 使用异步 I/O 操作，允许程序在等待 I/O 操作完成时继续执行其他任务。
    - 使用缓存减少磁盘 I/O 操作，提高效率。
    - 使用高效的文件系统和磁盘调度算法。
  3. **网络 I/O 密集**：
    - 使用异步网络 I/O 操作，提高并发性和效率。
    - 使用高效的网络协议，减少网络延迟。
    - 使用压缩减少传输的数据量，提高传输效率。

#### 1.4 代码实现常见原则
* **硬件友好代码**
  1. **利用 SIMD 特性**：
    - 现在的 CPU 很多时候都可以对指令并行化，利用 SIMD（Single Instruction, Multiple Data）特性进行向量化计算，提高并行计算性能。
  2. **提升缓存利用率**：
    - 使用结构化数组（SoA）和数组结构（AoS）方式优化数据布局，提高缓存命中率。
    - 避免缓存未命中，优化内存访问模式，使用顺序访问提高缓存命中率。

#### 1.5 性能优化常见手段
* 对象池
* 线程池
* 内存池
* 缓存


* **3. 编译器优化**
#### 3.1 pgo
PGO,全称为 Profile-Guided Optimization(基于分析的优化),是一种编译器优化技术,它通过收集程序运行时的性能信息来指导编译器优化.

PGO 的工作流程通常包括以下几个步骤:
1. **编译**:首先,你需要使用特殊的编译器选项来编译你的程序,这会使得程序在运行时收集性能信息.
2. **运行**:然后,你需要运行你的程序,并让它处理一些典型的工作负载.这会生成一个性能分析文件,其中包含了程序运行时的性能信息.
3. **优化编译**:最后,你需要再次使用特殊的编译器选项来编译你的程序,这次编译器会使用性能分析文件中的信息来指导优化.

通过这种方式,编译器可以了解到程序的实际运行情况,例如哪些代码经常被执行,哪些代码很少被执行,哪些条件分支的预测结果通常是什么等等.然后,编译器可以使用这些信息来进行更有效的优化,例如更精确地进行内联,更智能地安排代码布局,更准确地预测条件分支等等.

PGO 可以显著提高程序的运行速度,特别是对于那些性能敏感的应用程序.然而,PGO 也有一些缺点,例如它会增加编译时间和编译复杂性,因此并不是所有的项目都适合使用 PGO.


### 缓存
* 减少内存访问延迟：cpu缓存
* 减少磁盘IO读写延迟：文件缓存
* 减少数据库查询延迟：数据库缓存
* 减少网络IO读写延迟：web缓存/ 代理服务器缓存/ CDN缓存
* 减少cpu计算延迟：cacheData

### 如何解决缓存空间受限问题
缓存为了快速访问一般都是通过哈希表的方式存储。
但当需要限制缓存空间大小的时候，即数据会不断增加，但缓存空间有限，就需要考虑那些缓存的数据需要被淘汰。
常见的淘汰方法有这些。
* LRU（Least Recently Used）：移除最近最少使用的数据。
* LFU（Least Frequently Used）：移除使用频率最低的数据。
* FIFO（First In First Out）：移除最早进入缓存的数据。