# 多线程

## 1. concepts

### 1.1 C++多线程的主要关键字
c++关于多线程开发的关键字可以有以下分类：

* **创建和管理线程或异步任务:**
  * thread
    * 需要直接控制线程的生命周期：当你需要精细控制线程的创建、启动、暂停、恢复和终止时，使用std::thread是合适的选择。
    * 需要共享资源的复杂同步：当多个线程需要访问共享资源，并且需要复杂的同步机制（如互斥锁、条件变量）时，std::thread提供了更大的灵活性。
    * 需要高性能：在某些高性能计算场景中，直接使用std::thread可以避免一些抽象层带来的开销。
  * async
    * 简单的异步任务：当你需要启动一个简单的异步任务，并且不需要显式管理线程时，使用std::async是最方便的选择。
    * 任务的启动策略：当你希望任务可以根据需要立即执行或延迟执行时，std::async提供了灵活的启动策略
      （如std::launch::async和std::launch::deferred）。
    * 需要返回值的异步任务：当你需要启动一个异步任务并获取其返回值时，std::async会返回一个std::future对象，方便获取结果。
  * packaged_task
    * 需要更高的灵活性：当你需要将任务与线程分离，并在不同的时间和上下文中启动任务时，使用std::packaged_task是合适的选择。
    * 复杂的任务管理：当你需要显式管理任务的生命周期，并且可能需要将任务传递给其他线程或存储在容器中时，std::packaged_task提供了更高的灵活性。
    * 需要返回值的任务：与std::async类似，std::packaged_task也会返回一个std::future对象，用于获取任务的结果。
> **使用thread**：当你需要直接控制线程的生命周期和同步机制时。
> **使用async**：当你需要启动简单的异步任务，并且希望任务的启动策略灵活时。
> **使用packaged_task**：当你需要更高的灵活性来管理任务的生命周期，并且可能需要将任务传递或存储时。

* **用于线程间的同步和通信，确保线程安全:**
  * promise-future/shared-future
    * 线程之间的值传递
  * atomic
    * 原子操作
  * mutex
    * 互斥锁
  * condition_variable
    * 信号量


### 1.2 线程安全
* 线程安全的概念
  * 多个线程访问同一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他操作，调用这个对象的行为都可以获得正确的结果，那么这个对象就是线程安全的
  * 或者说：**一个类或者程序所提供的接口对于线程来说是原子操作或者多个线程之间的切换不会导致该接口的执行结果存在二义性，也就是说我们不用考虑同步的问题**
  * **线程安全问题大多是由全局变量及静态变量引起的，局部变量逃逸也可能导致线程安全问题**
  * 若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全
  * 类要成为线程安全的，**首先必须在单线程环境中有正确的行为**。如果一个类实现正确(这是说它符合规格说明的另一种方式)，那么没有一种对这个类的对象的操作序列(读或者写公共字段以及调用公共方法)可以让对象处于无效状态，观察到对象处于无效状态、或者违反类的任何不可变量、前置条件或者后置条件的情况
  * 此外，一个类要成为线程安全的，在被多个线程访问时，不管运行时环境执行这些线程有什么样的时序安排或者交错，它必须仍然有如上所述的正确行为，并且在调用的代码中没有任何额外的同步。其效果就是，在所有线程看来，对于线程安全对象的操作是以固定的、全局一致的顺序发生的
  * 正确性与线程安全性之间的关系非常类似于在描述 ACID(原子性、一致性、独立性和持久性)事务时使用的一致性与独立性之间的关系：从特定线程的角度看，由不同线程所执行的对象操作是先后(虽然顺序不定)而不是并行执行的
  * 简单理解，确保在多线程访问的时候，我们的程序还能按照我们预期的行为去执行，那么就是线程安全

* 并发编程中的三大性质

  * 原子性：即一个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。原子性就像数据库里面的事务一样，他们是一个团队，同生共死
  * 可见性：指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。**volatile可以保证可见性**，当一个变量被volatile修饰后，表示着线程本地内存无效，当一个线程修改共享变量后他会立即被更新到主内存中，当其他线程读取共享变量时，它会直接从主内存中读取。**volatile也可以保证线程可见性且提供了一定的有序性，但是无法保证原子性**
  * 有序性：即程序执行的顺序**按照代码的先后顺序执行**。为了效率，C++或Java允许编译器和处理器对指令进行重排序，当然重排序它不会影响单线程的运行结果，但是对多线程会有影响。volatile可以保证一定的有序性

* 非阻塞同步（乐观锁）

  * 随着硬件指令集的发展，出现了基于冲突检测的乐观并发策略，通俗地说，**就是先进行操作，如果没有其他线程争用共享数据，那操作就成功了**；**如果共享数据有争用，产生了冲突，那就再采用其他的补偿措施。（最常见的补偿错误就是不断地重试，直到成功为止）**，这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步操作称为**非阻塞同步**
  * **非阻塞的实现CAS（Compare-and-Swap）**
    * CAS指令需要有3个操作数，分别是内存地址（在java中理解为变量的内存地址，用V表示）、旧的预期值（用A表示）和新值（用B表示）。CAS指令执行时，当且仅当V处的值符合旧预期值A时，处理器用B更新V处的值，否则它就不执行更新，但是无论是否更新了V处的值，都会返回V的旧值，上述的CAS指令是一个原子操作
  * **CAS的ABA问题**
    * 因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。CAS只关注了比较前后的值是否改变，而无法清楚在此过程中变量的变更明细，这就是所谓的ABA漏洞
    * ABA问题的解决思路就是使用版本号(如MySQL的MVCC)。在变量前面追加版本号，每次变量更新的时候把版本号加一，那么A-B-A就变成了1A-2B-3C
#### 1.2.1 可重入函数

* 重入即表示重复进入，首先它意味着**这个函数可以被中断**，其次意味着它**除了使用自己栈上的变量以外不依赖于任何环境**（包括static ），这样的函数就是purecode （纯代码）可重入，可以允许有该函数的多个副本在运行，由于它们使用的是分离的栈，所以不会互相干扰
* 信号就像硬件中断一样，会打断正在执行的指令序列。**信号处理函数无法判断捕获到信号的时候，进程在何处运行**。如果信号处理函数中的操作与打断的函数的操作相同，而且这个操作中有**静态数据结构**等，当信号处理函数返回的时候（当然这里讨论的是信号处理函数可以返回），恢复原先的执行序列，可能会**导致信号处理函数中的操作覆盖了之前正常操作中的数据**
* 常见的情况是，程序执行到某个函数foo()时，收到信号，于是暂停目前正在执行的函数，转到信号处理 函数，而这个信号处理函数的执行过程中，又恰恰也会进入到刚刚执行的函数foo()，这样便发生了所谓的重入。此时如果foo()能够正确的运行，而且处理完成后，之前暂停的foo()也能够正确运行，则说明它是可重入的
* 不可重入的后果：不可重入的后果**主要体现在象信号处理函数这样需要重入的情况中**。如果**信号处理函数中使用了不可重入的函数**，则可能**导致程序的错误甚至崩溃**
* 要确保函数可重入，需满足以下几个条件： 
  1. 不在函数内部使用静态或全局数据 
  2. 不返回静态或全局数据，所有数据都由函数的调用者提供
  3. 使用本地数据，或者通过制作全局数据的本地拷贝来保护全局数据
  4. 不调用不可重入函数

* **不可重入的几种情况**：

  * 使用静态数据结构，比如getpwnam，getpwuid：如果信号发生时正在执行getpwnam，信号处理程序中执行getpwnam可能覆盖原来getpwnam获取的旧值

  - **调用malloc或free**：如果信号发生时正在malloc（修改堆上存储空间的链接表），**信号处理程序又调用malloc，会破坏内核的数据结构**
  - 使用标准IO函数，因为**好多标准IO的实现都使用全局数据结构**，比如printf(文件偏移是全局的)
  - 函数中调用longjmp或siglongjmp：信号发生时程序正在修改一个数据结构，处理程序返回到另外一处，导致数据被部分更新

* **可重入是线程安全的一个真子集，如果一个函数是可重入函数，那么它一定是线程安全的，但是如果一个函数是线程安全的，它不一定是可重入函数**

#### 1.2.2 异步信号安全(async-signal-safe)函数

  * **异步信号安全的函数是指当从信号处理器函数调用时，可以保证其实现是安全的，如果某一函数是可重入的，或者信号处理器函数无法将其中断时，就称该函数是异步信号安全的**
  * 但同时指出，仅当信号处理器函数中断了不安全函数的执行，且处理器函数自身也调用了这个不安全函数时，该函数才是不安全的
  * 由于**可能会更新errno，依然会导致信号处理器函数不可重入**，因为它们可能会覆盖之前由主程序调用函数时所设置的errno值。有一种变通方法，即当信号处理器函数使用了标准所列可重入函数时，可在其入口处保存errno值，并在其出口处恢复errno的旧有值

  - 从多个线程访问时,其表现出正确的行为
  - 无论操作系统如何调度这些线程,无论这些线程的执行顺序如何交织
  - 调用端代码无需额外的同步或其他协调动作

  ​	依据这个定义,C++ 标准库里的大多数类都不是线程安全的,无论 std::string 还是 std::vector 或 std::map,因为这些类通常需要在外部加锁.


## 2. 多线程关键词

### 2.1 threads

- 作者以[NonRecurisiveMutest.cc](https://github.com/chenshuo/recipes/tree/master/thread/test)这个为例子,如果mutex是递归的话,push_back()可能(但不总是)导致迭代器失效,程序偶尔会crash,这种错误不好debug.
- 而这种偶发的crash,发生在调用函数和被调用函数都以为自己拿到了锁,如果恰好都在修改一个对象的时候,这时候就容易crash.
- 而如果使用非递归锁,这种错误就会提前暴露出来,死锁比偶发的crash总归是好debug.
- 种种优化方法在没有数据支持的情况下,是靠不住的.很多人误认为用锁会让程序变慢,但实际上影响性能的不是锁,而是锁争用.要学会在程序的复杂度和性能之间取得平衡,并考虑机器扩容的可能.
- 多机的可扩展能力比单机的性能优化更重要,更值得投入精力.

#### 2.2 join和detach
* join和detach
* join:
    当你调用 join 时,它会等待被调用线程执行完毕,然后再继续执行主线程.换句话说,join 使得主线程等待被调用线程的完成.
    使用 join 可以确保在主线程继续执行之前,被调用线程的任务已经完成.这对于需要等待线程执行结果的情况很有用

* detach:
    当你调用 detach 时,它使得被调用线程成为后台线程,与主线程分离.主线程不再等待被调用线程的完成.
    使用 detach 可以使得主线程在后台线程运行的同时继续执行,而不必等待后台线程完成.这对于一些异步任务或长时间运行的任务很有用.

* 不使用join也不使用detach:
    在主线程退出时,可能会导致一些未定义行为,因为线程对象将被销毁,但线程本身可能仍在运行.
    以下是可能发生的情况:
    1. 程序可能终止,但线程可能仍在运行:
        如果主线程退出,而被创建的线程仍在运行,可能导致程序终止,但线程继续执行.这可能导致线程无法正确完成其任务,因为主线程已经退出.
        程序可能崩溃:

    2. 程序可能会崩溃:
        这是由于线程对象的销毁可能涉及到一些资源的释放,而线程本身仍在访问这些资源,导致未定义行为.
    3. 资源泄漏:
        如果线程分配了一些资源(例如内存),但在线程执行完毕前这些资源没有被释放,可能会导致资源泄漏.

### 2.2 mutex

#### 2.1 args
#### 2.2 lock_guard 2.3 unique_lock
是的,你的理解是正确的.

`std::lock_guard`和`std::unique_lock`都是RAII(Resource Acquisition Is Initialization)风格的互斥锁包装器,它们在构造时自动锁定互斥锁,在析构时自动解锁互斥锁.这种设计可以确保在函数退出(正常或异常)时自动释放锁,从而避免了因忘记解锁而导致的死锁.

`std::lock_guard`和`std::unique_lock`的主要区别在于,`std::unique_lock`提供了更多的灵活性:

1. **延迟锁定**:`std::unique_lock`可以在创建时不立即锁定互斥锁,然后在需要的时候再锁定.`std::lock_guard`则在创建时必须立即锁定互斥锁.

2. **所有权传递**:`std::unique_lock`是可移动的,这意味着你可以将锁的所有权从一个`std::unique_lock`对象转移到另一个.`std::lock_guard`则不可移动.

3. **手动锁定和解锁**:`std::unique_lock`提供了`lock`和`unlock`方法,允许你在任何时候手动锁定和解锁互斥锁.`std::lock_guard`则不提供这些方法.

因此,如果你需要更多的控制,例如延迟锁定/所有权传递或手动锁定和解锁,那么应该使用`std::unique_lock`.如果你只需要简单地锁定和解锁互斥锁,那么`std::lock_guard`可能是更好的选择,因为它更简单,且开销更小.

`std::adopt_lock`/`std::defer_lock` 和 `std::try_to_lock` 都是 `std::unique_lock` 的构造函数可以接受的锁策略参数,它们的含义和使用场景如下:

1. **std::adopt_lock**:这个策略表示互斥锁在构造锁对象时已经被锁定.当你已经手动锁定了一个互斥锁,然后想要将它的管理权交给 `std::unique_lock` 时,可以使用 `std::adopt_lock`.这样,`std::unique_lock` 在构造时就不会再次尝试锁定互斥锁,而是直接接管已经被锁定的互斥锁.

2. **std::defer_lock**:这个策略表示在构造 `std::unique_lock` 时不锁定互斥锁.你可以稍后手动调用 `std::unique_lock::lock` 方法来锁定互斥锁.这个策略在你需要延迟锁定互斥锁的情况下很有用.

3. **std::try_to_lock**:这个策略表示在构造 `std::unique_lock` 时尝试锁定互斥锁,如果互斥锁已经被锁定,则立即返回,不会阻塞.你可以检查 `std::unique_lock::owns_lock` 方法的返回值,来判断是否成功锁定了互斥锁.

在你给出的代码中,`std::lock(foo, bar)` 会同时锁定 `foo` 和 `bar` 互斥锁,然后使用 `std::adopt_lock` 策略创建 `std::unique_lock` 对象,接管已经被锁定的互斥锁.在 `task_b` 函数中,使用 `std::defer_lock` 策略创建 `std::unique_lock` 对象,然后使用 `std::lock(lck1, lck2)` 同时锁定两个 `std::unique_lock` 对象管理的互斥锁.这样可以避免因为锁定顺序的问题导致死锁.

`std::unique_lock` 和 `std::lock_guard` 都是 C++ 中用于管理互斥锁的类,但它们之间存在一些重要的区别:

1. **灵活性**:`std::unique_lock` 比 `std::lock_guard` 更灵活.`std::unique_lock` 允许你延迟锁定,手动锁定和解锁,以及尝试锁定.而 `std::lock_guard` 在构造时自动锁定互斥锁,在析构时自动解锁,不支持手动控制.

2. **所有权转移**:`std::unique_lock` 支持所有权的转移,这意味着你可以将一个 `std::unique_lock` 对象移动到另一个 `std::unique_lock` 对象.而 `std::lock_guard` 不支持所有权的转移.

3. **条件变量支持**:`std::unique_lock` 可以与 `std::condition_variable` 一起使用,以实现线程间的同步和通信.而 `std::lock_guard` 不支持与 `std::condition_variable` 一起使用.

4. **性能开销**:由于 `std::unique_lock` 提供了更多的功能,所以它的性能开销可能会比 `std::lock_guard` 稍大一些.

总的来说,如果你需要更多的控制和灵活性,或者需要使用条件变量,那么 `std::unique_lock` 是一个好的选择.如果你只需要简单地锁定和解锁互斥锁,那么 `std::lock_guard` 可能是一个更好的选择,因为它更简单,性能开销也可能更小.

是的,C++中确实有`std::shared_lock`.这是一个类模板,用于管理`std::shared_mutex`或`std::shared_timed_mutex`类型的互斥锁.

`std::shared_lock`的主要特性是它支持共享所有权语义.这意味着多个`std::shared_lock`可以同时拥有同一个互斥锁的共享所有权.当一个`std::shared_lock`拥有互斥锁的共享所有权时,其他线程可以获取互斥锁的共享所有权,但不能获取互斥锁的独占所有权.这在某些需要多个读者和单个写者的情况下非常有用.

`std::shared_lock`的使用方式与`std::unique_lock`类似.你可以在创建`std::shared_lock`时锁定互斥锁,也可以稍后手动调用`std::shared_lock::lock`或`std::shared_lock::lock_shared`方法来锁定互斥锁.当`std::shared_lock`被销毁时,它会自动释放互斥锁.

需要注意的是,`std::shared_lock`只能用于支持共享所有权语义的互斥锁,如`std::shared_mutex`和`std::shared_timed_mutex`.对于不支持共享所有权语义的互斥锁,如`std::mutex`,你应该使用`std::unique_lock`或`std::lock_guard`.


### 2.3 condition variable
`std::condition_variable`是C++中的一种同步原语,它可以用来在多线程环境中实现复杂的同步模式.以下是一些常见的用法:

1. **等待通知**:一个线程可以使用`std::condition_variable::wait`或`wait_for`/`wait_until`方法来等待另一个线程的通知.当`wait`被调用时,当前线程将被阻塞,直到另一个线程调用`std::condition_variable::notify_one`或`notify_all`方法.

2. **条件等待**:`std::condition_variable::wait`方法还可以接受一个谓词(返回`bool`的函数或函数对象).只有当这个谓词返回`true`时,`wait`才会返回.这可以用来实现条件等待:线程等待某个条件成立.


3. **唤醒一个或多个线程**:可以使用`std::condition_variable::notify_one`方法唤醒一个等待的线程,或者使用`std::condition_variable::notify_all`方法唤醒所有等待的线程.

以下是一个简单的例子,展示了如何使用`std::condition_variable`实现生产者-消费者模式:

```cpp
#include <condition_variable>
#include <mutex>
#include <queue>
#include <thread>

std::queue<int> produced_nums;
std::mutex m;
std::condition_variable cond_var;

void producer() {
    for (int i = 0; ; i++) {
        std::this_thread::sleep_for(std::chrono::milliseconds(900));
        std::lock_guard<std::mutex> lock(m);
        produced_nums.push(i);
        cond_var.notify_all();
    }
}

void consumer() {
    while (true) {
        std::unique_lock<std::mutex> lock(m);
        cond_var.wait(lock, []{ return !produced_nums.empty(); });
        std::cout << "consuming " << produced_nums.front() << '\n';
        produced_nums.pop();
    }
}

int main() {
    std::thread producer_thread(producer);
    std::thread consumer_thread(consumer);

    producer_thread.join();
    consumer_thread.join();

    return 0;
}
```

在这个例子中,生产者线程生成数字并将其放入队列,然后通知所有等待的消费者线程.消费者线程等待队列非空,然后从队列中取出并消费数字.

### 2.4 future

future是表示未来能够得到的值,具体什么时候能够得到,依赖于承诺对象的实现;什么是承诺对象?
promise和packaged_task就是承诺对象,但这些承诺对象set_value的时候,就可以执行future.get()

#### 2.4.1 async的入参解释

std::async 是 C++11 中引入的一个用于启动异步任务的函数.它的原型如下:

```cpp
template <class Fn, class... Args>
std::future<typename std::result_of<Fn(Args...)>::type> 
    async(std::launch policy, Fn&& f, Args&&... args);
```

这里是 std::async 函数的主要参数及其意义:

policy: 异步任务的启动策略,它是一个 std::launch 类型的枚举值.可能的值有:

std::launch::async:异步执行任务,可能会在新的线程中执行.
std::launch::deferred:延迟执行任务,直到调用 std::future 对象的 get 或 wait 函数时执行,可能在当前线程执行.
std::launch::async | std::launch::deferred:由系统自行选择执行方式,可能异步也可能延迟.
f: 要异步执行的函数或可调用对象.

args...: 传递给函数 f 的参数列表.

std::async 返回一个 std::future 对象,通过这个对象可以获取异步任务的结果.std::future 是一个轻量级的异步结果管理器,它提供了对异步任务的状态查询(是否完成/是否有异常等)以及获取最终结果的功能.

使用 std::async 可以方便地在后台执行任务,而调用 get 函数时,如果任务尚未完成,主线程会等待直到任务完成.这有助于充分利用多核系统的性能,将计算密集型任务分配到不同的线程中执行.

注意:在使用 std::async 时,需要小心选择适当的启动策略,以避免不必要的线程创建和上下文切换.

#### 2.4.2 promise && packaged_task

关于future,promise,packaged_task,async的理解,以下表述对吗?
promise和packaged_task都是还没有给出具体值的承诺对象,当给出具体数值的时候,就表示承诺实现,可以用于计算.
而async是表示会开一个异步线程进行计算,返回的是一个future的值,如果future的值计算好之后,就可以通过future.get()得到.

所以说,在一个异步计算中,promise和packaged_task是输入端的,async是输出端的.

#### 2.4.3 shared_future
`std::future`对象的设计是唯一所有权的,也就是说,一旦你从一个`std::future`对象中获取了值,这个`std::future`对象就不能再被用来获取值.这是因为`std::future::get`方法会移动(而不是复制)值或异常,这样可以避免不必要的复制,但也意味着你只能从一个`std::future`对象中获取值一次.

因此,如果你需要在多个线程中共享同一个值,你不能直接使用`std::future`,而应该使用`std::shared_future`.`std::shared_future`对象可以被多次拷贝和读取,这意味着你可以在多个线程中共享同一个值.

在你的代码中,你创建了一个`std::shared_future<int> sf`对象,并将它传递给了三个异步操作.这三个异步操作都可以通过`sf.get()`获取到同一个值.如果你试图直接使用`std::future<int> f`来做同样的事情,你会得到一个编译错误,因为`std::future`对象不能被拷贝.

* shared_future可以直接对一个promise变量使用get_future方法吗

不可以.`std::promise`的`get_future`方法只能返回一个`std::future`对象,而不是`std::shared_future`对象.如果你想要一个`std::shared_future`对象,你需要首先从`std::promise`获取一个`std::future`对象,然后调用`std::future`的`share`方法来获取一个`std::shared_future`对象.例如:

```cpp
std::promise<int> p;
std::future<int> f = p.get_future();
std::shared_future<int> sf = f.share();
```

在这段代码中,`sf`是一个`std::shared_future`对象,它与`f`共享同一个状态,也就是说,它们都可以获取到同一个值.


### 2.5 packaged_task

在你的代码示例中,`std::async`用于异步执行`is_prime`函数并返回一个`std::future`对象.这个`std::future`对象可以用来获取`is_prime`函数的返回值.在等待`is_prime`函数完成的同时,主线程可以继续执行其他任务.

`std::async`是一个高级工具,它自动处理线程的创建和销毁,使得异步编程变得更简单.如果你只需要在后台运行一个任务并获取其结果,那么`std::async`通常是最好的选择.

相比之下,`std::packaged_task`提供了更多的灵活性,但也需要更多的管理工作.`std::packaged_task`只是将一个任务和一个`std::future`对象关联起来,它并不创建线程.你需要自己创建一个`std::thread`并将`std::packaged_task`对象传递给它.这使得你可以更精细地控制线程的创建和销毁,以及任务的调度.例如,你可以将任务提交给一个线程池,或者在特定的时间点启动线程.

所以,如果你只是在简单的场景中使用异步编程,那么`std::async`通常是最好的选择.如果你需要更精细的控制,或者你正在实现一个线程池,那么`std::packaged_task`可能是更好的选择.



### 2.6 原子变量

* 解决多线程下共享变量的问题(i++，指令重排问题)：对于共享变量的访问进行加锁，加锁可以保证对临界区的互斥访问，
* C++11提供了一些原子变量与原子操作解决用户加锁操作麻烦或者容易出错的问题
* C++11标准在标准库atomic头文件提供了模版std::atomic<>来定义原子量，而对于大部分内建类型，C++11提供了一些特化，如，std::atomic_int (std::atomic<int>)等
* 自定义类型变成原子变量的条件是该类型必须为**Trivially Copyable类型**(简单的判断标准就是这个类型可以用std::memcpy按位复制)
* atomic有一个成员函数is_lock_free，这个成员函数可以告诉我们到底这个类型的原子量是使用了原子CPU指令实现了无锁化，还是依然使用的加锁的方式来实现原子操作



### 99. quiz
#### 1. new操作是如何保证线程安全的?
new操作的线程安全性是通过内存管理器实现的.内存管理器会使用一种称为锁的机制来保证在同一时刻只有一个线程可以分配或释放内存.当一个线程正在进行new操作时,其他试图进行new操作的线程将会被阻塞,直到第一个线程完成new操作.

需要注意的是,虽然new操作本身是线程安全的,但是如果你在多线程环境中使用new操作创建的对象,你仍然需要确保对这些对象的访问是线程安全的.例如,如果两个线程同时访问和修改同一个对象,可能会导致数据竞争和未定义的行为,除非你使用了适当的同步机制(如互斥锁)来保护这个对象.

在C++中,`new`操作本身是线程安全的.C++标准库保证了在多线程环境中,不同线程可以同时进行`new`操作而不会发生冲突.

`new`操作的线程安全性是通过内存管理器实现的.内存管理器会使用一种称为锁的机制来保证在同一时刻只有一个线程可以分配或释放内存.当一个线程正在进行`new`操作时,其他试图进行`new`操作的线程将会被阻塞,直到第一个线程完成`new`操作.

需要注意的是,虽然`new`操作本身是线程安全的,但是如果你在多线程环境中使用`new`操作创建的对象,你仍然需要确保对这些对象的访问是线程安全的.例如,如果两个线程同时访问和修改同一个对象,可能会导致数据竞争和未定义的行为,除非你使用了适当的同步机制(如互斥锁)来保护这个对象.

#### 2. 为什么一定要用while循环,而不是if判断?

```c++
  muduo::MutextLock mutex;
  muduo::Condition cond(mutex);
  std:deque<int> queue;
  
  //消费者
  int dequeue(){
      // queue pop掉最后一个,并返回
      MutexLockGuard lock(mutex);
      while(queue.emtpy()){ // 不能用if,必须用while,避免虚假唤醒
          cond.wait(); // 这一步会unlock mutex,并进入等待,不会与其他线程产生死锁
      }
      int top = queue.front();
      queue.pop_front();
      return top;
  }
  ```

- 简单来说就是cv有可能会出现[虚假唤醒](https://www.zhihu.com/question/271521213)的情况,用while,不用if的话就可以多次检验.
- 给一个虚假唤醒的场景,一个线程A,一个线程B被notify,但是A还没有获得锁,B线程先获得了锁,并消费了队列中的数据(或者说notify的条件又变成不满足了),线程B结束后,A获得了锁,但这个时候条件已经不满足了.

- 当一个线程在条件变量上调用`.wait()`方法并进入等待状态时,如果后来被另一个线程通过`.notify()`或`.notify_all()`唤醒,那么它会从`.wait()`方法的下一行代码开始执行.

- 但是,需要注意的是,唤醒并不意味着条件已经满足.这就是为什么我们通常在一个`while`循环中调用`.wait()`方法,循环的条件就是我们等待的条件.这样,每次线程被唤醒时,它都会检查条件是否满足,如果条件不满足,它会再次调用`.wait()`方法进入等待状态.
-   - 这就是所谓的"虚假唤醒",即线程被唤醒,但是条件并未满足.使用`while`循环可以避免因虚假唤醒导致的问题.


#### 3. atomic实现原理
- 不同平台原子操作的实现不一样,但多线程导致的数据冲突都是因为多核cpu同时在跑一份数据,本质上都是保证这个数据在不同cpu的时候,有且只有一个在进行操作.下面是cacheline lock的实现方法

- 首先每个cpu核心都有其对应的高速cache

![在这里插入图片描述](https://s2.loli.net/2022/04/14/IxfwdV2vROmhnS8.png)

1. CPU1发出"Read Invalidate"消息,其他CPU将原子变量所在的缓存无效,并从Cache返回数据.CPU1将Cache line置成Exclusive状态.然后将该**cache line标记locked**
2. 然后CPU1读取原子变量,修改,最后写入cache line.
3. 将cache line置位unlocked.

在步骤(1)和(3)之间,如果其他CPU(例如CPU1)尝试执行一个原子递增操作,CPU1会发送一个"Read Invalidate"消息,CPU0收到消息后,检查对应的cache line的状态是locked,暂时不回复消息(CPU1会一直等待CPU0回复Invalidate Acknowledge消息).直到cache line变成unlocked.这样就可以实现原子操作.我们称这种方式为锁cache line.这种实现方式必须要求操作的变量位于一个cache line.

#### 4.多核cpu的缓存以及如何保持缓存一致性
    (https://blog.csdn.net/zhizhengguan/article/details/121275331)
- 如果对多核cpu还存疑,可以继续看这个.


### 99. quiz
### 1. 什么是虚假唤醒？为什么会有虚假唤醒？可以避免虚假唤醒吗？

- 什么是虚假唤醒？
虚假唤醒（spurious wakeup）是指线程在等待条件变量时，即使没有任何线程调用`notify_one`或`notify_all`，也会被唤醒的情况。这种现象在某些操作系统和硬件平台上可能会发生。

- 为什么会有虚假唤醒？
虚假唤醒的原因可能包括：
- **操作系统的调度策略**：操作系统可能会出于各种原因唤醒等待的线程，例如资源重新分配或优先级调整。
- **硬件中断**：硬件中断可能会导致等待的线程被唤醒。
- **其他系统级别的事件**：系统级别的事件（如信号处理）也可能导致线程被唤醒。

- 可以避免虚假唤醒吗？
虚假唤醒是操作系统和硬件层面的现象，无法完全避免。但是，可以通过编写健壮的代码来正确处理虚假唤醒。

### 2. 怎么应对虚假唤醒？

为了正确处理虚假唤醒，通常在等待条件变量时使用一个循环来反复检查条件是否满足。这样可以确保线程在条件满足之前不会继续执行。

#### 示例代码

以下是一个示例，展示了如何使用条件变量和处理虚假唤醒：

```cpp
#include <iostream>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <functional>

void printFirst() {
  for (int i = 0; i < 5; i++) {
    std::cout << "first" << '\n';
  }
}

void printSecond() {
  for (int i = 0; i < 5; i++) {
    std::cout << "second" << '\n';
  }
}

void printThird() {
  for (int i = 0; i < 5; i++) {
    std::cout << "third" << '\n';
  }
}

class Foo {
public:
  void first(std::function<void()> printFirst) {
    printFirst();
    {
      std::lock_guard<std::mutex> lock(mtx);
      k = 1;
    }
    cv.notify_all();
  }

  void second(std::function<void()> printSecond) {
    std::unique_lock<std::mutex> lock(mtx);
    cv.wait(lock, [this]() { return k == 1; });
    printSecond();
    {
      std::lock_guard<std::mutex> lock(mtx);
      k = 2;
    }
    cv.notify_one();
  }

  void third(std::function<void()> printThird) {
    std::unique_lock<std::mutex> lock(mtx);
    cv.wait(lock, [this]() { return k == 2; });
    printThird();
  }

private:
  std::condition_variable cv;
  std::mutex mtx;
  int k = 0;
};

int main() {
  Foo f;
  std::thread t1(&Foo::first, &f, printFirst);
  std::thread t2(&Foo::second, &f, printSecond);
  std::thread t3(&Foo::third, &f, printThird);
  t1.join();
  t2.join();
  t3.join();
  return 0;
}
```

```c++
#include <condition_variable>
#include <iostream>
#include <mutex>
#include <thread>
#include <vector>

std::mutex mtx;
std::condition_variable_any cv;

int cargo = 0;

void consumer() {
  mtx.lock();
  while (cargo == 0) {
    cv.wait(mtx);
  }

  std::cout << cargo << '\n';
  cargo = 0;
  mtx.unlock();
}

void producer(int id) {
  mtx.lock();
  cargo = id;
  cv.notify_one();
  mtx.unlock();
}

int main() {
  std::vector<std::thread> consumers;
  consumers.reserve(10);
  std::vector<std::thread> producers;
  consumers.reserve(10);

  for (int i = 0; i < 10; ++i) {
    consumers[i] = std::thread(consumer);
    producers[i] = std::thread(producer, i + 1);
  }

  for (int i = 0; i < 10; ++i) {
    producers[i].join();
    consumers[i].join();
  }

  return 0;
}

```
#### 进程状态
在操作系统中，进程通常有以下几种状态：

1. **新建（New）**：进程正在被创建。
2. **就绪（Ready）**：进程已经创建并等待被分配 CPU 时间片。
3. **运行（Running）**：进程正在执行。
4. **等待（Waiting）或阻塞（Blocked）**：进程正在等待某个事件（如 I/O 操作完成或资源可用）。
5. **终止（Terminated）或完成（Completed）**：进程已经完成执行或被终止。

### 进程状态转换图

以下是一个简单的进程状态转换图：

```
        +-------+       +-------+
        | New   |       | Ready |
        +-------+       +-------+
            |               |
            v               v
        +-----------------------+
        |       Running         |
        +-----------------------+
            |               |
            v               v
        +-------+       +-------+
        | Blocked|       | Terminated|
        +-------+       +-------+
```

### 进程状态转换说明

1. **新建到就绪**：进程创建完成后，进入就绪状态，等待被调度执行。
2. **就绪到运行**：调度器选择一个就绪进程，并将其分配给 CPU 执行。
3. **运行到等待**：进程在执行过程中需要等待某个事件（如 I/O 操作），进入等待状态。
4. **等待到就绪**：等待的事件完成后，进程重新进入就绪状态，等待被调度执行。
5. **运行到就绪**：进程在执行过程中被操作系统中断，放回就绪队列，等待下一个调度周期。
6. **运行到终止**：进程执行完成或被终止，进入终止状态。

### 示例代码中的线程状态

在你提供的代码示例中，线程的状态转换如下：

```cpp
int main() {
  std::thread consumer_thread(consume, 10);

  for (int i = 0; i < 10; ++i) {
    while (shipment_available()) {
      std::this_thread::yield();
    }
    mtx.lock();
    cargo = i + 1;
    cv.notify_one();
    mtx.unlock();
  }

  consumer_thread.join();

  return 0;
}
```

1. **新建**：线程被创建。
2. **就绪**：线程进入就绪状态，等待被调度执行。
3. **运行**：函数。
4. **等待**：调用时进入等待状态，等待条件变量通知。
5. **就绪**：主线程在循环中调用后， 线程被唤醒，进入就绪状态。
6. **运行**：线程重新获得 CPU 时间片，继续执行。
7. **终止**：线程执行完成，进入终止状态。

通过这些状态转换，线程和进程能够有效地共享 CPU 资源，实现并发执行。

#### 1. 具体例子
* 等待状态：当线程调用 `cv.wait()` 时，它会进入等待状态，直到被条件变量唤醒。线程在等待期间不会占用 CPU 资源。
* 就绪：当线程调用 `yield()` 时，它会主动让出 CPU 使用权，进入就绪状态，等待被调度执行。线程不会继续占用 CPU 资源，直到操作系统再次分配时间片。
* 运行（忙等待）：`while(!ready)`：忙等待是指线程在等待某个条件满足时，不断地检查该条件，而不让出 CPU 使用权。线程在等待期间仍然占用 CPU 资源，直到时间片耗尽或条件满足。

#### 解释

1. **等待线程**：
   - `second`和`third`函数中的线程使用`cv.wait(lock, [this]() { return k == 1; });`和`cv.wait(lock, [this]() { return k == 2; });`来等待条件变量。
   - 这些等待操作都在一个循环中进行，以确保即使发生虚假唤醒，线程也会继续等待，直到条件满足。

2. **通知线程**：
   - `first`函数在完成任务后，调用`cv.notify_all()`通知所有等待的线程。
   - `second`函数在完成任务后，调用`cv.notify_one()`通知一个等待的线程。

通过这种方式，可以确保线程在条件满足之前不会继续执行，从而正确处理虚假唤醒。


### 99. quiz
容器线程安全
7/原子操作如何实现(锁/cas***作)

8/如何实现一个互斥锁,互斥锁的实现原理

18/如何使用信号量制作出一个互斥锁

2/红黑树是线程安全的吗
3/有哪些同步手段
6/计数如何保证线程安全?(cas***作/***作系统底层指令支持)


#### 1. 线程之间私有和共享的资源有哪些?
线程之间的私有和共享资源主要包括以下几种：

**私有资源**：

1. **栈内存**：每个线程都有自己的栈内存，用于存储局部变量和函数调用的上下文信息。其他线程无法访问一个线程的栈内存。

2. **寄存器**：每个线程都有自己的寄存器集，包括程序计数器和其他寄存器。这些寄存器的值在线程切换时会被保存和恢复。

3. **线程局部存储（Thread Local Storage，TLS）**：这是一种特殊的机制，允许每个线程拥有自己的全局变量或静态变量的副本。

**共享资源**：

1. **堆内存**：所有线程共享同一块堆内存，线程可以创建对象并将其地址传递给其他线程。

2. **全局变量和静态变量**：全局变量和静态变量存储在所有线程共享的内存中，任何线程都可以访问它们。

3. **文件和网络资源**：如果一个程序打开了一个文件或网络连接，所有的线程都可以使用这些资源。

请注意，虽然线程可以共享许多资源，但在访问这些资源时需要小心，因为这可能会导致竞态条件和其他并发问题。为了避免这些问题，通常需要使用互斥锁、信号量等同步机制来保护共享资源。


#### 2. C++11的thread_local是什么？

`thread_local`是C++11引入的一个关键字，用于声明线程局部存储（Thread Local Storage，TLS）。

当一个变量被声明为`thread_local`时，每个线程都会有这个变量的一个副本，每个线程对其副本的修改都不会影响其他线程的副本。

这对于多线程编程非常有用，因为它可以让每个线程拥有自己的全局变量或静态变量的副本，避免了多线程之间的数据竞争。

以下是一个简单的例子：

```cpp
#include <thread>

thread_local int tls_var = 0;

void worker() {
    tls_var++;
    // 对tls_var的修改不会影响其他线程的tls_var
}

int main() {
    std::thread t1(worker);
    std::thread t2(worker);

    t1.join();
    t2.join();

    return 0;
}
```

在这个例子中，每个线程都有自己的`tls_var`副本，它们对`tls_var`的修改不会相互影响。


**37. 从各个方面使得std::threads unjoinable**

每一个std::thread类型的对象都处于两种状态：joinable和unjoinable

+ joinable：对应底层已运行、可运行或者运行结束的出于阻塞或者等待调度的线程
+ unjoinable： 默认构造的std::thread, 已move的std::thread, 已join的std::thread, 已经分离的std::thread
+ 如果某一个std::thread是joinable的，然后他被销毁了，会造成很严重的后果，（比如会造成隐式join（会造成难以调试的性能异常）和隐式detach（会造成难以调试的未定义行为）），所以我们要保证thread在所有路径上都是unjoinable的：
  
    class ThreadRAII{
    public:
        enum class DtorAction{join, detach};
        ThreadRAII(std::thread&& t, DtorAction a):action(a), t(std::move(t)){} //把线程交给ThreadRAII处理
        ~THreadRAII(){
            if(t.joinable()){
                if(action == DtorAction::join){
                    t.join();
                }
                else{
                    t.detach();                  //保证所有路径出去都是不可连接的
                }
            }
        }
    private:
        DtorAction action;
        std::thread t;    //成员变量最后声明thread
    }

**38. 知道不同线程句柄析构行为**

     _____           ___返回值___  std::promise _______
    |调用方|<--------|被调用方结果|<------------|被调用方|

因为被调用函数的返回值有可能在调用方执行get前就执行完毕了，所以被调用线程的返回值会保存在一个地方，所以会存在一个"共享状态"

所以在异步状态下启动的线程的共享状态的最后一个返回值是会保持阻塞的，知道该任务结束，返回值的析构函数在常规情况下，只会析构返回值的成员变量


#### 考虑对于单次事件通信使用

这段文本讨论了在多线程编程中，如何有效地进行单次事件通信。具体来说，它比较了使用标志位、线程锁和`std::promise`三种不同的方法来实现线程间的同步和通信。

1. **使用标志位(flag)**:
   - 代码示例中没有直接展示，但提到了一种常见的做法，即在一个线程中使用`while(!flag){}`循环等待另一个线程改变`flag`的值。这种方法简单，但它会导致忙等待（busy-waiting），浪费CPU资源，因为等待的线程会持续检查`flag`而不做任何有用的工作。

2. **使用线程锁**:
   - 文本提到可以使用线程锁来代替标志位，以避免忙等待。示例代码中，`std::lock_guard<std::mutex>`用于自动管理互斥锁，但示例似乎有误，因为它没有展示如何正确使用互斥锁来等待某个条件。正确的做法通常涉及到`std::condition_variable`，它可以与互斥锁一起使用，让线程在条件不满足时休眠，直到条件被另一个线程改变并通知。

3. **使用`std::promise`**:
   - 最后，文本推荐使用`std::promise`来进行单次事件通信。`std::promise`是一种同步机制，可以在一个线程中存储一个值或异常，然后在另一个线程中通过与之对应的`std::future`对象来检索这个值或异常。示例中，`detect`函数创建了一个线程`t`，这个线程会等待`std::promise`对象`p`的状态被设置。当`detect`函数调用`p.set_value()`时，`p`的状态被设置，`t`中的等待操作完成，`react`函数随后被执行。这种方法避免了忙等待，且只适用于一次性通信，但需要注意的是，它可能涉及到堆内存的使用。

总的来说，这段文本强调了在设计多线程程序时，应该避免使用忙等待策略，而应该考虑使用更高级的同步机制，如`std::promise`，来高效地进行线程间的单次事件通信。


- ***如何从构造函数,实现线程安全?***

  对象构造要做到线程安全,惟一的要求是在构造期间不要泄露 this 指针,即

  - 不要在构造函数中注册任何回调
  - 也不要在构造函数中把 this 传给跨线程的对象
  - 即便在构造函数的最后一行也不行

  之所以这样规定,是因为在构造函数执行期间对象还没有完成初始化,如果 this 被泄露 (escape) 给了其他对象(其自身创建的子对象除外),那么别的线程有可能访问这个半成品对象,这会造成难以预料的后果.

- ***为什么线程安全的,析构函数这么麻烦?***

  ​	因为一般线程安全方法都是依赖于互斥锁的,而析构函数会在析构的过程中把锁给销毁.

  确保所有线程都已经停止使用对象:在销毁对象之前,你需要确保没有任何线程还在使用或者可能会使用这个对象.这可能需要使用一些同步机制,例如条件变量或者future,来等待所有线程完成.

  使用智能指针管理资源:在C++中,你可以使用智能指针(例如std::unique_ptr或std::shared_ptr)来管理对象.当没有任何指针指向对象时,对象会被自动销毁.这可以避免手动管理内存和资源的复杂性.

#### 6.1 如果函数返回一个future,对这个future不调用get(),会发生什么
如果你调用`std::async`但不将返回值存储在一个`std::future`对象中,那么一个临时的`std::future`对象会被创建.这个临时对象会在表达式结束时被销毁,销毁时会阻塞等待异步任务完成.

这就是为什么如果你不想阻塞当前线程,你不能简单地忽略`std::async`的返回值.你需要将返回的`std::future`对象存储在某个地方,以便在适当的时候等待任务完成.

如果你创建了一个`std::future`对象,但是没有调用`get()`方法,那么在`std::future`对象被销毁时,如果关联的异步操作(例如`std::async`)还没有完成,那么程序会阻塞,直到异步操作完成.

这是因为`std::future`的析构函数会检查关联的异步操作是否已经完成.如果没有完成,析构函数会阻塞,直到异步操作完成.这是为了确保异步操作能够安全地完成,而不会在还没有完成的情况下被强制停止.

如果你不想在`std::future`对象被销毁时阻塞,你可以调用`std::future::detach()`方法.这将使`std::future`对象与其关联的异步操作分离,这样,即使`std::future`对象被销毁,异步操作也会继续运行.

需要注意的是,如果你没有调用`get()`方法,那么你将无法获取异步操作的结果.此外,`get()`方法只能被调用一次,因为调用`get()`方法后,`std::future`对象会变为无效状态.

函数的返回值哪怕没有用变量接着,其实也是存在的,在外部函数结束的时候会被析构.

而`future`的析构又要确保`get()`方法完成,所以如果不接着,就会产生阻塞.


- ***什么是析构竞态?***

  ​	与其他面向对象语言不同,C++ 要求程序员自己管理对象的生命期,这在多线程环境下显得尤为困难.当一个对象能被多个线程同时看到,那么对象的销毁时机就会变得模糊不清,可能出现多种竞态条件:

  - 在即将析构一个对象时,从何而知是否有另外的线程正在执行该对象的成员函数?
  - 如何保证在执行成员函数期间,对象不会在另一个线程被析构?
  - 在调用某个对象的成员函数之前,如何得知这个对象还活着?它的析构函数会不会刚执行到一半?


有件事需要注意,当把函数对象传入到线程构造函数中时,需要避免"[最令人头痛的语法解析](http://en.wikipedia.org/wiki/Most_vexing_parse)"\(_C++'s most vexing parse_, [中文简介](http://qiezhuifeng.diandian.com/post/2012-08-27/40038339477)\).如果你传递了一个临时变量,而不是一个命名的变量;C++编译器会将其解析为函数声明,而不是类型对象的定义.



#### Futex设计与实现

* futex (fast userspace mutex) 是Linux的一个基础组件，可以用来构建各种更高级别的同步机制，比如锁或者信号量等等，POSIX信号量就是基于futex构建的。大多数时候编写应用程序并不需要直接使用futex，一般用基于它所实现的系统库就够了

* 背景

  * 传统的SystemV IPC(inter process communication)**进程间同步机制都是通过内核对象来实现**的，以 semaphore 为例，当进程间要同步的时候，必须通过系统调用semop(2)进入内核进行PV操作。系统调用的缺点是开销很大，需要从**user mode切换到kernel mode、保存寄存器状态、从user stack切换到kernel stack、等等，通常要消耗上百条指令**

  * 事实上，有一部分系统调用是可以避免的，因为**现实中很多同步操作进行的时候根本不存在竞争，即某个进程从持有semaphore直至释放semaphore的这段时间内，常常没有其它进程对同一semaphore有需求**

  * 在这种情况下，内核的参与本来是不必要的，可是在传统机制下，**持有semaphore必须先调用semop(2)进入内核去看看有没有人和它竞争，释放semaphore也必须调用semop(2)进入内核去看看有没有人在等待同一semaphore，这些不必要的系统调用造成了大量的性能损耗**

  * 在futex诞生之前，linux下的同步机制可以归为两类：用户态的同步机制 和 内核同步机制。 用户态的同步机制基本上就是利用原子指令实现的spinlock。最简单的实现就是使用一个整型数，0表示未上锁，1表示已上锁。trylock操作就利用原子指令尝试将0改为1

    ```c
    bool trylock(int lockval) {
        int old;
        atomic { old = lockval; lockval = 1; }  // 如：x86下的xchg指令
        return old == 0;
    }
    ```

  * 无论spinlock事先有没有被上锁，经历trylock之后，它肯定是已经上锁了。所以lock变量一定被置1。而trylock是否成功，取决于spinlock是事先就被上了锁的（old\==1），还是这次trylock上锁的(old\==0)。而使用原子指令则可以避免多个进程同时看到old==0，并且都认为是自己改它改为1的
  * spinlock的lock操作则是一个死循环，不断尝试trylock，直到成功。 对于一些很小的临界区，使用spinlock是很高效的。因为trylock失败时，可以预期持有锁的线程（进程）会很快退出临界区（释放锁）。所以死循环的忙等待很可能要比进程挂起等待更高效
  * 但是spinlock的应用场景有限，**对于大的临界区，忙等待则是件很恐怖的事情**，特别是当同步机制运用于等待某一事件时（比如服务器工作线程等待客户端发起请求）。所以很多情况下进程挂起等待是很有必要的
  * 内核提供的同步机制，诸如semaphore、mutex等，其实骨子里也是利用原子指令实现的spinlock，内核在此基础上实现了进程的睡眠与唤醒。 使用这样的锁，能很好的支持进程挂起等待。**但是最大的缺点是每次lock与unlock都是一次系统调用，即使没有锁冲突，也必须要通过系统调用进入内核之后才能识别**
  * 理想的同步机制应该是**在没有锁冲突的情况下在用户态利用原子指令就解决问题**，而**需要挂起等待时再使用内核提供的系统调用进行睡眠与唤醒**。**换句话说，用户态的spinlock在trylock失败时，能不能让进程挂起，并且由持有锁的线程在unlock时将其唤醒**？

* futex设计思想

  * futex的解决思路是：**在无竞争的情况下操作完全在user space进行，不需要系统调用，仅在发生竞争的时候进入内核去完成相应的处理(wait 或者 wake up)**
  * 所以说，futex是一种**user mode和kernel mode混合的同步机制**，需要两种模式合作才能完成，**futex变量必须位于user space，而不是内核对象**，futex的代码也分为user mode和kernel mode两部分，**无竞争的情况下在user mode，发生竞争时则通过sys_futex系统调用进入kernel mode进行处理**

* 实现：

  ```c
  // 在uaddr指向的这个锁变量上挂起等待（仅当*uaddr==val时）
  int futex_wait(int *uaddr, int val);
  // 唤醒n个在uaddr指向的锁变量上挂起等待的进程
  int futex_wake(int *uaddr, int n);
  ```

  * 内核会动态维护一个跟uaddr指向的锁变量相关的等待队列
  * 注意futex_wait的第二个参数，由于**用户态trylock与调用futex_wait之间存在一个窗口，其间lockval可能发生变化**（比如正好有人unlock了）。所以用户态应该将自己看到的*uaddr的值作为第二个参数传递进去，futex_wait真正将进程挂起之前一定得检查lockval是否发生了变化，并且检查过程跟进程挂起的过程得放在同一个临界区中。如果futex_wait发现lockval发生了变化，则会立即返回，由用户态继续trylock
  * futex实现了锁粒度的等待队列，而这个锁却并不需要事先向内核申明。任何时候，用户态调用futex_wait传入一个uaddr，内核就会维护起与之配对的等待队列
  * 这件事情听上去好像很复杂，实际上却很简单。其实它并不需要为每一个uaddr单独维护一个队列，futex只维护一个总的队列就行了，所有挂起的进程都放在里面。当然，队列中的节点需要能标识出相应进程在等待的是哪一个uaddr。这样，当用户态调用futex_wake时，只需要遍历这个等待队列，把带有相同uaddr的节点所对应的进程唤醒就行了
  * 作为优化，futex维护的这个等待队列由若干个带spinlock的链表构成。调用futex_wait挂起的进程，通过其uaddr hash到某一个具体的链表上去。这样一方面能分散对等待队列的竞争、另一方面减小单个队列的长度，便于futex_wake时的查找。每个链表各自持有一把spinlock，将"*uaddr和val的比较操作"与"把进程加入队列的操作"保护在一个临界区中
  * 另一个问题是关于uaddr参数的比较。futex支持多进程，需要考虑同一个物理内存单元在不同进程中的虚拟地址不同的问题。那么不同进程传递进来的uaddr如何判断它们是否相等，就不是简单数值比较的事情。相同的uaddr不一定代表同一个内存，反之亦然
  * 两个进程（线程）要想共享同存，无外乎两种方式：**通过文件映射**（映射真实的文件或内存文件、ipc shmem，以及有亲缘关系的进程通过带MAP_SHARED标记的匿名映射共享内存）、**通过匿名内存映射**（比如多线程），这也是进程使用内存的唯二方式
  * 那么futex就应该支持这两种方式下的uaddr比较。匿名映射下，需要比较uaddr所在的地址空间（mm）和uaddr的值本身；文件映射下，需要比较uaddr所在的文件inode和uaddr在该inode中的偏移。注意，上面提到的内存共享方式中，有一种比较特殊：有亲缘关系的进程通过带MAP_SHARED标记的匿名映射共享内存。这种情况下表面上看使用的是匿名映射，但是内核在暗中却会转成到/dev/zero这个特殊文件的文件映射。若非如此，各个进程的地址空间不同，匿名映射下的uaddr永远不可能被futex认为相等

* 互斥锁pthread_mutex_t的实现原理

  ```c
  // pthread_mutex_lock:
  atomic_dec(pthread_mutex_t.value);
  if (pthread_mutex_t.value!=0)
    futex(WAIT)
  else
    success
  
  // pthread_mutex_unlock:
  atomic_inc(pthread_mutex_t.value);
  if(pthread_mutex_t.value!=1)
  	futex(WAKEUP)
  else
  	success
  ```

* 信号量sem_t的实现原理

  ```c
  sem_wait(sem_t *sem)
  {
  	for (;;) {
          if (atomic_decrement_if_positive(sem->count))
             break;
          futex_wait(&sem->count, 0)
      }
  }
  
  sem_post(sem_t *sem)
  {
     n = atomic_increment(sem->count);
     // Pass the new value of sem->count
     futex_wake(&sem->count, n + 1);
  }
  ```


### 进程与线程

#### fork，vfork，clone

* fork，vfork，clone**都是linux的系统调用**，这三个函数分别调用了**sys_fork、sys_vfork、sys_clone**，最终都调用了do_fork函数，**差别在于参数的传递和一些基本的准备工作不同，主要用来linux创建新的子进程或线程**（vfork创造出来的是线程）

  ![fork_vfork_clone](imgs/os/fork_vfork_clone.png)

* fork

  * 函数调用成功：返回两个值； 父进程：返回子进程的PID；子进程：返回0；失败：返回-1

  * 写时复制技术（Copy-On-Write）：其基础的观念是，如果有多个调用者(callers)同时要求相同资源，他们会共同取得相同的指标指向相同的资源，直到某个调用者(caller)尝试修改资源时，系统才会真正复制一个副本(private copy)给该呼叫者，以避免被修改的资源被直接察觉到，这过程对其他的呼叫只都是通透的(transparently)。**此作法主要的优点是如果呼叫者并没有修改该资源，就不会有副本(private copy)被建立**

  * 现在Linux系统调用fork利用COW技术，**父进程和子进程共享页帧而不是复制页帧**。然而，只要页帧被共享，它们就不能被修改，即页帧被保护。**无论父进程还是子进程何时试图写一个共享的页帧，就产生一个异常，这时内核就把这个页复制到一个新的页帧中并标记为可写**。原来的页帧仍然是写保护的：当其他进程试图写入时，内核检查写进程是否是这个页帧的唯一属主，如果是，就把这个页帧标记为对这个进程是可写的

  * fork前后内存关系

    * fork()创建了一个心的进程(child)信进程几乎是调用进程(父进程的翻版),理解fork()的关键是，在完成对其调用之后，会产生2个进程，且每个进程都会从fork()的返回处开始执行

    * 这俩个进程将**执行相同的程序段**，但是**拥有各自不同的堆段，栈段，数据段**，每个子程序都可修改各自的数据段，堆段，和栈段

    * 调用fork()之后先执行哪个进程的是由Linux下专有文件/proc/sys/kernel/sched_child_runs_first的值来确定的(值为0父进程先执行，非0子进程先执行)

    * fork后**子进程只复制父进程的页表，父子进程的代码段是相同的，所以代码段是没必要复制的，因此内核将代码段标记为只读，这样父子进程就可以安全的共享此代码段了**。fork之后在进程创建代码段时，新子进程的进程级页表项都指向和父进程相同的物理页帧

      <img src="imgs/os/fork_mem.png" alt="fork_mem" style="zoom: 80%;" />

    * **而对于父进程的数据段，堆段，栈段中的各页，由于父子进程要相互独立，所以我们采用写实复制的技术，来最大化的提高内存以及内核的利用率。刚开始，内核做了一些设置，令这些段的页表项指向父进程相同的物理内存页。调用fork之后，内核会捕获所有父进程或子进程针对这些页面的修改企图(说明此时还没修改)并为将要修改的页面创建拷贝。系统将新的页面拷贝分配给被内核捕获的进程，还会对子进程的相应页表项做适当的调整，现在父子进程就可以分别修改各自的上述段，不再互相影响了**

    * COW前

      <img src="imgs/os/fork_cow1.png" alt="fork_cow1" style="zoom:80%;" />

    * COW后

      <img src="imgs/os/fork_cow2.png" alt="fork_cow2" style="zoom:80%;" />

* vfork

  * 是一个过时的应用，**vfork也是创建一个子进程，但是子进程共享父进程的空间**。**在vfork创建子进程之后，父进程阻塞，直到子进程执行了exec()或者exit()**
  * **vfork最初是因为fork没有实现COW机制，而很多情况下fork之后会紧接着exec，而exec的执行相当于之前fork复制的空间全部变成了无用功，所以设计了vfork**。而现在fork使用了COW机制，唯一的代价仅仅是复制父进程页表的代价，所以vfork不应该出现在新的代码之中
  * **由vfork创建的子进程要先于父进程执行，子进程执行时，父进程处于挂起状态，子进程执行完，唤醒父进程**。除非子进程exit或者execve才会唤起父进程
  * vfork()用法与fork()相似，但是也有区别，具体区别归结为以下3点
    * **fork() 子进程拷贝父进程的数据段，代码段，vfork() 子进程与父进程共享数据段**
    * **fork() 父子进程的执行次序不确定，vfork()，保证子进程先运行**
    * **vfork()保证子进程先运行，在它调用exec或_exit之后父进程才可能被调度运行**。如果**在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁**

* clone

  * 是Linux**为创建线程设计**的（虽然也可以用clone创建进程）。所以可以说**clone是fork的升级版本，不仅可以创建进程或者线程，还可以指定创建新的命名空间（namespace）、有选择的继承父进程的内存、甚至可以将创建出来的进程变成父进程的兄弟进程等等**
  * clone函数功能强大，带了众多参数，它提供了一个非常灵活自由的常见进程的方法。因此由他创建的进程要比前面2种方法要复杂。**clone可以让你有选择性的继承父进程的资源，你可以选择像vfork一样和父进程共享一个虚存空间，从而使创造的是线程，你也可以不和父进程共享，你甚至可以选择创造出来的进程和父进程不再是父子关系，而是兄弟关系**

  ```c++
  int clone(int (*fn)(void *), void *child_stack, int flags, void *arg);
  
  // fn为函数指针，此指针指向一个函数体，即想要创建进程的静态程序（我们知道进程的4要素，这个就是指向程序的指针，就是所谓的“剧本"）；
  // child_stack为给子进程分配系统堆栈的指针（在linux下系统堆栈空间是2页面，就是8K的内存，其中在这块内存中，低地址上放入了值，这个值就是进程控制块task_struct的值）；
  // arg就是传给子进程的参数一般为（0）；
  // flags为要复制资源的标志，描述你需要从父进程继承那些资源
  ```

  以下是flags可取的值

  <img src="imgs/os/clone.png" alt="clone" style="zoom:80%;" />

* clone和fork的区别：

  * clone和fork的调用方式很不相同，clone调用需要传入一个函数，该函数在子进程中执行

* clone和fork最大不同在于**clone不再复制父进程的栈空间，而是自己创建一个新的**。 （void *child_stack）也就是第二个参数，需要分配栈指针的空间大小，所以**它不再是继承或者复制，而是全新的创造**

#### 孤儿进程和僵尸进程

* **孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作**
  * **孤儿进程并不会有什么危害**

* **僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程**、

  * 任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理
  * 危害：如果进程不调用wait / waitpid的话，那么保留的那段信息就不会释放，其**进程号就会一直被占用**，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程
  * 解决办法：子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号，在处理函数中调用wait或者waitpid

* 僵尸进程危害场景：

  　　* 例如有个进程，它**定期的产生一个子进程**，这个子进程需要做的事情很少，做完它该做的事情之后就退出了，因此这个子进程的生命周期很短，但是，**父进程只管生成新的子进程，至于子进程 退出之后的事情，则一概不闻不问，这样，系统运行上一段时间之后，系统中就会存在很多的僵死进程**，倘若用ps命令查看的话，就会看到很多状态为Z的进程
    　　* 严格地来说，僵死进程并不是问题的根源，**罪魁祸首是产生出大量僵死进程的那个父进程**。因此，当我们寻求如何消灭系统中大量的僵死进程时，答案就是**把产生大量僵尸进程的那个元凶枪毙掉**（也就是通过kill发送SIGTERM或者SIGKILL信号啦）。枪毙了元凶进程之后，它产生的僵死进程就变成了孤儿进程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源，这样，这些已经僵死的孤儿进程 就能瞑目而去了


#### [守护进程](https://blog.csdn.net/mijichui2153/article/details/81394387)

* 守护进程概念

  * 守护进程是**后台运行的**、**不与任何终端关联的(无法通过终端输入输出)**，用于**周期性地执行某种任务或等待处理特定的事件**

* 守护进程实现思路

  * **现一个守护进程，其实就是将普通进程按照上述特性改造为守护进程的过程。**需要注意的一点是，不同版本的 Unix 系统其实现机制不同，BSD 和 Linux 下的实现细节就不同

* 进程组和会话的概念

  * 进程组是**一组相关进程的集合**
  * 会话是**一组相关进程组的集合**

* 一个进程会有如下ID

  * PID：进程的唯一标识。对于多线程的进程而言，所有线程调用`getpid`函数会返回相同的值

  * PGID：进程组ID。每个进程都会有进程组ID，表示该进程所属的进程组。**默认情况下新创建的进程会继承父进程的进程组ID**

  * SID：会话ID。每个进程也都有会话ID。默认情况下，**新创建的进程会继承父进程的会话ID**

  * 可以调用以下函数获取/设置进程组ID跟会话ID

    ```c
    #include<unistd.h>
    #include<sys/types.h>
    pid_t getpgrp(void);
    pid_t getsid(pid_t pid); 
    int setpgid(pid_t pid, pid_t pgid); // 找到进程ID为pid的进程，将其进程组ID修改为pgid，如果pid的值为0，则表示要修改调用进程的进程组ID。该接口一般用来创建一个新的进程组
    
    pid_t setsid(void);  
    /*
    如果这个函数的调用进程不是进程组组长，那么调用该函数会发生以下事情：
    1）创建一个新会话，会话ID等于进程ID，调用进程成为会话的首进程。
    2）创建一个进程组，进程组ID等于进程ID，调用进程成为进程组的组长。
    3）该进程没有控制终端，如果调用setsid前，该进程有控制终端，这种联系就会断掉。
    调用setsid函数的进程不能是进程组的组长，否则调用会失败，返回-1，并置errno为EPERM。
    这个限制是比较合理的。如果允许进程组组长迁移到新的会话，而进程组的其他成员仍然在老的会话中，那么，就会出现同一个进程组的进程分属不同的会话之中的情况，这就破坏了进程组和会话的严格的层次关系了。
    */
    ```

* 创建后台进程步骤

  * **fork()创建子进程，父进程exit()退出**

    * 这是创建守护进程的第一步。**由于守护进程是脱离控制终端的，完成这一步后就会在Shell终端里造成程序已经运行完毕的假象**。之后的所有工作都在子进程中完成，而用户在Shell终端里则可以执行其他命令，从而在形式上做到了与控制终端的脱离，在后台工作
    * 由于**父进程先于子进程退出**，**子进程就变为孤儿进程**，并由` init `进程作为其父进程收养

  * **在子进程调用setsid()创建新会话**

    * 在调用了 fork() 函数后，子进程全盘拷贝了父进程的会话期、进程组、控制终端等，**虽然父进程退出了，但会话期、进程组、控制终端等并没有改变。这还不是真正意义上的独立开来，而 setsid() 函数能够使进程完全独立出来**
    * setsid()创建一个新会话，**调用进程担任新会话的首进程**，其作用有
      * 使当前进程脱离原会话的控制
      * 使当前进程脱离原进程组的控制
      * 使当前进程脱离原控制终端的控制
    * 这样，当前进程才能实现真正意义上完全独立出来，摆脱其他进程的控制

  * **再次 fork() 一个子进程，父进程exit()退出**

    * 现在，进程已经成为无终端的会话组长，但它可以重新申请打开一个控制终端，可以通过 fork() 一个子进程，该子进程不是会话首进程，该进程将不能重新打开控制终端。退出父进程
    * 也就是说**通过再次创建子进程结束当前进程，使进程不再是会话首进程来禁止进程重新打开控制终端**

  * **在子进程中调用chdir()让根目录“/”成为子进程的工作目录**

    * 这一步也是**必要的步骤**。**使用fork创建的子进程继承了父进程的当前工作目录**。由于在进程运行中，当前目录所在的文件系统（如“/mnt/usb”）是不能卸载的，这对以后的使用会造成诸多的麻烦（比如系统由于某种原因要进入单用户模式）
    * 因此，通常的做法是让"/"作为守护进程的当前工作目录，这样就可以避免上述的问题，当然，如有特殊需要，也可以把当前工作目录换成其他的路径，如/tmp。改变工作目录的常见函数是chdir。(避免原父进程当前目录带来的一些麻烦)

  * **在子进程中调用umask()重设文件权限掩码为0**

    * 文件权限掩码是指**屏蔽掉文件权限中的对应位**。比如，有个文件权限掩码是050，它就屏蔽了文件组拥有者的可读与可执行权限（就是说可读可执行权限均变为7）。**由于使用fork函数新建的子进程继承了父进程的文件权限掩码，这就给该子进程使用文件带来了诸多的麻烦。因此把文件权限掩码重设为0即清除掩码（权限为777），这样可以大大增强该守护进程的灵活性**。通常的使用方法为umask(0)。(相当于把权限开发)

  * **在子进程中close()不需要的文件描述符**

    * 同文件权限码一样，用fork函数新建的子进程会从父进程那里继承一些已经打开了的文件。这些被打开的文件可能永远不会被守护进程读写，但它们一样消耗系统资源，而且可能导致所在的文件系统无法卸下
    * 其实在上面的第二步之后，守护进程已经与所属的控制终端失去了联系。因此从终端输入的字符不可能达到守护进程，守护进程中用常规方法（如printf）输出的字符也不可能在终端上显示出来。所以，**文件描述符为0、1和2 的3个文件（常说的输入、输出和报错）**已经失去了存在的价值，也应被关闭（关闭失去价值的输入、输出、报错等对应的文件描述符）

  * **守护进程退出处理**

    * 当用户需要外部停止守护进程运行时，往往会使用 kill 命令停止该守护进程。所以，守护进程中需要编码来实现 kill 发出的signal信号处理，达到进程的正常退出

    * 想退出守护进程，只需给守护进程发送 SIGQUIT 信号即可

      ```shell
      sudo kill -3 PID 
      ```

* 步骤流程图

  <img src="imgs/os/daemon.png" alt="daemon" style="zoom:67%;" />

* 代码实现

  ```c++
  #include<stdio.h>
  #include<fcntl.h>
  #include<sys/types.h>
  #include<unistd.h>
  #include<stdlib.h>
  
  void create_daemon()
  {
    pid_t pid;
    /*(1)-----创建一个进程来用作守护进程-----*/
    pid = fork();
    if(pid == -1){
      printf("fork error\n");
      exit(1);
    }
    /*(1.1)-----------原父进程退出-------------*/
    else if(pid){
      exit(0);
    }
    /*(2)---setsid使子进程独立。摆脱会话控制、摆脱原进程组控制、摆脱终端控制----*/
    if(-1 == setsid()){
      printf("setsid error\n");
      exit(1);
    }
      /*(3)---通过再次创建子进程结束当前进程，使进程不再是会话首进程来禁止进程重新打开控制终端----*/
    pid = fork();
    if(pid == -1){
      printf("fork error\n");
      exit(1);
    }
    else if(pid){
      exit(0);
    }
      /*(4)---子进程中调用chdir()让根目录成为子进程工作目录----*/
    chdir("/");
      
      /*(5)---重设文件掩码为0（将权限全部开放）----*/
    umask(0);
      
    /*(6)---关闭文件描述符(常说的输入，输出，报错3个文件)----*/
    for(int i = 0; i < 3; ++i){
      close(i);
    }
      // 将标准输入、标准输出、标准错误输出重定向到/dev/null文件
      open("/dev/null", O_RDONLY);	// 0
      open("/dev/null", O_RDWR);		// 1
      open("/dev/null", O_RDWR);		// 2
    
    return;
  }
  ```

* Linux提供了完成同样功能的库函数

  ```c++
  #include<unistd.h>
  int daemon(int nochdir, int noclose);
  // nochdir参数用于指定是否改变工作目录，如果给它传递0，则工作目录被设置为"/"(根目录)，否则继续使用当前工作目录
  // noclose参数为0时，标准输入、标准输出、标准错误输出都被重定向到/dev/null文件，否则依然使用原来的设备
  // 成功返回0，失败返回-1并设置errno
  ```

