## 性能优化

### 1. concepts
#### 1.1 这些是一些常见操作的成本的数量级的概念:
时钟频率表示CPU每秒钟可以执行的周期数。时钟频率越高，CPU每秒钟可以执行的周期数就越多，处理速度也就越快。现代家用CPU的时钟频率通常在几GHz范围内。例如，3 GHz的CPU表示每秒钟有30亿个周期。

以3 GHz的CPU为例：
$ T = 1/f $
$ T= 1/(3*10e9)=1/3 ns $

时间单位换算：
1 s = 10e3 ms = 10e6 μs = 10e8 ns

| 操作类型                                   | CPU时钟周期范围 | 时间范围（纳秒）    |
|------------------------------------------|------------|----------------|
| 简单寄存器-寄存器操作（例如 ADD、OR 等）       | <1         | <3ns            |
| 内存写入                                   | 1          | 3ns             |
| 绕过延迟：在整数和浮点单元之间切换           | 0-3        | 0-9ns           |
| 正确的 if 分支                               | 1-2        | 3-6ns           |
| char的比较                                | 1-3        | 3-6ns           |
| 浮点/向量加法                                | 1-3        | 3-9ns           |
| 乘法（整数/浮点/向量）                       | 1-7        | 3-21ns          |
| 返回错误和检查                               | 1-7        | 3-21ns          |
| L1 缓存读取                                 | 3-4        | 9-12ns          |
| TLB 未命中                                  | 7-21       | 21-63ns         |
| 上锁（互斥锁，非竞争）                        | 8 - 35    | 25ns - 100ns   |
| L2 缓存读取                                 | 10-12      | 30-36ns         |
| 错误的 if 分支（分支错误预测）                 | 10-20      | 30-60ns         |
| 浮点除法                                   | 10-40      | 30-120ns        |
| 128 位向量除法                              | 10-70      | 30-210ns        |
| 原子操作/CAS                               | 15-30      | 45-90ns         |
| C 函数直接调用                              | 15-30      | 45-90ns         |
| 整数除法                                   | 15-40      | 45-120ns        |
| C 函数间接调用                              | 20-50      | 60-150ns        |
| C++ 虚函数调用                              | 30-60      | 90-180ns        |
| L3 缓存读取                                 | 30-70      | 90-210ns        |
| 主内存读取                                  | 100-150    | 300-450ns       |
| NUMA（不同插槽的原子操作/CAS，估计值）         | 100-300    | 300-900ns       |
| NUMA（不同插槽的 L3 缓存读取）                | 100-300    | 300-900ns       |
| 分配+释放配对（小对象，内存池方式）           | 5-15    | 10-50ns      |
| 分配+释放配对（小对象，new和delete方式）      | 200-500    | 600-1500ns      |
| NUMA（不同插槽的主内存读取）                  | 300-500    | 900-1500ns      |
| 内核调用                                   | 1000-1500  | 3-4.5μs     |
| 线程上下文切换（直接成本）                    | 2000       | 6μs         |
| C++ 异常抛出并捕获                           | 5000-50000 | 15-150μs  |
| 线程上下文切换（总成本，包括缓存失效）         | 10000 - 100万 | 30μs - 3ms |
| 磁盘访问（SSD）                              | 100000 - 1000000 | 30μs - 300μs |
| 磁盘访问（HDD）                              | 1000000 - 10000000 | 300μs - 3ms |
| 线程创建                                    | 1000000 - 10000000 | 300μs - 3ms |
| 线程销毁                                    | 1000000 - 10000000 | 300μs - 3ms |
| 网络消息（本地网络）                          | 100000 - 1000000 | 30μs - 300μs |
| 网络消息（广域网）                            | 1000000 - 1000000000 | 300μs - 300ms |

#### 1.2 优化原则
1. **二八原则**：
   - 80% 的性能问题通常来自 20% 的代码。
2. **先正确运行，再优化**：
   - 确保程序正确运行，然后再进行性能优化。
3. **不要太提前优化**：
   - 避免过早优化，先确保代码的正确性和可维护性。
4. **优化需要数据支持**：
   - 进行性能优化时需要有数据支持，编译器的优化能力很强，看上去有效的优化不一定实际有效。

#### 1.3 代码优化主要思路
* **性能优化原则**
  1. **二八原则**：
    - 80% 的性能问题通常来自 20% 的代码。
  2. **先正确运行，再优化**：
    - 确保程序正确运行，然后再进行性能优化。
  3. **不要太提前优化**：
    - 避免过早优化，先确保代码的正确性和可维护性。
  4. **优化需要数据支持**：
    - 进行性能优化时需要有数据支持，编译器的优化能力很强，看上去有效的优化不一定实际有效。

* **CPU 密集任务**
  1. **多线程**：
    - 使用多线程并行化计算任务，充分利用多核处理器的计算能力。
    - 使用 `wait` 机制协调线程间的同步。
  2. **优化算法实现**：
    - 避免不必要的递归，使用迭代替代递归。
    - 避免不必要的参数复制，使用引用传递参数。
    - 避免不必要的计算，减少重复计算。
    - 正确使用高效的算法和数据结构。

* **I/O 密集任务**
  1. **内存 I/O 密集**：
    - 使用对象池，避免重复构造和销毁对象。
    - 优化内存访问模式，使用顺序访问提高缓存命中率。
  2. **硬盘 I/O 密集**：
    - 使用异步 I/O 操作，允许程序在等待 I/O 操作完成时继续执行其他任务。
    - 使用缓存减少磁盘 I/O 操作，提高效率。
    - 使用高效的文件系统和磁盘调度算法。
  3. **网络 I/O 密集**：
    - 使用异步网络 I/O 操作，提高并发性和效率。
    - 使用高效的网络协议，减少网络延迟。
    - 使用压缩减少传输的数据量，提高传输效率。

#### 1.4 代码实现常见原则
* **硬件友好代码**
  1. **利用 SIMD 特性**：
    - 现在的 CPU 很多时候都可以对指令并行化，利用 SIMD（Single Instruction, Multiple Data）特性进行向量化计算，提高并行计算性能。
  2. **提升缓存利用率**：
    - 使用结构化数组（SoA）和数组结构（AoS）方式优化数据布局，提高缓存命中率。
    - 避免缓存未命中，优化内存访问模式，使用顺序访问提高缓存命中率。

#### 1.5 性能优化常见手段
* 对象池
* 线程池
* 内存池
* 缓存


* **3. 编译器优化**
#### 3.1 pgo
PGO,全称为 Profile-Guided Optimization(基于分析的优化),是一种编译器优化技术,它通过收集程序运行时的性能信息来指导编译器优化.

PGO 的工作流程通常包括以下几个步骤:
1. **编译**:首先,你需要使用特殊的编译器选项来编译你的程序,这会使得程序在运行时收集性能信息.
2. **运行**:然后,你需要运行你的程序,并让它处理一些典型的工作负载.这会生成一个性能分析文件,其中包含了程序运行时的性能信息.
3. **优化编译**:最后,你需要再次使用特殊的编译器选项来编译你的程序,这次编译器会使用性能分析文件中的信息来指导优化.

通过这种方式,编译器可以了解到程序的实际运行情况,例如哪些代码经常被执行,哪些代码很少被执行,哪些条件分支的预测结果通常是什么等等.然后,编译器可以使用这些信息来进行更有效的优化,例如更精确地进行内联,更智能地安排代码布局,更准确地预测条件分支等等.

PGO 可以显著提高程序的运行速度,特别是对于那些性能敏感的应用程序.然而,PGO 也有一些缺点,例如它会增加编译时间和编译复杂性,因此并不是所有的项目都适合使用 PGO.


### 缓存
* 减少内存访问延迟：cpu缓存
* 减少磁盘IO读写延迟：文件缓存
* 减少数据库查询延迟：数据库缓存
* 减少网络IO读写延迟：web缓存/ 代理服务器缓存/ CDN缓存
* 减少cpu计算延迟：cacheData

### 如何解决缓存空间受限问题
缓存为了快速访问一般都是通过哈希表的方式存储。
但当需要限制缓存空间大小的时候，即数据会不断增加，但缓存空间有限，就需要考虑那些缓存的数据需要被淘汰。
常见的淘汰方法有这些。
* LRU（Least Recently Used）：移除最近最少使用的数据。
* LFU（Least Frequently Used）：移除使用频率最低的数据。
* FIFO（First In First Out）：移除最早进入缓存的数据。

- **汇编指令**：汇编指令是人类可读的指令，通常直接对应于机器指令（CPU 指令）。每条汇编指令通常对应一条或多条机器指令。
- **指令执行过程**
  1. **取值（Fetch）**：从内存中取出指令。
  2. **译码（Decode）**：将取出的指令译码为 CP U 可以理解的操作。
  3. **执行（Execute）**：执行指令的操作，例如算术运算、逻辑运算、内存访问等。
  4. **写回（Write Back）**：将执行结果写回寄存器或内存。

- **时钟周期消耗**
  - **取值、译码、写回**：这些阶段的时钟周期消耗相对固定，通常都是一个时钟周期。
  - **执行**：执行阶段的时钟周期消耗取决于指令的类型，可以是一个时钟周期到几十个时钟周期。例如，简单的算术运算可能只需要一个时钟周期，而复杂的指令（如除法、内存访问）可能需要多个时钟周期。

- **超标量结构**
  - **超标量结构**：现代 CPU 通常使用超标量结构，可以在一个核内一个时钟周期内执行多条指令。这种结构通过增加多个执行单元，使得 CPU 可以并行处理多条指令，从而提高指令执行的效率。

### 解释

- **内核调用**：指的是从用户态切换到内核态执行系统调用的时间。
- **线程上下文切换**：包括直接成本和总成本（包括缓存失效）。
- **C++ 异常抛出并捕获**：指的是在 C++ 中抛出和捕获异常的时间。
- **内存分配（malloc/free）**：指的是使用 `malloc` 和 `free` 进行内存分配和释放的时间。
- **互斥锁加锁/解锁**：包括无竞争和有竞争两种情况。
- **读写锁加锁/解锁**：包括无竞争和有竞争两种情况。
- **进程创建**：指的是创建一个新进程的时间。
- **文件I/O操作**：指的是对小文件进行读写操作的时间。
- **网络I/O操作**：指的是发送和接收小数据包的时间。
- **系统调用**：包括简单和复杂的系统调用。
- **缓存命中**：包括 L1、L2 和 L3 缓存的命中时间。
- **内存访问（DRAM）**：指的是访问主内存的时间。
- **磁盘I/O操作**：包括 SSD 和 HDD 的读写操作时间。

这些时间范围是基于典型的硬件和操作系统环境，实际时间可能会因具体的硬件配置和系统负载而有所不同。


流水线技术，指的是一个指令没有完整执行完，另一个指令就已经在执行了是吧？

是的，你的理解是正确的。流水线技术的核心思想是将指令的执行过程分解成多个阶段，并允许这些阶段并行处理不同的指令。这样，当一个指令还在执行的过程中，另一个指令就可以开始执行它的下一个阶段。这种并行性可以显著提高处理器的效率和吞吐量。

具体来说，流水线技术的工作方式如下：

1. **取值（Fetch）**：从内存中取出指令。
2. **译码（Decode）**：将取出的指令译码为CPU可以理解的操作。
3. **执行（Execute）**：执行指令的操作，例如算术运算、逻辑运算、内存访问等。
4. **写回（Write Back）**：将执行结果写回寄存器或内存。

在流水线中，这四个阶段可以同时进行，每个阶段处理不同的指令。例如：

- 指令1在执行阶段。
- 指令2在写回阶段。
- 指令3在译码阶段。
- 指令4在取值阶段。

这种并行处理可以减少每个指令完成所需的总时间，因为每个时钟周期内都有一个指令的某个阶段被处理。然而，流水线技术也引入了一些挑战，如流水线冒险（数据冒险、控制冒险和结构冒险），需要通过各种技术（如转发、暂停流水线、分支预测等）来管理和解决。

总之，流水线技术通过允许指令在不同阶段并行执行，提高了处理器的效率和吞吐量，但同时也需要处理由此引入的复杂性和挑战。


如果这些都存在的话，执行一个寄存器加法命令，最少需要4个时钟周期，是嘛？

执行一个寄存器加法命令确实会经历取值、译码、执行和写回这四个阶段，但是否需要四个时钟周期取决于具体的处理器设计和流水线的实现方式。

在没有流水线的简单处理器中，每个指令确实需要四个时钟周期来完成，因为每个阶段必须在前一个阶段完成后才能开始。这意味着如果一个寄存器加法指令正在执行，它将独占处理器四个周期。

然而，在流水线处理器中，情况就不同了。流水线处理器将这四个阶段分开，并允许每个阶段同时处理不同的指令。例如，当一个寄存器加法指令在执行阶段时，另一个指令可以同时在取值阶段，第三个指令在译码阶段，以此类推。这样，尽管每个指令仍然需要经过这四个阶段，但流水线的设计允许在每个时钟周期内完成一个指令的某个阶段，从而减少了每个指令的平均执行时间。

在流水线处理器中，一个寄存器加法指令可能只需要一个时钟周期就可以完成，但这取决于流水线的宽度和是否有任何流水线冒险（如数据冒险、控制冒险等）需要处理。如果流水线是无冒险的，并且有足够的执行单元来处理指令，那么每个指令可以在每个时钟周期内完成一个阶段，从而在四个时钟周期内完成整个指令。

总结来说，虽然指令执行的基本阶段（取值、译码、执行、写回）是固定的，但是否需要四个时钟周期来完成一个寄存器加法指令取决于处理器的具体设计和是否使用了流水线技术。


#### (23)服务器高并发的解决方案
1. 应用数据与静态资源分离
将静态资源(图片,视频,js,css等)单独保存到专门的静态资源服务器中,在客户端访问的时候从静态资源服务器中返回静态资源,从主服务器中返回应用数据.

2. 客户端缓存
因为效率最高,消耗资源最小的就是纯静态的html页面,所以可以把网站上的页面尽可能用静态的来实现,在页面过期或者有数据更新之后再将页面重新缓存.或者先生成静态页面,然后用ajax异步请求获取动态数据.

3. 集群和分布式
(集群是所有的服务器都有相同的功能,请求哪台都可以,主要起分流作用)<br>
(分布式是将不同的业务放到不同的服务器中,处理一个请求可能需要使用到多台服务器,起到加快请求处理的速度.)<br>
可以使用服务器集群和分布式架构,使得原本属于一个服务器的计算压力分散到多个服务器上.同时加快请求处理的速度.

4. 反向代理
在访问服务器的时候,服务器通过别的服务器获取资源或结果返回给客户端.


* 假设在某一时刻由几万个并发请求同时产生,请设计一个方案来处理这种情况.


#### 虚函数表开销
虚函数表（vtable）的使用确实会引入一些性能开销，主要体现在以下几个方面：
* **1. 虚函数调用的间接寻址**
    - **解释**：虚函数调用需要通过虚函数表进行间接寻址，这比直接调用函数要慢。
    - **原因**：编译器在编译时无法确定具体调用哪个函数，因此在运行时需要通过虚函数表查找函数地址，然后进行调用。这种间接寻址会增加指令开销。

* **2. 破坏指令缓存（Instruction Cache）**
    - **解释**：虚函数调用可能会破坏指令缓存（Instruction Cache），因为虚函数表中的函数地址可能指向不同的内存位置。
    - **原因**：现代处理器使用指令缓存来加速指令的执行。当程序执行过程中频繁跳转到不同的内存位置时，指令缓存可能会失效（cache miss），导致性能下降。

* **3. 破坏数据缓存（Data Cache）**
    - **解释**：虚函数表的访问可能会破坏数据缓存（Data Cache），因为虚函数表和实际函数实现可能位于不同的内存区域。
    - **原因**：数据缓存用于加速数据的访问。当程序访问虚函数表时，可能会导致数据缓存失效（cache miss），从而增加内存访问延迟。
