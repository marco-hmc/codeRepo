
## 性能优化

### 1. concepts
#### 1.1 这些是一些常见操作的成本的数量级的概念:
时钟频率表示CPU每秒钟可以执行的周期数。时钟频率越高，CPU每秒钟可以执行的周期数就越多，处理速度也就越快。现代家用CPU的时钟频率通常在几GHz范围内。例如，3 GHz的CPU表示每秒钟有30亿个周期。

以3 GHz的CPU为例：
$ T = 1/f $
$ T= 1/(3*10e9)=1/3 ns $

时间单位换算：
1 s = 10e3 ms = 10e6 μs = 10e8 ns

| 操作类型                                   | CPU时钟周期范围 | 时间范围（纳秒）    |
|------------------------------------------|------------|----------------|
| 简单寄存器-寄存器操作（例如 ADD、OR 等）       | <1         | <3ns            |
| 内存写入                                   | 1          | 3ns             |
| 绕过延迟：在整数和浮点单元之间切换           | 0-3        | 0-9ns           |
| 正确的 if 分支                               | 1-2        | 3-6ns           |
| char的比较                                | 1-3        | 3-6ns           |
| 浮点/向量加法                                | 1-3        | 3-9ns           |
| 乘法（整数/浮点/向量）                       | 1-7        | 3-21ns          |
| 返回错误和检查                               | 1-7        | 3-21ns          |
| L1 缓存读取                                 | 3-4        | 9-12ns          |
| TLB 未命中                                  | 7-21       | 21-63ns         |
| 上锁（互斥锁，非竞争）                        | 8 - 35    | 25ns - 100ns   |
| L2 缓存读取                                 | 10-12      | 30-36ns         |
| 错误的 if 分支（分支错误预测）                 | 10-20      | 30-60ns         |
| 浮点除法                                   | 10-40      | 30-120ns        |
| 128 位向量除法                              | 10-70      | 30-210ns        |
| 原子操作/CAS                               | 15-30      | 45-90ns         |
| C 函数直接调用                              | 15-30      | 45-90ns         |
| 整数除法                                   | 15-40      | 45-120ns        |
| C 函数间接调用                              | 20-50      | 60-150ns        |
| C++ 虚函数调用                              | 30-60      | 90-180ns        |
| L3 缓存读取                                 | 30-70      | 90-210ns        |
| 主内存读取                                  | 100-150    | 300-450ns       |
| NUMA（不同插槽的原子操作/CAS，估计值）         | 100-300    | 300-900ns       |
| NUMA（不同插槽的 L3 缓存读取）                | 100-300    | 300-900ns       |
| 分配+释放配对（小对象，内存池方式）           | 5-15    | 10-50ns      |
| 分配+释放配对（小对象，new和delete方式）      | 200-500    | 600-1500ns      |
| NUMA（不同插槽的主内存读取）                  | 300-500    | 900-1500ns      |
| 内核调用                                   | 1000-1500  | 3-4.5μs     |
| 线程上下文切换（直接成本）                    | 2000       | 6μs         |
| C++ 异常抛出并捕获                           | 5000-50000 | 15-150μs  |
| 线程上下文切换（总成本，包括缓存失效）         | 10000 - 100万 | 30μs - 3ms |
| 磁盘访问（SSD）                              | 100000 - 1000000 | 30μs - 300μs |
| 磁盘访问（HDD）                              | 1000000 - 10000000 | 300μs - 3ms |
| 线程创建                                    | 1000000 - 10000000 | 300μs - 3ms |
| 线程销毁                                    | 1000000 - 10000000 | 300μs - 3ms |
| 网络消息（本地网络）                          | 100000 - 1000000 | 30μs - 300μs |
| 网络消息（广域网）                            | 1000000 - 1000000000 | 300μs - 300ms |

#### 1.2 优化原则
1. **二八原则**：
   - 80% 的性能问题通常来自 20% 的代码。
2. **先正确运行，再优化**：
   - 确保程序正确运行，然后再进行性能优化。
3. **不要太提前优化**：
   - 避免过早优化，先确保代码的正确性和可维护性。
4. **优化需要数据支持**：
   - 进行性能优化时需要有数据支持，编译器的优化能力很强，看上去有效的优化不一定实际有效。

#### 1.3 代码优化主要思路
* **性能优化原则**
  1. **二八原则**：
    - 80% 的性能问题通常来自 20% 的代码。
  2. **先正确运行，再优化**：
    - 确保程序正确运行，然后再进行性能优化。
  3. **不要太提前优化**：
    - 避免过早优化，先确保代码的正确性和可维护性。
  4. **优化需要数据支持**：
    - 进行性能优化时需要有数据支持，编译器的优化能力很强，看上去有效的优化不一定实际有效。

* **CPU 密集任务**
  1. **多线程**：
    - 使用多线程并行化计算任务，充分利用多核处理器的计算能力。
    - 使用 `wait` 机制协调线程间的同步。
  2. **优化算法实现**：
    - 避免不必要的递归，使用迭代替代递归。
    - 避免不必要的参数复制，使用引用传递参数。
    - 避免不必要的计算，减少重复计算。
    - 正确使用高效的算法和数据结构。

* **I/O 密集任务**
  1. **内存 I/O 密集**：
    - 使用对象池，避免重复构造和销毁对象。
    - 优化内存访问模式，使用顺序访问提高缓存命中率。
  2. **硬盘 I/O 密集**：
    - 使用异步 I/O 操作，允许程序在等待 I/O 操作完成时继续执行其他任务。
    - 使用缓存减少磁盘 I/O 操作，提高效率。
    - 使用高效的文件系统和磁盘调度算法。
  3. **网络 I/O 密集**：
    - 使用异步网络 I/O 操作，提高并发性和效率。
    - 使用高效的网络协议，减少网络延迟。
    - 使用压缩减少传输的数据量，提高传输效率。

#### 1.4 代码实现常见原则
* **硬件友好代码**
  1. **利用 SIMD 特性**：
    - 现在的 CPU 很多时候都可以对指令并行化，利用 SIMD（Single Instruction, Multiple Data）特性进行向量化计算，提高并行计算性能。
  2. **提升缓存利用率**：
    - 使用结构化数组（SoA）和数组结构（AoS）方式优化数据布局，提高缓存命中率。
    - 避免缓存未命中，优化内存访问模式，使用顺序访问提高缓存命中率。

#### 1.5 性能优化常见手段
* 对象池
* 线程池
* 内存池
* 缓存

### 2. 实现优化

#### 2.1 RVO

```c++
#include <iostream>

class MyObject {
public:
    MyObject() {
        std::cout << "Constructor called" << std::endl;
    }

    MyObject(const MyObject& other) {
        std::cout << "Copy constructor called" << std::endl;
    }
};

MyObject createObject() {
    MyObject obj;
    return obj;
}

int main() {
    MyObject newObj = createObject();
    return 0;
}
```

1. 什么是 RVO？

   RVO，全称 Return Value Optimization（返回值优化），是 C++编译器的一种优化技术。当函数返回一个局部对象时，RVO 允许编译器省略额外的拷贝或移动构造函数的调用，直接在调用位置构造返回对象。

2. RVO 有什么好处？

   RVO 的主要好处是提高性能。通过省略额外的拷贝或移动构造函数的调用，RVO 可以减少不必要的临时对象的创建，从而减少内存使用和提高运行速度。对于大型对象或者拷贝操作开销大的对象，RVO 的性能优势更为明显。

3. 怎么用 RVO？

   你不需要做任何特殊的操作来使用 RVO，它是由编译器自动进行的。只要你的函数返回一个局部对象，编译器就可能会应用 RVO。但是，你应该注意的是，RVO 并不是在所有情况下都会发生，它取决于编译器的实现和你的代码结构。在你的代码中，`createObject`函数返回一个`MyObject`对象，这个对象立即被赋值给`newObj`，这是 RVO 可能会发生的一个场景。

#### 2.2 soa 和 aos

让我们通过一个具体的例子来解释 SOA（Structure of Arrays）和 AOS（Array of Structures）。
假设我们有一个粒子系统，每个粒子都有位置（x，y，z）和速度（vx，vy，vz）。

    ```cpp
    namespace AOS {
        struct Particle
        {
            float x, y, z; // 位置
            float vx, vy, vz; // 速度
        };
        std::array<Particle, 1000> particles;
        // 如果我们想更新所有粒子的位置，我们需要遍历整个数组
        // 这可能会导致缓存未命中，因为位置和速度数据在内存中是交错的。
        update(particles);
    }

    namespace SOA {
        struct Particles
        {
            std::array<float, 1000> x, y, z; // 位置
            std::array<float, 1000> vx, vy, vz; // 速度
        };

        Particles particles;
        // 如果我们想更新所有粒子的位置，我们可以连续地访问 x、y 和 z 数组，这有助于提高缓存命中率
        // 因为这些数据在内存中是连续的。
        update(particles);
    }
    ```

#### 2.3 CRTP

CRTP，全称 Curiously Recurring Template Pattern（奇异递归模板模式），是一种在 C++ 中使用的编程技巧。这种模式涉及到一个类模板，它以自己的派生类作为模板参数。**CRTP 可以用于实现编译时的多态性**，也就是说，**它可以在编译时决定调用哪个函数，而不是在运行时**。这可以提高性能，因为它**避免了虚函数调用的开销**。

    ```cpp
    template <typename Derived>
    class Base {
    public:
        void interface() {
            static_cast<Derived*>(this)->implementation();
        }
    };

    class Derived : public Base<Derived> {
    public:
        void implementation() {
            // 实现具体的功能
        }
    };
    ```

在这个例子中，`Base` 是一个模板类，它有一个 `interface` 方法，这个方法调用 `implementation` 方法。`Derived` 类继承自 `Base`，并提供 `implementation` 方法的实现。

当我们调用 `interface` 方法时，实际上调用的是 `Derived` 类的 `implementation` 方法。这是在编译时决定的，所以没有运行时的虚函数调用开销。

#### 2.4 CAS（Compare-and-Swap）

CAS，全称 Compare-and-Swap（比较并交换），是一种用于实现并发算法的原子操作。这种操作可以在多线程环境中安全地读取和更新共享数据，而无需使用锁。

CAS 操作接受三个参数：一个内存位置、一个预期的旧值和一个新值。如果内存位置的当前值与预期的旧值匹配，那么 CAS 操作就会将新值写入内存位置。否则，操作不会进行任何更改。无论哪种情况，CAS 操作都会返回内存位置的原始值。CAS 操作的一个关键特性是它是原子的，也就是说，它不会被其他线程的操作中断。这使得它在实现无锁数据结构和其他并发算法时非常有用。

    ```cpp
    int compare_and_swap(int* ptr, int old_val, int new_val) {
        int original_val = *ptr;
        if (original_val == old_val) {
            *ptr = new_val;
        }
        return original_val;
    }
    ```

在实际使用中，CAS 操作通常由硬件直接支持，并通过特殊的机器指令实现。在 C++ 中，你可以使用 `<atomic>` 头文件中的 `std::atomic` 类来进行 CAS 操作。

#### 2.5 CAS（Copy and Swap）

- **什么是 CAS（Copy and Swap）？有什么用？**

在 C++ 编程中，"Copy and Swap"（CAS）是一种常用的技术，用于实现赋值操作符（`operator=`）。CAS 的基本思想是先创建一个副本，然后交换副本和原对象。

- **在什么场景下使用？**
    1. **实现赋值操作符**：
        - CAS 是实现赋值操作符（`operator=`）的一种常见方法。它可以简化代码，并提供强异常安全性。
    2. **提供强异常安全性**：
        - 如果你的代码需要在异常发生时保持一致性（即，不会因为异常而处于无效状态），那么 CAS 可能是一个好的选择。在 CAS 中，如果复制操作抛出异常，原对象不会被修改。
    3. **避免自我赋值问题**：
        - 在传统的赋值操作符实现中，你需要检查自我赋值（即，`a = a`）。但是在 CAS 中，由于赋值操作符接受的是一个副本，所以不需要检查自我赋值。

- **注意事项**
    * **性能问题**：
        - CAS 并不适用于所有情况。CAS 的一个主要缺点是它需要进行复制操作，这可能会导致性能问题。如果你的对象很大，或者复制操作很昂贵，那么你可能需要使用其他方法来实现赋值操作符。
    * **总结**：
        - CAS（Copy and Swap）是一种在 C++ 中实现赋值操作符的常用技术。它通过先创建一个副本，然后交换副本和原对象，提供了简化代码和强异常安全性的优势。尽管 CAS 有助于避免自我赋值问题，但在处理大对象或昂贵的复制操作时，可能会导致性能问题。因此，在选择使用 CAS 时，需要权衡其优缺点。

#### 2.6 COW（Copy On Write）

- **什么是 COW（Copy On Write）？有什么用？**

COW，即 Copy On Write，是一种优化策略。在这种策略下，当对象被复制时，并不立即进行实际的复制操作，而是等到对象被修改时才进行复制。这种策略可以避免不必要的复制操作，从而提高程序的性能。

- **在什么场景下使用？**
  1.  **需要复制大量数据但不经常修改的场景**：
      - COW 技术通常在需要复制大量数据，但又不经常修改数据的场景中使用。例如，在字符串操作中，如果一个字符串被复制多次，但只有少数几次会修改字符串，那么使用 COW 技术可以大大提高性能。

  2.  **共享资源的场景**：
      - 在多线程或多进程环境中，多个线程或进程可以共享同一个资源，直到其中一个需要修改资源时才进行复制。这可以显著减少内存使用和提高性能。

- **怎么实现？**
  COW 技术的实现通常依赖于引用计数。以下是实现 COW 的步骤：
  1.  **引用计数**：
      - 每个对象都有一个引用计数，表示有多少个引用指向这个对象。当对象被复制时，不复制对象本身，而是增加引用计数。
  2.  **延迟复制**：
      - 当对象被修改时，首先检查引用计数。如果引用计数大于 1，那么就复制对象，然后修改复制后的对象，同时减少原对象的引用计数。如果引用计数等于 1，那么直接修改对象。

COW（Copy On Write）是一种优化策略，通过延迟复制操作直到对象被修改时才进行实际的复制，从而避免不必要的复制操作，提高程序性能。COW 技术通常在需要复制大量数据但不经常修改的场景中使用，其实现通常依赖于引用计数。通过合理使用 COW，可以显著减少内存使用和提高性能。


#### 2.7 考虑使用延迟计算

一个延迟计算的例子：

    class String{....}
    String s1 = "Hello";
    String s2 = s1;  //在正常的情况下，这一句需要调用new操作符分配堆内存，然后调用strcpy将s1内的数据拷贝到s2里面。但是我们此时s2并没有被使用，所以我们不需要s2，这个时候如果让s2和s1共享一个值，就可以减小这些开销

使用延迟计算进行读操作和写操作：

    String s = "Homer's Iliad";
    cout << s[3];
    s[3] = 'x';

首先调用 operator[] 用来读取 string 的部分值，但是第二次调用该函数式为了完成写操作。读取效率较高，写入因为需要拷贝，所以效率较低，这个时候可以推迟作出是读操作还是写操作的决定。

延迟策略进行数据库操作：有点类似之前写 web 的时候，把数据放在内存和数据库两份，更新的时候只更新内存，然后隔一段时间（或者等到使用的时候）去更新数据库。
在 effective c++里面，则是更加专业的将这个操作封装成了一个类，然后把是否更新数据库弄成一个 flag。以及使用了 mutable 关键字，来修改数据

延迟表达式：

    Matrix<int> m1(1000, 1000), m2(1000, 1000);
    m3 = m1 + m2;
    因为矩阵的加法计算量太大（1000*1000）次计算，所以可以先用表达式表示m3是m1和m2的和，然后真正需要计算出值的时候再真的进行计算（甚至计算的时候也只计算m3[3][2]这样某一个位置的值）

#### 2.8 零拷贝技术

- 概念

  - **零拷贝（ zero-copy ）**技术可以有效地改善数据传输的性能，在内核驱动程序（比如网络堆栈或者磁盘存储驱动程序）处理 I/O 数据的时候，零拷贝技术可以在某种程度上减少甚至完全避免不必要 CPU 数据拷贝操作。
  - **零拷贝就是一种避免 CPU 将数据从一块存储拷贝到另外一块存储的技术**。**针对操作系统中的设备驱动程序、文件系统以及网络协议堆栈而出现的各种零拷贝技术极大地提升了特定应用程序的性能，并且使得这些应用程序可以更加有效地利用系统资源**。这种性能的提升就是**通过在数据拷贝进行的同时，允许 CPU 执行其他的任务来实现的**
  - 概括如下
    - **避免数据拷贝**
      - **避免操作系统内核缓冲区之间进行数据拷贝操作**
      - **避免操作系统内核和用户应用程序地址空间这两者之间进行数据拷贝操作**
      - **用户应用程序可以避开操作系统直接访问硬件存储**
      - **数据传输尽量让 DMA 来做**
    - **综合目标**
      - **避免不必要的系统调用和上下文切换**
      - 需要拷贝的数据可以先被缓存起来
      - 对数据进行处理尽量让硬件来做

- 零拷贝使用场景

  - 在写一个服务端程序时（Web Server 或者文件服务器），文件下载是一个基本功能。这时候服务端的任务是：将服务端主机磁盘中的文件不做修改地从已连接的 socket 发出去，我们通常用下面的代码完成：

    ```c++
    while((n = read(diskfd, buf, BUF_SIZE)) > 0)
       write(sockfd, buf , n);
    ```

  - 基本操作就是循环的从磁盘读入文件内容到缓冲区，再将缓冲区的内容发送到 socket。但是由于 Linux 的 I/O 操作默认是缓冲 I/O。这里面主要使用的也就是 read 和 write 两个系统调用，我们并不知道操作系统在其中做了什么。实际上在以上 I/O 操作中，发生了多次的数据拷贝。

  - 当应用程序访问某块数据时，操作系统首先会检查，是不是最近访问过此文件，文件内容是否缓存在内核缓冲区，如果是，操作系统则直接根据 read 系统调用提供的 buf 地址，将内核缓冲区的内容拷贝到 buf 所指定的用户空间缓冲区中去。如果不是，**操作系统则首先将磁盘上的数据拷贝的内核缓冲区，这一步目前主要依靠 DMA 来传输**，然后再把内核缓冲区上的内容拷贝到用户缓冲区中。接下来，write 系统调用再把用户缓冲区的内容拷贝到网络堆栈相关的内核缓冲区中，最后 socket 再把内核缓冲区的内容发送到网卡上

    <img src="imgs/os/multi_copy.png" alt="multi_copy" style="zoom:80%;" />

  - 从上图中可以看出，共产生了**两次系统调用，四次数据拷贝**，即使使用了 DMA 来处理了与硬件的通讯，CPU 仍然需要处理两次数据拷贝，与此同时，在用户态与内核态也发生了多次上下文切换，无疑也加重了 CPU 负担。在此过程中，我们没有对文件内容做任何修改，那么在内核空间和用户空间来回拷贝数据无疑就是一种浪费，而零拷贝主要就是为了解决这种低效性

  - 零拷贝主要的任务就是避免 CPU 将数据从一块存储拷贝到另外一块存储，主要就是利用各种零拷贝技术，避免让 CPU 做大量的数据拷贝任务，减少不必要的拷贝，或者让别的组件来做这一类简单的数据传输任务，让 CPU 解脱出来专注于别的任务。这样就可以让系统资源的利用更加有效

- 零拷贝技术使用

  - **使用 mmap**

    - 减少拷贝次数的一种方法是调用 mmap()来代替 read 调用：

      ```c++
      buf = mmap(diskfd, len);
      write(sockfd, buf, len);
      ```

    - 应用程序调用 mmap()，**磁盘上的数据会通过 DMA 被拷贝的内核缓冲区**，**接着操作系统会把这段内核缓冲区与应用程序共享**，**这样就不需要把内核缓冲区的内容往用户空间拷贝**。应用程序**再调用 write()**，**操作系统直接将内核缓冲区的内容拷贝到 socket 缓冲区中**，这一切都发生在内核态，最后，socket 缓冲区再把数据发到网卡去

    <img src="imgs/os/mmap.png" alt="mmap" style="zoom:80%;" />

  - 使用 mmap 替代 read 很明显减少了一次拷贝，当拷贝数据量很大时，无疑提升了效率。**但是使用 mmap 是有代价的。当你使用 mmap 时，你可能会遇到一些隐藏的陷阱。例如，当你的程序 map 了一个文件，但是当这个文件被另一个进程截断(truncate)时, write 系统调用会因为访问非法地址而被 SIGBUS 信号终止**。SIGBUS 信号默认会杀死你的进程并产生一个 coredump,如果你的服务器这样被中止了，那会产生一笔损失。通常可以使用以下解决方案避免这种问题：

    - **为 SIGBUS 信号建立信号处理程序**

      - 当遇到 SIGBUS 信号时，信号处理程序简单地返回，write 系统调用在被中断之前会返回已经写入的字节数，并且 errno 会被设置成 success，但是这是一种糟糕的处理办法，因为你并没有解决问题的实质核心

    - **使用文件租借锁**

      - 通常我们使用这种方法，在**文件描述符上使用租借锁**，我们为文件向内核申请一个租借锁，当其它进程想要截断这个文件时，内核会向我们发送一个实时的`RT_SIGNAL_LEASE`信号，告诉我们内核正在破坏你加持在文件上的读写锁。这样在程序访问非法内存并且被 SIGBUS 杀死之前，你的 write 系统调用会被中断。write 会返回已经写入的字节数，并且置 errno 为 success。我们应该在 mmap 文件之前加锁，并且在操作完文件后解锁：

        ```c++
        if(fcntl(diskfd, F_SETSIG, RT_SIGNAL_LEASE) == -1) {
            perror("kernel lease set signal");
            return -1;
        }
        /* l_type can be F_RDLCK F_WRLCK  加锁*/
        /* l_type can be  F_UNLCK 解锁*/
        if(fcntl(diskfd, F_SETLEASE, l_type)){
            perror("kernel lease set type");
            return -1;
        }
        ```

- 使用 sendfile

  - sendfile 原型

    ```c++
    #include<sys/sendfile.h>

    ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
    ```

  - 系统调用`sendfile()`在代表输入文件的描述符`in_fd`和代表输出文件的描述符`out_fd`之间传送文件内容（字节）。描述符`out_fd`**必须指向一个套接字**，而`in_fd`指向的文件必须是可以`mmap`的。这些局限限制了 sendfile 的使用，使**sendfile 只能将数据从文件传递到套接字上**，反之则不行。使用 sendfile 不仅减少了数据拷贝的次数(1 次)，还减少了上下文切换(一次调用，两次切换)，数据传送始终只发生在 kernel space

    <img src="imgs/os/sendfile.png" alt="sendfile" style="zoom:80%;" />

  - 在调用 sendfile 时，如果有其它进程截断了文件会发生什么呢？假设我们没有设置任何信号处理程序，**sendfile 调用仅仅返回它在被中断之前已经传输的字节数，errno 会被置为 success**。如果我们在调用 sendfile 之前给文件加了锁，sendfile 的行为仍然和之前相同，我们还会收 RT_SIGNAL_LEASE 的信号

  - sendfile 仍然存在一次拷贝，就是页缓存到 socket 缓存的拷贝。现在我们仅仅需要把**缓冲区描述符传到 socket 缓冲区，再把数据长度传过去，这样 DMA 控制器直接将页缓存中的数据打包发送到网络中就可以了**

    <img src="imgs/os/zero_sendfile.png" alt="zero_sendfile" style="zoom:80%;" />

    - sendfile 系统调用利用 DMA 引擎将文件内容拷贝到内核缓冲区去，然后将带有文件位置和长度信息的缓冲区描述符添加 socket 缓冲区去，这一步不会将内核中的数据拷贝到 socket 缓冲区中，**DMA 引擎会将内核缓冲区的数据拷贝到协议引擎中去，避免了最后一次拷贝**

    - 不过这一种收集拷贝功能是需要硬件以及驱动程序支持的。**需要网卡支持 SG-DMA**（_The Scatter-Gather Direct Memory Access_）技术（和普通的 DMA 有所不同）

    - 可以在 Linux 系统通过下面这个命令，查看网卡是否支持 scatter-gather 特性：

      ```shell
      $ ethtool -k eth0 | grep scatter-gather
      scatter-gather: on
      ```

- 使用 splice

  - sendfile 只适用于将数据**从文件拷贝到套接字**上，限定了它的使用范围。Linux 在 2.6.17 版本引入 splice 系统调用，用于**在两个文件描述符中移动数据**

  - 原型

    ```c++
      #define _GNU_SOURCE         /* See feature_test_macros(7) */
      #include <fcntl.h>
      ssize_t splice(int fd_in, loff_t *off_in, int fd_out, loff_t *off_out, size_t len, unsigned int flags);
    ```

    - splice 调用在**两个文件描述符之间移动数据**，而**不需要数据在内核空间和用户空间来回拷贝**。他从`fd_in`拷贝`len`长度的数据到`fd_out`，**但是有一方必须是管道设备，这也是目前 splice 的一些局限性**。如果`fd_in`是一个管道文件描述符，那么 off_in 必须设为 NULL；如果不是，那么表示从输入数据流的何处开始读取数据，此时若`fd_in`为 NULL，则表示从输入数据流的当前偏移位置读入；不为 NULL，则指出具体的偏移位置。``fd_out/off_out`同理使用与于输出流。flags 参数有以下几种取值
    - SPLICE_F_MOVE ：尝试去移动数据而不是拷贝数据。这仅仅是对内核的一个小提示：**如果内核不能从 pipe 移动数据或者 pipe 的缓存不是一个整页面，仍然需要拷贝数据**。Linux 最初的实现有些问题，**所以从 2.6.21 开始这个选项不起作用**，后面的 Linux 版本应该会实现
    - SPLICE_F_NONBLOCK ：splice 操作不会被阻塞。然而，如果文件描述符没有被设置为不可被阻塞方式的 I/O ，那么调用 splice 有可能仍然被阻塞
    - SPLICE_F_MORE： 后面的 splice 调用会有更多的数据。

  - splice 调用利用了 Linux 提出的**管道缓冲区机制**， 所以**至少一个描述符要为管道**。以上几种零拷贝技术都是**减少数据在用户空间和内核空间拷贝技术实现的**，**但是有些时候，数据必须在用户空间和内核空间之间拷贝**。这时候，我们只能**针对数据在用户空间和内核空间拷贝的时机上下功夫了**。**Linux 通常利用写时复制(copy on write)来减少系统开销，这个技术又时常称作 COW**

- 使用 tee

  - tee 函数用于**两个管道之间复制数据**，也是零拷贝操作，它不消耗数据，源文件描述符上面的数据仍然可以用于后续读操作

  - 原型

    ```c++
    #include <fcntl.h>
    ssize_t tee(int fd_in, int fd_out, size_t len, unsigned int flags);
    ```

  - 上述参数与 splice 相同，但 fd_in 和 fd_out 都必须是管道文件描述符。成功返回两个文件描述符之间复制的数据，返回 0 表示没任何数据复制，失败返回-1 并设置 errno


### 3. 编译器优化

#### 3.1 pgo
PGO,全称为 Profile-Guided Optimization(基于分析的优化),是一种编译器优化技术,它通过收集程序运行时的性能信息来指导编译器优化.

PGO 的工作流程通常包括以下几个步骤:
1. **编译**:首先,你需要使用特殊的编译器选项来编译你的程序,这会使得程序在运行时收集性能信息.
2. **运行**:然后,你需要运行你的程序,并让它处理一些典型的工作负载.这会生成一个性能分析文件,其中包含了程序运行时的性能信息.
3. **优化编译**:最后,你需要再次使用特殊的编译器选项来编译你的程序,这次编译器会使用性能分析文件中的信息来指导优化.

通过这种方式,编译器可以了解到程序的实际运行情况,例如哪些代码经常被执行,哪些代码很少被执行,哪些条件分支的预测结果通常是什么等等.然后,编译器可以使用这些信息来进行更有效的优化,例如更精确地进行内联,更智能地安排代码布局,更准确地预测条件分支等等.

PGO 可以显著提高程序的运行速度,特别是对于那些性能敏感的应用程序.然而,PGO 也有一些缺点,例如它会增加编译时间和编译复杂性,因此并不是所有的项目都适合使用 PGO.


### 4. 缓存
* 减少内存访问延迟：cpu缓存
* 减少磁盘IO读写延迟：文件缓存
* 减少数据库查询延迟：数据库缓存
* 减少网络IO读写延迟：web缓存/ 代理服务器缓存/ CDN缓存
* 减少cpu计算延迟：cacheData

#### 4.1 如何解决缓存空间受限问题
缓存为了快速访问一般都是通过哈希表的方式存储。
但当需要限制缓存空间大小的时候，即数据会不断增加，但缓存空间有限，就需要考虑那些缓存的数据需要被淘汰。
常见的淘汰方法有这些。
* LRU（Least Recently Used）：移除最近最少使用的数据。
* LFU（Least Frequently Used）：移除使用频率最低的数据。
* FIFO（First In First Out）：移除最早进入缓存的数据。

- **汇编指令**：汇编指令是人类可读的指令，通常直接对应于机器指令（CPU 指令）。每条汇编指令通常对应一条或多条机器指令。
- **指令执行过程**
  1. **取值（Fetch）**：从内存中取出指令。
  2. **译码（Decode）**：将取出的指令译码为 CP U 可以理解的操作。
  3. **执行（Execute）**：执行指令的操作，例如算术运算、逻辑运算、内存访问等。
  4. **写回（Write Back）**：将执行结果写回寄存器或内存。

- **时钟周期消耗**
  - **取值、译码、写回**：这些阶段的时钟周期消耗相对固定，通常都是一个时钟周期。
  - **执行**：执行阶段的时钟周期消耗取决于指令的类型，可以是一个时钟周期到几十个时钟周期。例如，简单的算术运算可能只需要一个时钟周期，而复杂的指令（如除法、内存访问）可能需要多个时钟周期。

- **超标量结构**
  - **超标量结构**：现代 CPU 通常使用超标量结构，可以在一个核内一个时钟周期内执行多条指令。这种结构通过增加多个执行单元，使得 CPU 可以并行处理多条指令，从而提高指令执行的效率。

#### 4.2 解释

- **内核调用**：指的是从用户态切换到内核态执行系统调用的时间。
- **线程上下文切换**：包括直接成本和总成本（包括缓存失效）。
- **C++ 异常抛出并捕获**：指的是在 C++ 中抛出和捕获异常的时间。
- **内存分配（malloc/free）**：指的是使用 `malloc` 和 `free` 进行内存分配和释放的时间。
- **互斥锁加锁/解锁**：包括无竞争和有竞争两种情况。
- **读写锁加锁/解锁**：包括无竞争和有竞争两种情况。
- **进程创建**：指的是创建一个新进程的时间。
- **文件I/O操作**：指的是对小文件进行读写操作的时间。
- **网络I/O操作**：指的是发送和接收小数据包的时间。
- **系统调用**：包括简单和复杂的系统调用。
- **缓存命中**：包括 L1、L2 和 L3 缓存的命中时间。
- **内存访问（DRAM）**：指的是访问主内存的时间。
- **磁盘I/O操作**：包括 SSD 和 HDD 的读写操作时间。

这些时间范围是基于典型的硬件和操作系统环境，实际时间可能会因具体的硬件配置和系统负载而有所不同。

流水线技术，指的是一个指令没有完整执行完，另一个指令就已经在执行了是吧？

是的，你的理解是正确的。流水线技术的核心思想是将指令的执行过程分解成多个阶段，并允许这些阶段并行处理不同的指令。这样，当一个指令还在执行的过程中，另一个指令就可以开始执行它的下一个阶段。这种并行性可以显著提高处理器的效率和吞吐量。

具体来说，流水线技术的工作方式如下：

1. **取值（Fetch）**：从内存中取出指令。
2. **译码（Decode）**：将取出的指令译码为CPU可以理解的操作。
3. **执行（Execute）**：执行指令的操作，例如算术运算、逻辑运算、内存访问等。
4. **写回（Write Back）**：将执行结果写回寄存器或内存。

在流水线中，这四个阶段可以同时进行，每个阶段处理不同的指令。例如：

- 指令1在执行阶段。
- 指令2在写回阶段。
- 指令3在译码阶段。
- 指令4在取值阶段。

这种并行处理可以减少每个指令完成所需的总时间，因为每个时钟周期内都有一个指令的某个阶段被处理。然而，流水线技术也引入了一些挑战，如流水线冒险（数据冒险、控制冒险和结构冒险），需要通过各种技术（如转发、暂停流水线、分支预测等）来管理和解决。

总之，流水线技术通过允许指令在不同阶段并行执行，提高了处理器的效率和吞吐量，但同时也需要处理由此引入的复杂性和挑战。


如果这些都存在的话，执行一个寄存器加法命令，最少需要4个时钟周期，是嘛？

执行一个寄存器加法命令确实会经历取值、译码、执行和写回这四个阶段，但是否需要四个时钟周期取决于具体的处理器设计和流水线的实现方式。

在没有流水线的简单处理器中，每个指令确实需要四个时钟周期来完成，因为每个阶段必须在前一个阶段完成后才能开始。这意味着如果一个寄存器加法指令正在执行，它将独占处理器四个周期。

然而，在流水线处理器中，情况就不同了。流水线处理器将这四个阶段分开，并允许每个阶段同时处理不同的指令。例如，当一个寄存器加法指令在执行阶段时，另一个指令可以同时在取值阶段，第三个指令在译码阶段，以此类推。这样，尽管每个指令仍然需要经过这四个阶段，但流水线的设计允许在每个时钟周期内完成一个指令的某个阶段，从而减少了每个指令的平均执行时间。

在流水线处理器中，一个寄存器加法指令可能只需要一个时钟周期就可以完成，但这取决于流水线的宽度和是否有任何流水线冒险（如数据冒险、控制冒险等）需要处理。如果流水线是无冒险的，并且有足够的执行单元来处理指令，那么每个指令可以在每个时钟周期内完成一个阶段，从而在四个时钟周期内完成整个指令。

总结来说，虽然指令执行的基本阶段（取值、译码、执行、写回）是固定的，但是否需要四个时钟周期来完成一个寄存器加法指令取决于处理器的具体设计和是否使用了流水线技术。


### 98. attach files
#### 1. cas

    ```cpp
    #include <algorithm>

    class MyClass {
    public:
        MyClass(int size) : size(size), data(new int[size]) {}

        // 赋值操作符
        MyClass& operator=(MyClass other) {
            swap(*this, other);
            return *this;
        }

        // 交换函数
        friend void swap(MyClass& first, MyClass& second) noexcept {
            std::swap(first.size, second.size);
            std::swap(first.data, second.data);
        }

        ~MyClass() {
            delete[] data;
        }

    private:
        int size;
        int* data;
    };
    ```

#### 2. cow

    ```cpp
    #include <iostream>
    #include <cstring>

    class String {
    public:
        String(const char* str = "") : data(new Data(str)) {}

        // 拷贝构造函数
        String(const String& other) : data(other.data) {
            ++data->refCount;
        }

        // 赋值操作符
        String& operator=(const String& other) {
            if (this != &other) {
                if (--data->refCount == 0) {
                    delete data;
                }
                data = other.data;
                ++data->refCount;
            }
            return *this;
        }

        // 修改字符串
        void setChar(size_t index, char c) {
            if (data->refCount > 1) {
                data = new Data(data->str);
            }
            data->str[index] = c;
        }

        // 获取字符串
        const char* getStr() const {
            return data->str;
        }

        ~String() {
            if (--data->refCount == 0) {
                delete data;
            }
        }

    private:
        struct Data {
            char* str;
            size_t refCount;

            Data(const char* str) : str(new char[strlen(str) + 1]), refCount(1) {
                strcpy(this->str, str);
            }

            ~Data() {
                delete[] str;
            }
        };

        Data* data;
    };

    int main() {
        String s1("Hello");
        String s2 = s1;

        s2.setChar(0, 'h');

        std::cout << "s1: " << s1.getStr() << std::endl;
        std::cout << "s2: " << s2.getStr() << std::endl;

        return 0;
    }
    ```


### 99. quiz
#### 1. 服务器高并发的解决方案
1. 应用数据与静态资源分离
将静态资源(图片,视频,js,css等)单独保存到专门的静态资源服务器中,在客户端访问的时候从静态资源服务器中返回静态资源,从主服务器中返回应用数据.

2. 客户端缓存
因为效率最高,消耗资源最小的就是纯静态的html页面,所以可以把网站上的页面尽可能用静态的来实现,在页面过期或者有数据更新之后再将页面重新缓存.或者先生成静态页面,然后用ajax异步请求获取动态数据.

3. 集群和分布式
(集群是所有的服务器都有相同的功能,请求哪台都可以,主要起分流作用)<br>
(分布式是将不同的业务放到不同的服务器中,处理一个请求可能需要使用到多台服务器,起到加快请求处理的速度.)<br>
可以使用服务器集群和分布式架构,使得原本属于一个服务器的计算压力分散到多个服务器上.同时加快请求处理的速度.

4. 反向代理
在访问服务器的时候,服务器通过别的服务器获取资源或结果返回给客户端.
* 假设在某一时刻由几万个并发请求同时产生,请设计一个方案来处理这种情况.


#### 2. 虚函数表开销
虚函数表（vtable）的使用确实会引入一些性能开销，主要体现在以下几个方面：
* **1. 虚函数调用的间接寻址**
    - **解释**：虚函数调用需要通过虚函数表进行间接寻址，这比直接调用函数要慢。
    - **原因**：编译器在编译时无法确定具体调用哪个函数，因此在运行时需要通过虚函数表查找函数地址，然后进行调用。这种间接寻址会增加指令开销。

* **2. 破坏指令缓存（Instruction Cache）**
    - **解释**：虚函数调用可能会破坏指令缓存（Instruction Cache），因为虚函数表中的函数地址可能指向不同的内存位置。
    - **原因**：现代处理器使用指令缓存来加速指令的执行。当程序执行过程中频繁跳转到不同的内存位置时，指令缓存可能会失效（cache miss），导致性能下降。

* **3. 破坏数据缓存（Data Cache）**
    - **解释**：虚函数表的访问可能会破坏数据缓存（Data Cache），因为虚函数表和实际函数实现可能位于不同的内存区域。
    - **原因**：数据缓存用于加速数据的访问。当程序访问虚函数表时，可能会导致数据缓存失效（cache miss），从而增加内存访问延迟。

