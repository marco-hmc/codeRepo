---
title: "(3)第二章线程同步精要"
subtitle: "muduo阅读笔记"
layout: post
author: "Marco"
header-style: text
hidden: true
tags:
  - 计算机网络
  - linux多线程服务端编程

---

 ## 第二章线程同步精要

### 1. 导语

- ***多线程编程入门***

  ​	对比过很多资料，最后的多线程入门资料还是在[leetcode](https://leetcode-cn.com/problems/print-in-order/solution/c-hu-chi-suo-tiao-jian-bian-liang-xin-hao-liang-yi/)上，有练习题，有答案，有讲解，照着敲很快就能熟悉多线程编程的用法了。

- ***线程同步的四项原则***

  - 尽量最低程度共享对象，减少需要同步的场合。即减少多个线程之间的通信，如果某个对象需要在多个线程暴露，优先考虑immutable对象，即不可变对象；实在不行才用同步措施(锁)等去保护；
  - 使用高级的并发编程构建，如taskQueue、Producer-Consumer Queue、CountDwonLatch
  - 必须用底层同步原语(如mutex、condition_variable等)，只用非递归的互斥锁以及条件变量，少用读写锁，不要用信号量
  - 除了使用atomic整数之外，不自己编写lock-free代码，也不要使用内核级别的同步原语。

  > - [atomic是什么？](https://wenku.baidu.com/view/33241bca0a75f46527d3240c844769eae009a389.html)
  >
  >   - atomic是表示原子，atomic_int、atomic_bool等数据结构，无需借助锁机制，也能够在多线程下正确工作。
  >
  > - [atomic实现原理](https://zhuanlan.zhihu.com/p/115355303)
  >
  >   - 不同平台原子操作的实现不一样，但多线程导致的数据冲突都是因为多核cpu同时在跑一份数据，本质上都是保证这个数据在不同cpu的时候，有且只有一个在进行操作。下面是cacheline lock的实现方法
  >
  >   - 首先每个cpu核心都有其对应的高速cache
  >
  >     ![在这里插入图片描述](https://s2.loli.net/2022/04/14/IxfwdV2vROmhnS8.png)
  >
  >     a) CPU1发出"Read Invalidate"消息，其他CPU将原子变量所在的缓存无效，并从Cache返回数据。CPU1将Cache line置成Exclusive状态。然后将该**cache line标记locked**。b) 然后CPU1读取原子变量，修改，最后写入cache line。c) 将cache line置位unlocked。
  >
  >     在步骤a)和c)之间，如果其他CPU（例如CPU1）尝试执行一个原子递增操作，CPU1会发送一个"Read Invalidate"消息，CPU0收到消息后，检查对应的cache line的状态是locked，暂时不回复消息（CPU1会一直等待CPU0回复Invalidate Acknowledge消息）。直到cache line变成unlocked。这样就可以实现原子操作。我们称这种方式为锁cache line。这种实现方式必须要求操作的变量位于一个cache line。
  >
  > - [多核cpu的缓存以及如何保持缓存一致性](https://blog.csdn.net/zhizhengguan/article/details/121275331)
  >
  >   - 如果对多核cpu还存疑，可以继续看这个。
  >
  > - [什么是lock-free](https://zhuanlan.zhihu.com/p/53012280)
  >
  >   - lock-free是不通过互斥锁、信号量等锁机制实现多线程安全的编程方法。而lock-free的实现实际上是通过atomic操作实现的。

### 2. 互斥器mutex

- ***互斥器作者建议的使用原则***

  - 用RAII手法封装mutex的创建、销毁、加锁、解锁。实际上把锁的创建写进一个类的构造函数(这种类一般叫guard)，把锁的销毁写进析构函数，那用这个类生成的锁对象，再超出声明周期后，就会自动销毁。而不用手动解锁，锁都没了，自然就不用手动解锁了。
  - 只用非递归的mutex
  - 每次构造guard对象的时候，思考调用栈上已有的锁，防止加锁顺序不同导致的死锁。

  ------

  - 不使用跨进程的mutex，进程通信只用TCP sockets(便于多机情况)。

- ***为什么不建议使用递归的mutex？***

  - ***什么是递归、非递归的mutex？***

    - 递归锁：同一个线程可以多次获取同一个递归锁，不会产生死锁
    - 非递归锁：如果一个线程多次获取同一个非递归锁，则会产生死锁。

  - ***答案不是因为性能***

    - 首先排除一个常见原因，性能。非递归mutex和递归的其实性能差不多，前者只是少了一个计数器，仅此而已。

  - ***递归锁不容易维护，有可能会出现偶尔出现的crash***

    > ```c++
    > MutexLock mutex;
    > 
    > void foo()
    > {
    >     mutex.lock();
    >     // do something
    >     mutex.unlock();
    > }
    > 
    > void bar()
    > {
    >     mutex.lock();
    >     // do something
    >     foo();
    >     mutex.unlock();    
    > }
    > ```

    - 作者以[NonRecurisiveMutest.cc](https://github.com/chenshuo/recipes/tree/master/thread/test)这个为例子，如果mutex是递归的话，push_back()可能(但不总是)导致迭代器失效，程序偶尔会crash，这种错误不好debug。
    - 而这种偶发的crash，发生在调用函数和被调用函数都以为自己拿到了锁，如果恰好都在修改一个对象的时候，这时候就容易crash。
    - 而如果使用非递归锁，这种错误就会提前暴露出来，死锁比偶发的crash总归是好debug。

  - ***如果上面这个用递归锁的话怎么实现？***

    - 不可以直接用递归锁，因为bar()申请了锁，进入到foo()之后，foo()也申请这把锁，因此foo()阻塞了，而bar()在foo()执行完之前，也不释放锁，死锁就产生了。

    - 解决方法在于将foo变成两个函数

      ```c++
      MutexLock mutex;
      
      void foo()
      {
          mutex.lock();
          // do something
          mutex.unlock();
      }
      
      void foo_nolock()
      {
          // do something
      }
      
      void bar()
      {
          mutex.lock();
          // do something
          foo_nolock();
          mutex.unlock();    
      }
      ```

- ***一个线程正在析构对象，而另一个对象却正在调用它的成员函数导致的死锁问题。***

  - [MutualDeadLock.cc](https://github.com/chenshuo/recipes/tree/master/thread/test)

### 3. 条件变量condition variable

- 以多线程的队列为例子

  ```c++
  muduo::MutextLock mutex;
  muduo::Condition cond(mutex);
  std:deque<int> queue;
  
  //消费者
  int dequeue(){
      // queue pop掉最后一个，并返回
      MutexLockGuard lock(mutex);
      while(queue.emtpy()){ // 如果意不能用if，必须用while，避免虚假唤醒
          cond.wait(); // 这一步会unlock mutex,并进入等待，不会与其他线程产生死锁
      }
      int top = queue.front();
      queue.pop_front();
      return top;
  }
  ```

  - ***为什么一定要用while循环，而不是if判断？***
    - 简单来说就是cv有可能会出现[虚假唤醒](https://www.zhihu.com/question/271521213)的情况，用while，不用if的话就可以多次检验。
    - 给一个虚假唤醒的场景，一个线程A，一个线程B被notify，但是A还没有获得锁，B线程先获得了锁，并消费了队列中的数据(或者说notify的条件又变成不满足了)，线程B结束后，A获得了锁，但这个时候条件已经不满足了。

### 4. 不要用读写锁和信号量

- ***什么是读写锁***
  - [读写锁的c++实现](https://zhuanlan.zhihu.com/p/374042984)
    - 当读写锁中的读锁被某个线程加上时，先加上读互斥锁，这样保证了其他线程不能再读了；接着，再加上写互斥锁，同时计数加上 1，这样保证了其他线程不能再写了。接着，把读互斥锁释放掉，因为要允许其他线程也能读这个共享变量。**也就是说，多次读时，只需要加一把写锁，表明其他线程暂时不能执行写操作。**
    - 当读写锁中的读锁被某个线程释放时，也是加上了读互斥锁，这样保证多个线程同时释放读写锁中的读锁时没有问题。**当没有线程读操作时，释放写互斥锁。表明其他线程可以执行写操作了。**

- ***为什么不要用读写锁？***
  - 不易维护，读写锁本质上也是通过mutex来实现的，不是真的说上了读锁，就真的不可以改了，程序员还是可以改的，有可能在程序的维护阶段，被新来的程序员在原来的读锁保护的函数中调用了写函数。
  - 读写锁的开销只会比mutex大。
- ***为什么不要用信号量？***
  - 信号量可以被条件变量和mutex的组合方式实现，而且更不容易出错。

### 5. 总结

- 线程同步的四项原则，尽量用高层同步方法(线程池、队列、倒计时等)，mutex和cv都是非常底层的同步原语，在开发中往往都用更高级的工具。但是使用mutex和cv有一个好处就是，分析工具更便于分析；现在很多高级的框架，甚至乎可以让你像写单线程程序一样写多线程，如Java servlet
- 种种优化方法在没有数据支持的情况下，是靠不住的。很多人误认为用锁会让程序变慢，但实际上影响性能的不是锁，而是锁争用。要学会在程序的复杂度和性能之间取得平衡，并考虑机器扩容的可能。
- 多机的可扩展能力比单机的性能优化更重要，更值得投入精力。
- 