## 缓存

### 1. 导言

* **缓存是什么做什么，有什么用？**
* **缓存的组成是怎么样的？**
* **缓存的是如何工作的？**

本文从上面这些角度出发，希望能够让读者知道缓存的作用以及原理。



### 2. 缓存是什么

* ***缓存是什么，有什么用？***

  缓存是使用SRAM技术的存储器，因为CPU工作频率和内存工作频率相差太远，CPU工作极易受限于内存IO速度，因此希望能够有一个以牺牲容量为代价，提升IO读写速度的存储媒介，而这就是缓存。

  * 存储技术：

    * SRAM：多用于缓存，由六个晶体管组成，读写快，容量小，贵，掉电丢失数据；
    * DRAM：多用于内存，由一个二极管和一个电容构成，读写次快，容量次大，次贵，掉电丢失数据；
    * ROM：多用于硬盘，读写最慢，容量最大，最便宜，掉电不丢失数据。

    

### 3. 缓存的组成

* ***缓存的结构是怎么样的？***

  - L1缓存
    - 指令缓存：Insturuction cache, I-Cache
    - 数据缓存：Data cache, D-cache
  - L2缓存
    - 统一缓存：不区分指令和数据
  - L3缓存
    - 多核心共享

* ***缓存为什么要采取这种分级设计***

  可以假设先you

* ***为什么L1采用分离的缓存，而L2采用统一缓存？***

  - **原因1：**因为处理器是按照123的顺序访问缓存的，而L1分离缓存后可以解决取指令单元和取数据单元的竞争。而L2就无所谓了。
  - **原因2：**L2只是无所谓是否采用分离缓存，而采用统一缓存的原因在于，提供缓存利用率。避免数据缓存满了，但是指令缓存还是空的问题。

* ***L3是如何共享的***

  这里的L3缓存其实在早期是不在CPU芯片上的，是在主板上，又叫做片外缓存，现在集成技术好了，才放回到芯片内部，使得传输的物理距离更短，且不占用系统总线。所以L3较L1和L2是更接近L3的。

  

### 4. 缓存的工作原理

* ***工作的基本原理***

  * 时间局部性：如果一个数据被访问，那这个数据可能近期还会被访问。
  * 空间局部性：如果一个数据被访问，那这个数据附近可能还会被使用。

  基于这两个朴素的先验知识，在CPU第一次向内存访问数据的时候，可以把这个数据以及附近的数据一块保存到缓存上去，那接下来大概率CPU访问的数据将会出现在缓存中。

* **CPU、缓存和内存整体的工作流程**

  ```mermaid
  graph TB
  CPU --> 缓存
  缓存 --如果命中则返回--> CPU
  缓存 --如果未命中则读内存--> 内存
  内存 --内存读到数据再写回缓存--> 缓存
  ```

  - ***CPU是根据内存地址去访问数据，怎么找到对应缓存数据的呢？***

    很简单，缓存和内存地址有一个映射，根据这个映射关系，可以将内存地址转为缓存地址，具体的映射方式可以用`直接映射、全相联映射、组相联映射`等关键词去搜索。

    

* ==***可以读写另一个处理器的缓存呢？***==

  

* ***CPU指令运行周期中，`取码->译码->执行(访存)->写回`，中的访存和写回对象是谁？***

  缓存。那肯定就有一个关键问题了，如果把最新数据写在了缓存，那缓存什么时候跟内存同步呢？要知道这个同步是很重要的，有可能其他处理器也马上要使用这个数据，从内存得到的这个数据却不是最新的，超出了预期结果。

  这个多核缓存保持一致性的协议就是MESI协议，下面继续展开。





#### 4.1 MESI协议

- ***什么是MESI协议？***

  低代价（即快速）保证不同核之间的缓存一致性的协议就是MESI协议。

- ==***MESI协议的工作原理***==

  > - Cache 中的数据是**按块读取**的，当CPU访问某个数据时，会假设该数据附近的数据以后会被访问到，因此，第一次访问这一块区域时，会将该数据连同附近区域的数据（共64字节）一起读取进缓存中，那么**这一块数据称为一个Cache Line 缓存行**。
  
  * M(修改，Modified)：本地处理器已经修改缓存行, 即是脏行, 它的内容与内存中的内容不一样. 并且此cache只有本地一个拷贝(专有)
  * E(专有，Exclusive)：缓存行内容和内存中的一样, 而且其它处理器都没有这行数据.
  * S(共享，Shared)：缓存行内容和内存中的一样, 有可能其它处理器也存在此缓存行的拷贝.
  * I(无效，Invalid)：缓存行失效, 不能使用.



### 5. 知识点

- ***缓存有哪些***

  * CPU缓存
* 磁盘缓存
  * 应用缓存

  前两个都是硬件角度，第三个需要从软件设计、应用场景出发。



- ***如何提高缓存命中率***

  回答这个问题，要注意角度，是CPU缓存还是各种应用层面的缓存概念。

  - **CPU缓存：**

    在硬件层面中，整体的思路是时间局部性和空间局部性，简单来说就是即当前的时间段会优先使用连续的内存块，而这部分我们是不能更改的。我们的优化思路只能够是写出一些更加契合这一原则的代码，如数据读写都是行读写先的，因此对二维数组`A[i][j]`的遍历应该是先行，后列。

    除此之外，多进程任务中，可以考虑绑定核。

  - **应用层面，以redis为代表：**

    - **缓存对象要合理选择：**选择高频访问，低频写的，如果是频繁写的数据，缓存要经常更新。
    - **合理的更新策略：**一般就是LRU那种。
    - **预热：**提前将数据加载到缓存中。这个只能在起动初期的时候起到作用，因为一半刚启动的时候，缓存区为0，可以提前加载一些可能数据作为准备。
    - **小缓存粒度：**粒度太大，难命中。因为缓存是空间大小固定的，粒度大了，存放的量就少了，命中的概率也就低了。除此之外，粒度太大的时候，如果当中一些元素被修改了，那这整一个大粒度的cache也失效了，需要移除。
    - **扩容：**和多处理器的缓存类似，是分布式扩容。因为单机的缓存容量天花板是低垂的，搞成分布式就好了。但是分布式也会有新的问题，这里就不谈了。

    > 相应的，redis有可能因为新缓存大批量同时到期等等缓存失效因素，导致所有请求直接访问数据库，使得数据库服务器访问压力过大崩溃。

  


### 6. 总结