## 单元测试

### 一、整体上看测试

1. 代码是一种负债，而不是一种资产。人们通常认为测试越多越好，事实并非如此，引入的代码越多，软件中潜在错误的表面积就越大，项目的维护成本就越高。用尽可能少的代码解决问题总是更好。
2. 测试也是代码。应该将它们视为旨在解决特定问题的代码库的一部分：确保应用程序的正确性。与任何其他代码一样，单元测试也容易出现错误并需要维护。
3. 测试覆盖率
    1. 代码覆盖率：测试中执行的代码行数/生产中执行的代码行数
    2. 分支覆盖率：测试中所有执行到的分支数/生产中所有可能执行到的分支数
    3. 低覆盖率能够说明测试用例不够，但是高覆盖率并不能说明测试用例优秀。反而会带来一些不必要的麻烦比如维护成本、对不必要的测试验证投入较高的时间、新版本可能永远延期发布等
    4. 总之测试覆盖率是一个指标而不是一个目标
4. 一个好的测试套件具有以下属性：
    1. 它被集成到开发周期中。
    2. 它只针对代码库中最重要的部分。
    3. 它以最低的维护成本提供最大的价值。

### 二、单元测试的定义

    运行测试的时候总会在内存中新建被测系统（SUT），所以共享依赖都是进程外的
    但是进程外的系统不一定是共享依赖，只要其返回结果总是不变的，就不会影响到测试结果
    比如数据库是一个共享依赖，配置文件

    是一个私有且不变的依赖，内存缓存是一个私有且可变的依赖
    一个共享或者可变的依赖称为一个交互方


1. 三个重要属性
    1. 验证一小段代码
    2. 执行快
    3. 具有隔离性
2. 对于第三个属性的理解差异催生出两个流派
    1. 经典派：主张将其视为单元测试的本身与彼此的隔离，经典派认为一个单元指的是单一功能，应当互相隔离的是单元测试本身，而不是单元代码，确保各个测试在运行中互不影响。

    经典派往往采用自下而上（inside-out）的TDD流程，优先建立核心的领域模型，再逐步添加周边功能

    2. 伦敦派：主张将其视为被测系统与其合作者（依赖项）的隔离。伦敦派认为一个单元指的就是一段代码（往往是一个类），因此所谓隔离，就是应当把被测系统（SUT）与其交互方隔离出来，也即所有的共享及可变依赖都应当使用测试替身来替换（mock）。这样才能在测试中只关注单个类。
        提供更细的测试粒度，每次只专注一个类
        对于一组相关关联的复杂的类，因为所有交互方都mock了
        因为测试的粒度很小，在测试失败的时候也很容易定位原因

        伦敦派采用从上之下（outside-in）的TDD方式，通过mock掉交互方，可以先写高层的测试来为整体功能设定目标，再逐步细化具体实现

    然而问题在于：
    对于单元的理解就不合理，关注单个功能才是合理的。
    一个测试用例应当是对一个系统功能的内聚

3. 测试依赖
    1. 共享依赖：如数据库、文件系统
    2. 私有依赖：如其他的类
    3. 可变依赖：如数据库、行为不确定的类
    4. 不可变依赖：如枚举类、数值
    5. 进程外依赖：如数据库。注意共享依赖通常是进程外依赖，如果共享依赖是进程内的那么为了隔离性和并发测试你可以为每个测试单独创建一个实例，这时就转为了私有依赖
4. 经典派与伦敦派对比
    |  | 隔离目标 | 单元定义 | 使用测试替身的范围 |
    | --- | --- | --- | --- |
    | 伦敦派 | 一个单元 | 通常是一个类 | 除了不可变的依赖项 |
    | 经典派 | 一个测试 | 一个类或一组类，通常是指一个行为 | 只对共享依赖 |
    
    ![Untitled](/unit_testing/Untitled.png)
    
5. 作者倾向于经典派，因为伦敦派会导致脆弱性测试，后面有解释。
    以类的角度强行拆分，会导致测试用例支离破碎难以理解
    如果因为类之间的关联关系复杂导致难以测试，这是设计的问题，mock只是隐藏了问题，并没有解决问题
    对于单测来说，定位原因总是相对简单的事情，因此这里的差距很小

    其实直观感受上，伦敦派对于单元测试的定义可能是现在接受度更广泛的。但是整体上我非常认同本书作者的观点，尤其同意每一个测试用例都应当表达业务意义，也就是用户故事

    。实质上这也是BDD或者活文档的核心观点，因为测试用例本身是可以运行保证正确的，再加上合理的语义信息，就是对于领域模型的精确的表达。

### 三、剖析单元测试

1. 一个测试方法的构成（AAA 模式）
    
    ```java
    public void test_add() {
    	// Arrange 编排
    	int a = 9;
    	int b = 10;
    	int sum = 19;
    	Calculator sut = new Calculator();
    
    	// Act 行动
    	int addSum = sut.add(a, b);
    	
    	// Assert 断言
    	assert sum == addSum;
    }
    ```
    * arrange部分把SUT和相关依赖设置到目标状态
    * act部分中会调用SUT的方法
    * assert部分用于验证所有结果的正确性，包括返回值、SUT的状态、交互方的状态以及预期交互行为

2. 避免一个测试方法中使用多个 arrange、act 和 assert 部分
一个测试中出现多个 AAA 意味着你在一个测试中验证了多个行为，这通常是集成测试的职责
3. 如果act部分需要多个语句，就值得引起注意，这往往说明SUT的API设计的有问题，系统的不变量容易被违反（invariant violation），需要更好的封装。
3. 避免使用 `if` 语句
 `if` 语句也表示你在一个测试中验证了太多的东西，与多个 AAA 不同的是无论单元测试还是集成测试都不应出现分支，它只会使测试更加难以阅读和理解，从而增加维护成本
4. AAA 每个部分的行数
    1. Arrange 部分通常是行数较多的，但过于多时（远超过剩余AA部分的行数总和）应考虑将其提取到同一测试类的私有方法或单独的工厂类中
    2. Act 部分通常是一行，超过一行则表明你的生产代码对该行为的封装性不够好
    3. Assert 部分可以多行，但是行数过多则表明生产代码缺乏抽象，如判断两个对象是否相等，与其在测试方法中一行行断言其拥有的属性是否相等不如在对象类中增加判断对象是否相等的方法
5. 拆解部分
    
    你可能在断言后还见过拆解部分或清理部分，用于清理测试中创建的文件、数据库记录等。请注意单元测试不应该有进程外依赖，因此不会产生需要处理的副作用，这是集成测试的领域。
    
6. SUT（System under test）被测系统
    
    它为你要在应用程序中调用的行为提供入口点，这个行为可以跨越多个类，也可以跨域一个方法，但它只能有一个入口：一个出发该行为的类。所以将 SUT 和其他依赖项区分开非常重要，这样你就不会花太多时间来弄清楚测试中谁是谁的问题，为此我们始终要将测试中的 SUT 命名为 sut，同时不同部分格式使用对应的注释来标明。为了方便我将上面的代码复制到此处：
    
    ```java
    // 注意：你的注释统一使用中英文就好，这里只是演示
    public void test_add() {
    	// Arrange 编排
    	int a = 9;
    	int b = 10;
    	int sum = 19;
    	Calculator sut = new Calculator();
    
    	// Act 行动
    	int addSum = sut.add(a, b);
    	
    	// Assert 断言
    	assert sum == addSum;
    }
    ```
    
7. 尽量在测试方法中可以观察到代码的全貌
    
    将 Arrange 部分的代码提取到测试类的构造函数中会降低测试的可读性，你不再仅通过查看测试本身就可以看到全貌，你必须检查类中的不同位置以了解测试方法的作用
    
8. 命名风格
    1. 定义行为而不是实现细节，面向客户而不是程序员
    `sum_of_two_numbers()` 比 `sum_two_numbers_returns_sum()` 好
    2. 不要遵循严格的命名规则，复杂的行为是无法放入这样狭窄的框框内，所以要允许命名自由
    3. 使用下划线提高可读性，不同语言有各自的命名风格，遵循对应的风格就好
    4. 使用陈述句， `是` 就是 `是` ,  `不是` 就是 `不是` , 不存在 `可能是` 和 `应该不是` 等
    5. 测试用例的命名应当有表达力，就如同和非开发人员描述一个场景。有人建议使用固定的模板，比如[MethodUnderTest]_[Scenario]_[ExpectedResult]，这未必合理。在命名中使用方法名字实际上是与实现的耦合，应当尽量避免。相对于拘泥严格的规则，很多时候采用自然的描述会更加清晰。比如`IsDeliveryValid_InvalidDate_ReturnsFalse()` 可以改为 `Delivery_with_a_past_date_is_invalid()`
    > 这个观点还是要综合来考虑，自然语言固然有最好的表达力，但是也需要使用者都对英文本身有较好的语感。而一般而言国内程序员的英文能力也未必出色，所以适当的结构固然约束了表达力，但也能使得命名不至于差的太远。使用适当的中文注释我觉得也是合理的，不过至少在中英文词汇上应当规范使用。

### 四、编写良好的单元测试

1. 四个重要属性
    1. 防回归 Protection against regressions
        单元测试被看成是产品代码的一部分，一并上线；
        但以后出现修改的时候，出现了非预期结果，应该被发现。
        防回归（回归通俗来讲就是引入新功能后又回到了之前出问题的状态）
        1. 琐碎没有意义的代码不应测试，如 get set 方法
        2. 重点关注业务关键功能和复杂的业务逻辑
        3. 测试引用的三方库同样重要，你需要检查它们的行为是否符合你的预期
    2. 抗重构 Resistance to refactoring
        重构指的是对代码做的不影响可观测行为的修改，一般是为了提升系统的非功能属性，比如提高可读性和降低复杂度，包括修改命名、抽取函数等。如果我们仅仅对系统做了一些重构，就导致了测试用例运行失败，这就产生了误报，即false positive。太多误报会降低了我们对于测试的信赖，最终影响我们通过测试发现bug的能力。
        1. 要实现项目的可持续增长，测试就要满足在引入新功能或重构时而不引入回归
        2. 减少误报很重要，误报不仅会消磨开发人员的信心，也会减少对故障的警惕，久而久之甚至会导致开发人员忽略所有的测试失败
        3. 要以最终结果为目标，而不是实现细节。重构就是对实现细节的改动，如果最终结果不变，实现细节无所谓
    3. 快反馈 Fast feedback
        测试跑的越快，就越能减少反馈循环，也使得我们可以更加频繁的运行，最终提升反馈效率。
        快速运行测试，快速得到反馈结果，开发人员会更愿意处理一些错误，因为这几乎没有成本。相反如果测试非常慢，每次修改完代码需要等待很长时间才能运行测试完毕，那么没有谁愿意经常运行它，而导致在错误的方向上浪费时间
    4. 可维护 Maintainability
        可维护性包含理解测试的难度以及运行测试的难度。
        1. 理解测试的难易程度：将测试代码当作一等公民对待，它和生产代码一样重要，不要偷工减料，提高易读性，减小复杂性
        2. 运行测试的难易程度：如准备数据库、网络、配置等

7. 测试的价值计算
    
    `测试价值` = `防回归` x `抗重构` x `快反馈` x `可维护`

如果给上面每个属性一个分数，那么四个数值相乘就可以认为是测试的价值。相乘意味着，在任何一个属性上得到零分，就代表了测试的价值归零。当然实际中无法给出精确的分值，但我们可以进行相对精确的估算。

然而完美的测试是不存在的，召回率、精确率、快速反馈是互斥的，不可能同时得到最高分，只能通过权衡来使得整体得分最高。比如端对端测试在召回率和精确率上能够得到高分，但是却难以做到快速反馈；无关紧要的测试（trivial test）只能保证精确率和快速反馈；脆弱的测试（brittle tests）或许能做到召回率和快速反馈，但是在精确率上表现很差。

实际中，精确率不应当被妥协，因为其取值往往只有0和1，所以需要在召回率和快速反馈中进行取舍。

作者还拿CAP的例子做了对比，支出分区容忍性也是无法选择的，所以只能在一致性和可用性之间取舍。我很同意精确率的重要性，不过我觉得这里有点过于绝对，精确的程度还是有相当大的变动空间。

2. 代码正确性和测试结果的四种可能性
    1. 功能正确→测试通过→结果正确
    2. 功能错误→测试通过→结果错误（具有良好回归保护的测试可以减少该类错误的数量）
    3. 功能正确→测试失败→结果错误（具有良好抵抗重构的测试可以减少该类错误的数量）
    4. 功能错误→测试失败→结果正确
    
    | 错误类型表 | 功能正确 | 功能错误 |
    | --- | --- | --- |
    | 测试通过 | 正确推断（真阴性） | 二类错误（假阴性） |
    | 测试失败 | 一类错误（假阳性） | 正确推断（真阳性） |


    
8. 理想的测试
    1. 以上的表达式是惩罚计算，一旦一个指标为 0 那么该测试的价值为 0
    2. 防回归、抗重构、快反馈这三个指标是互斥的，不可能全部最大化
    3. 代码 `抗重构` 是二极管式的，测试要么是抗重构的，要么是不抗重构的，不存在中间值。所以我们能做的就是，在满足抗重构的条件下，根据测试的目的调整防回归和块反馈的平衡
    
    ![Untitled](/unit_testing/Untitled%201.png)
    

测试金字塔

提倡了不同测试类型的使用比例，从单元测试到集成测试再到端对端测试，逐步减少占比。这三类测试，依据前面的分析，在保证精确率的前提下，就是其侧重点就是从快速反馈到召回率的变化。

一般情况下，维持测试金字塔的比例是合理的，因为端对端测试需要最高的维护成本。但是也有些例外，比如对于CRUD类的简单场景，单元测试带来的收益不大，如果集成测试和端对端测试的成本不高，可以更多的使用。



### 五、模拟和测试脆弱性（脆弱性对应抗重构）

1. Test double 即测试替身
    1. mock: 模拟真实依赖项的行为，由模拟框架辅助创建的模拟对象
    2. spy: 和 mock 作用相同，但是是手动编写和创建的模拟对象
    3. stub: 复杂的、更加成熟的模拟真实依赖项，可配置为针对不同的场景返回不同的值
    4. dummy: 简单的、硬编码的对象，只用于满足 SUT 的方法签名，但不参与产生最后结果
    5. fake: 大多数的作用和 stub 相同，不同之处是其创建的原理，fake 通常是实现一个尚不存在的依赖项

2. Test double 分类
    大体上可以分为两类 Mock(mock, spy) 和 Stub(stub, dummy, fake)，其中 
    Mock 是针对输出交互且会产生副作用的测试替身, 因为 SUT 的输出是可观察的行为，所以是可以断言其交互的
    Stub 是针对输入交互切不会产生副作用的测试替身，因为 SUT 的输入不是 SUT 的最终结果，也不是外部可观察的行为，而是其实现细节，所以断言其交互会产生脆弱性测试
    
    如：
    
    ![Untitled](/unit_testing/Untitled%202.png)
    
3. Command query separatio (CQS) 即命令查询分离原则
    1. 命令是会产生副作用且不返回值的方法
    2. 查询是没有副作用且返回值的方法
    3. 副作用：改变对象状态、更该数据库、修改系统文件等
    4. 实际编码中严格遵循该原则是不可能的，但尽量遵循该原则总是好的
    5. Mock 一般是命令，Stub 一般是查询
4. 六边形架构
    
    ![Untitled](/unit_testing/Untitled%203.png)
    
    领域层位于六边形中心，它包含业务逻辑，构建应用程序的基本功能
    
    应用层位于领域层之上，协调该层与外部世界之间的通信。如果您的应用程序是一个RESTful API，则对该 API 的所有请求都会首先到达应用程序服务层。该层然后协调域类和进程外依赖项之间的工作。
    
    由此我们的系统自然而然类似下图
    
    ![Untitled](/unit_testing/Untitled%204.png)
    
    好，从这里我们可以容易看出有两种通信方式系统内通信和系统间通信
    
    系统内通信属于实现细节，所以在该部分使用模拟会导致脆弱性
    
    系统间通信是可观察的行为，应该在此使用模拟
    
    ***注意如果数据库是不可观察的，只有该应用可以访问那么和数据库的通信是属于系统内通信***
    

### 六、单元测试的风格

1. 基于输出的风格
    
    只验证一个行为的最终结果或者一个方法的返回值，这也是我们所提倡的，该风格也叫做函数式风格
    
2. 基于状态的风格
    
    这里的状态可以是 SUT 本身状态，也可以是其依赖项状态，在 SUT 执行后去断言状态的改变是否正确
    
3. 基于通信的风格
    
    即使用模拟的方式验证 SUT 与其协作者之间的通信
    
4. 三种风格的比较
    
    
    |  | 基于输出 | 基于状态 | 基于通信 |
    | --- | --- | --- | --- |
    | 抗重构成本 | 低 | 中 | 中 |
    | 可维护成本 | 低 | 中 | 高 |
    
    三种风格都和快反馈和防回归无关
    
5. 函数式架构
    1. 函数式编程的目标是把业务逻辑和副作用分离
    2. 一个函数式的方法/功能没有任何隐藏输入和输出，这使得非常容易测试
    3. 函数式架构将副作用推到业务边缘以实现这种分离，和六边形架构相似，核心层做出决定，将决定传到外壳（业务边缘）来处理产生的副作用

### 七、重构有价值的单元测试

1. 从两个维度观察代码
    1. 复杂性或领域意义
    2. 协作者数量
2. 两个维度的组合产生四种类型的代码
    1. 领域模型和算法
    2. 琐碎的代码
    3. 控制器
    4. 过于复杂的代码
    
    ![Untitled](/unit_testing/Untitled%205.png)
    
3. 有价值的测试
    1. 领域模型和算法象限的代码最值得测试，回报高、成本低
    2. 琐碎的代码不值得测试
    3. 控制器应该在集成测试中搞
    4. 超复杂的代码应该被重构成领域模型和算法或控制器
4. 拆分超复杂代码的考量：代码的宽度和深度
    
    你的代码可以很深（复杂或重要）或很宽（与许多合作者一起工作），但绝不能两者兼而有之
    
    ![Untitled](/unit_testing/Untitled%206.png)
    
5. 拆分超复杂代码的考量: 三个属性
    1. 领域模型可测试性
    2. 控制器的简单性
    3. 性能
    
    同样最多满足其中两个属性
    

### 八、集成测试

1. 凡是不满足单元测试任一定义的都是集成测试，即任何不适单元测试的测试
2. 集成测试涵盖控制器，单元测试涵盖领域模型和算法
3. 进程外依赖
    1. 托管依赖：只与你的应用交互，对外部世界是不可见的
    2. 非托管依赖：你无法完全控制的进程外依赖
    
    ***对于托管依赖我们使用真正的实例，对于非托管依赖我们使用模拟***
    
4. 如果你的数据库在项目中属于托管依赖，而由于无法控制的原因无法使用数据库，那么就不要编写该部分的测试，专注于领域模型的单元测试就好
5. 减少代码层数，尽量使用尽可能少的间接层。在大多数后端系统中，可以只使用其中的三个：领域模型、应用程序服务层（控制器）和基础设施层。基础设施层通常包含不属于领域模型的算法，以及允许访问进程外依赖项的代码
6. 消除代码中的循环依赖
7. 关于日志
    1. 支持日志是为支持人员和系统管理员准备的，它是应用程序可观察行为的一部分
    2. 支持日志记录是一项业务需求，因此请在你的代码库中明确反映该需求
    3. 将支持日志记录视为与进程外依赖项一起使用的任何其他功能
    4. 诊断日志记录有助于开发人员了解应用程序内部发生的事情，它是一个实现细节
    5. 不需要测试诊断日志
    6. 诊断日志尽量少，对于代码来说是一种噪声

### 九、最佳实践

1. 仅将模拟应用非托管依赖项
2. 在系统最比边缘验证与这些依赖的交互
3. 仅在集成测试中使用模拟
4. 仅模拟你拥有的类型，在提供对非托管依赖项的访问的第三方库之上编写您自己的适配器。模拟那些适配器而不是底层类型

### 十、数据库

1. 将数据库视为常规代码，随源代码一样在 git 仓库中维护，不应在源代码控制之外对数据库结构进行任何修改
2. 参考数据是数据库的一部分，如一些预设的字典值
3. 每个开发者一个单独的实例
4. 使用基于迁移的方式做数据库的改动，即保留每一次的更改，部署时对目标数据库执行这些更改
5. 你的测试不应该依赖于数据库的状态，即你的测试应该自行将该状态带到所需条件
6. 在测试开始时清理数据库数据，这是最好的选择。它工作速度很快，不会导致不一致的行为，也不容易意外跳过清理阶段
7. 避免使用内存数据库模拟

### 十一、反模式

1. 不要贪图方便而在测试时将生产代码中的一些私有项公开化，将它们作为总体可观察行为的一部分进行间接测试，或者是你应该思考你的代码抽象是否不够
2. 从黑盒角度验证代码
3. 代码污染是在生产代码中添加仅用于测试的代码，这是一种反模式，因为它混合了测试代码和生产代码并增加了后者的维护成本

### notes:
* 企业级应用 (enterprise application)的特点:
    业务逻辑复杂
    项目周期很长
    数据量中等
    对于运行速度的要求不高

    作者这里突出说了企业级应用，是和一些互联网应用的高流量场景做了区分。在一些高流量场景中，业务逻辑其实比较简单，核心挑战是处理高流量高并发带来的速度和稳定性挑战，这种场景下自动化测试能够提供的帮助是有限的，基础架构带来的收益更为直接。
    而对于业务逻辑复杂的企业应用场景，面临的最大问题往往是系统腐化之后带来的复杂性挑战，体现在系统难以理解，以及各类修改带来不可知的问题。这种场景下如果自动化测试能够在修改中保护原有逻辑的正确性，对于系统稳定性和迭代效率都会有巨大的收益。
    在国内的互联网行业中，纯C端的高流量场景发展空间已经很少，现在的系统都是向B端、向复杂的方向演进，因此高效的自动化测试应该会发挥越来越大的作用。

* 可测试性是优良设计的一个方面。难以测试是往往是高耦合的体现，但是易于测试的设计也未必是一个好的设计。

* 开发速度的剧烈下降的现象称为软件熵(software entropy)，也即代表了软件的腐化。单元测试的目标是保证软件的可持续发展，在长期开发之后，依然可以持续演进。

* 单纯增加测试的数量并不能达成上诉目标，需要考虑测试的价值和成本。测试的成本包括了：
    重构代码时所需要的对于测试的修改
    运行测试的时间
    处理测试误报的情况
    阅读和理解测试

* 一个成功的测试集应当
    融入到开发流程当中，在代码修改的过程中经常运行
    专注在代码中最重要的部分，大部分情况下，最重要的部分是包含业务逻辑的部分，也就是领域模型
    用最小的维护成本提供最高的价值，需要程序员识别有价值的测试，并编写有价值的测试


### 5 Mocks and test fragility

    本章讨论测试替身的使用，也涉及了对于系统架构的讨论

测试替身(test double)指代了所有测试中用到的非生产环境的依赖，包括 dummy, stub, spy, mock, fake，本质上可以分为两种类型。



Mock是为了模拟和检查 由内向外（outcoming）的交互，即SUT用于改变外部依赖的调用。Stub是为了模拟由外向内（incoming）的交互，即SUT用于获取信息的调用，细分dummy/stub/fake

只是在智能程度上的差别而已。对于stub不应该验证其交互，因为这些只是中间过程，属于实现细节。

    感觉这个分类非常有道理！注意这些概念不要和Mock框架的方法混淆，比如Mockito中的mock对象

    和spy对象，如果我们只是为方法设置了返回值，而不去验证其调用的话，就只是一个Stub，只有验证了调用才算是Mock。

代码可以从两个维度来分类：公共API

vs 私有API，可观测行为 vs 实现细节。

    公共/私有是通过代码访问权限控制的
    可观测行为指对外暴露的提供用户功能的操作或者状态，其它的则是实现细节
    理想情况下，系统的公共API就应当是其可观测行为，而实现细节都不应当对外暴露
    需要通过封装来实现更好的设计，保护代码的不变性（invariant）；对外暴露实现细节很容易导致不变性被违反（invariant violations）
    良好的API设计自然会提高测试的质量


六边形架构关注三个重要的方面：

    领域层和应用服务层的关注点分离

    。领域层为业务逻辑负责，应用服务层编排流程
    只有应用服务层到领域层的单向依赖
    外部应用通过应用服务层来连接系统，不能直接访问领域层

跨系统的通信是可观测行为，而系统内部的通信都是实现细节。进程外的依赖，如果使用方只有SUT自己，那么也不应该归类到可观测行为，而应该属于实现细节，比如数据库。Mock应该只关注系统的可观测行为，而不应该用于验证实现细节，否则会使得测试非常脆弱。

    这里有一个隐含的假设，那就是公共API要比私有API

    更加稳定。这应该是非常合理的假设，因为公共API是对外的承诺，对其修改总是需要协调多个系统甚至团队，因此天然就要求稳定性。而实现细节本身就需要在项目开发过程中不断调整优化的，所以一旦在测试中依赖了实现细节，就更有可能受到影响。如果大家对于这一点感受不强，那可能恰好说明了平时系统重构做的太少了。。。
    书中没有提到的点，是在不同场景下，我们关注的SUT的粒度可能不一样，“系统功能”的粒度也可能不一样。因此可观测行为与实现细节的边界在不同的场景下不是一成不变的。所以我个人认为，还是可以淡化单元测试和集成测试的边界，只需要明确在其场景下清晰的定义可观测行为和公共API，然后在这个边界去验证SUT的行为。

### 6 Styles of unit testing

    本章讨论不同的测试风格，主要是指验证方式的区别，同时介绍了函数式编程

单元测试可以分为三种风格：

    基于输出（output-based）的测试只校验SUT的输出
    这是假设SUT没有隐藏的状态，其运行的唯一结果就是返回值
    这种风格的测试拥有最好的测试质量，因为所有交互都基于公共API而无需关注实现细节，实现上也很简洁
    基于状态（state-based）的测试指在运行结束后验证SUT的状态
    与基于输出的测试相比较，基于状态的测试总是需要和更多的API打交道以获取状态，因此与系统的耦合还是多了一些，所以精确率上有所不如
    此外在测试用例书写时由于需要校验状态，也不是非常简洁，所以可维护性也不如
    基于交互（communication-based）的测试，是指使用mock来验证系统间的交互行为
    伦敦派的写法会大量使用这种风格的测试
    这种风格需要使用大量的mock，因此在精确率和可维护性上都是最差的

基于输出的测试需要代码本身是函数式的。函数式编程的代码会分为两个部分：内部是无状态的业务逻辑部分，包含了主要的复杂度，外部则是处理状态的壳，应该越简单越好。外部需要收集所有的输入信息，函数式的核心部分会产生决策，外部再基于决策来产生各类副作用。我们的目标是尽量用基于输出的测试来覆盖核心部分，而外部流程则留给少量的集成测试。与六边形架构相比，函数式把所有的状态都放到了领域逻辑之外，而六边形架构则允许内部状态。



当然函数式也有其成本，以上面的流程来看，需要在第一阶段就获取所有可能需要的信息，而这里有部分可能是不必要的。另外要把代码按函数式来划分也需要很多额外的代码。所以只有复杂度较高的部分才值得做这么大的改动。
### 7 Refactoring toward valuable unit tests

    在上面讨论了“什么是好的测试”之后，本章介绍“如何写出好的测试”。

上一章讨论了如何把代码重构为函数式的风格，本章讨论更加通用的方法。

代码的复杂度指其中决策点的数量，既包括在代码中直接声明的，也包括通过类库间接声明的。复杂的代码一般来说应当也是对于问题领域影响最大的代码，也是从单测中收益最明显的部分。



代码可以从复杂度/领域重要性 和 交互方数量 的维度分为四个象限

    左上角的部分应当是领域模型和算法，它们拥有最高的复杂度，但是不应该有太多交互方
    左下角是一些琐碎（trivial）的代码，复杂度和交互方都很少
    右下角的部分是控制器，不应当包含太复杂的业务逻辑，主要是承担编排其他组件的功能
    右上角的象限既有高复杂度又有大量交互对象

右上角的部分难以测试，可以通过humble object的模式把其中的业务逻辑抽取出来进入领域逻辑象限，而使得剩余部分
能够落入控制器的象限。可以把复杂度和交互方数量理解为代码的深度和宽度，代码要么很深要么很宽，不能两者兼有。六边形架构和函数式编程

都是这种思想的体现，只不过函数式编程做到了极致。

领域逻辑是单元测试最能发挥作用的地方，而控制器部分只需要通过集成测试来简要覆盖，琐碎代码则完全不必测试。我们应当关注的合理的测试覆盖率，而不应该追求100%的覆盖率，让测试发挥最好的价值。

把业务逻辑从流程编排

中隔离出来，也需要平衡三个方面

    领域模型的可测试性，交互方越少越容易测试
    控制器的简单性，决策点越少越简单
    性能，主要体现在进程外交互的数量

因为很多交互流程取决于业务逻辑的判断，所以各种方案都可能导致某个方向受损：

    如果把所有交互方都放在控制器层，则需要在领域逻辑外准备好所有可能用到的数据，导致性能降低
    如果把交互逻辑

    放到领域模型内，会影响可测试性
    拆分领域模型，把决策流程分为多个小步骤，又会增加控制器的复杂度

第三种方案是相对合理的取舍。也可以使用一些模式来减少对于控制器复杂度的影响

    canExecute/execute模式，也就是由领域模型提供canExecute的判断，避免业务逻辑的碎片化并收敛在领域模型内部
    领域事件模式，把领域模型内的重要变化通过事件来通知控制器层，使得模型变化的信息可以被追踪

    这一章的内容继续深化前面的讨论，并且提出了比较通用的方案，就是隔离业务逻辑和控制器。这个和DDD中倡导的隔离业务复杂度和技术复杂度异曲同工，本质上也是关注点分离原则的体现，使得各个部分能够有各自适合的测试策略。作者这里的讨论也远远超过了测试本身，而是对于整体架构设计的分析讨论。

## Part 3 Integration testing
### 8 Why integration testing?

    本章继续讨论集成测试



不符合单元测试标准的都可以认为是集成测试，一般来说集成测试总是需要验证系统和交互方的集成

    集成测试关注控制器，单元测试则覆盖算法和领域模型
    集成测试能够有更好的召回率和准确率，单元测试运行更快也更加容易维护

测试金字塔体现了这种权衡，让大部分测试用例都是低成本的单元测试。边缘场景尽量使用单元测试来覆盖，集成测试只覆盖关键的happy path

。但如果项目本身的领域逻辑比较简单，那么也可以减少单元测试的比例。

使用集成测试去覆盖边缘场景是得不偿失的，对于这类场景的问题，应当遵循快速失败原则（fail fast principle)，一旦发生预期外的错误就停止当前操作，尽早暴露错误，并保护系统状态不受到损坏。

    作者在书中多次提醒，要关注测试的价值，价值不高的测试是坏的测试，还不如不写。

集成测试需要处理进程外的依赖，可以分为两类

    受控依赖(managed dependencies)是只有自己的应用会访问的外部依赖，不算是可观测行为（比如数据库），而是实现的细节，建议在测试中使用真实的实例
    非受控依赖(unmanaged dependencies)是其他应用也需要访问的依赖，属于外部可观测行为，应当在集成测试中使用mock

    作者建议对受控依赖采用真实实例，更多还是从提高测试的召回率角度来考虑，前提也是集成测试的占比应该不高。但是为了快速反馈，也可以采用各种变通的方式。比如对于数据库，很多时候可以采用内存数据库

    来模拟大部分的流程。

接口常常被用来对依赖进行抽象，但是如果一个接口只有一种实现，那么这个接口并不会提供更低的耦合，而且可能违反了YAGNI(You aren’t gonna need it)原则。只有这类依赖是我们需要mock的外部依赖时，接口才有意义。

集成测试的一些最佳实践：

    让领域模型

的边界更为显式和清晰
减少代码的层级，太多层级使得代码难以理解和推理（reason about），大多数系统使用领域层、控制器层和基础架构层

    就足够了
    消除循环依赖，也会加重认知负荷，难以理清
    act部分不应当有多个语句，除非难以达到目标状态。单测中不应该出现，集成测试可能会出现。

### 9 Mocking best practices

我们应当使得mock的价值最大化，只用在系统边缘的非受控依赖。对包装非受控依赖的最后一个类型进行Mock，这样能提高测试的召回率和准确率，因为测试中包含的代码最多，同时也贴近系统真正的对外交互。

Spy是mock的一种，区别在于是单独手写的对象，而非通过框架生成。实践表明使用spy来做mock可以提供更加优雅的测试语句，因为我们可以在spy

上扩展相应的功能。

    注意这里的spy和mockito框架里的概念不一致，可以理解为自己对依赖实现一份内存实现，而不是用框架来设置各个方法的返回值。这样确实可以使得mock过程更加容易理解。而且这样的实现可以在多个场景复用，而不需要每次都痛苦的思考该设置什么输入输出。

一些最佳实践：

    理论上只有controller需要和非受控依赖打交道，所以单测是不需要mock的，只有集成测试要使用mock
    在测试中不要依赖生产代码的逻辑，可以重新定义常量和字面值，否则无法进行有效的检查。
    对于log这样的非受控依赖，可以不需要太关注具体的结构，只需要验证其存在以及核心信息即可
    在mock中验证交互的次数，既要关注预期发生的交互，也要关注预期不发生的交互。
    不要mock不属于自己的类型，对于非受控的依赖应当写一个适配器（adaptor），并mock这个适配器。适配器就是反腐层，可以使用本应用的领域语言，并且只需要包含真正使用到的功能。

### 10 Testing the database

如前所述，数据库一般是作为系统的受控依赖，因此不要mock数据库，而是采用真实的数据库系统。

数据库的schema

应当作为代码管理，reference data（应用不能修改的数据）也应当作为schema的一部分。

因为要连接真实数据库，所以在测试中并行是非常困难的，建议还是串行的运行。另外也应该连接本地的数据库实例来加速。也可以使用Docker镜像来进一步加速，但是必要性不太大。

    这个还是建立在需要数据库的测试用例不多的前提下，否则带来的运行速度问题还是比较明显的。如果本身应用中使用的SQL语句不太复杂，我个人认为内存数据库还是不错的方案。

数据库schama可以使用state-based模式或者migration-based模式，前者相当于记录最新的snapshot，后者则记录所有的变更。大部分情况下推荐使用migration-based模式，因为更加容易在schema变更的时候处理现有数据。

为了保证测试结果不要互相影响，需要在多次运行之间清理数据库，建议在每次测试开始的时候清理数据库。

    要注意系统状态可能分布在多个组件，数据库只是其中一种，还包括内存状态、缓存、Redis、MQ等，其中有一些需要进行mock。要想在测试之间避免影响，其实需要清理所有的状态，如果设计不好有可能会漏掉或者导致测试速度太慢。

## Part 4 Unit testing anti-patterns
### 11 Unit testing anti-patterns

在测试中使用私有方法加重了测试与实现的耦合，应当采用间接的方式来访问。

如果私有方法太过于复杂，以致于公共API无法测试，这可能说明了抽象的问题。应当把这部分抽象抽出为一个单独的类。

不要为了单元测试而暴露内部状态，所有的交互都应当和生产环境一样。

在测试中不要依赖具体的实现方式，用黑盒的方式来验证。

code pullution是指为了测试而增加生产代码，这是一个反模式，提升了生产代码的维护成本。

不要mock一个具体类，而应该使用接口。

在测试中依赖时间会导致测试的脆弱性，可以把时间依赖注入
到逻辑中，便于在测试时进行mock。

### 99. terms

黑盒测试
白盒测试
