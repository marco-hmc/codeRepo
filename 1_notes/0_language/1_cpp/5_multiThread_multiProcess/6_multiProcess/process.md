### 3. 进程和线程篇

- ***什么是进程和线程?***
  - **进程**:**进程是程序在某个数据集合上的一次运行活动,也是操作系统进行资源分配和保护的基本单位**.通俗来说,**'进程就是程序的一次执行过程'**,程序是静态的,它作为系统中的一种资源是永远存在的.而进程是动态的,它是动态的产生,变化和消亡的,拥有其自己的生命周期
  - **进程:**线程是独立调度的基本单位.一个进程中可以有多个线程,它们共享进程资源
- ***如何保证线程安全?***
- ***什么是协程?***

# 进程管理

## 进程和线程

* **进程的概念**：**进程是程序在某个数据集合上的一次运行活动，也是操作系统进行资源分配和保护的基本单位**。通俗来说，**「进程就是程序的一次执行过程」**，程序是静态的，它作为系统中的一种资源是永远存在的。而进程是动态的，它是动态的产生，变化和消亡的，拥有其自己的生命周期

* 进程的组成

  * **进程控制块 PCB**。包含如下几个部分：
    - 进程描述信息，如pid，gid
    - 进程控制和管理信息，如进程状态，优先级，未决信号集，信号屏蔽字
    - 资源分配清单，如页表，打开文件列表
    - CPU 相关信息，如寄存器，状态寄存器，堆栈指针
  * **数据段**。即进程运行过程中各种数据（比如程序中定义的变量）
  * **程序段**。就是程序的代码（指令序列）

* 进程上下文切换

  * 首先，将进程 A 的运行环境信息存入 PCB，这个运行环境信息就是进程的上下文（Context）
  * 然后，将 PCB 移入相应的进程队列
  * 选择另一个进程 B 进行执行，并更新其 PCB 中的状态为运行态
  * 当进程 A 被恢复运行的时候，根据它的 PCB 恢复进程 A 所需的运行环境

* 线程的概念：线程是独立调度的基本单位。一个进程中可以有多个线程，它们共享进程资源

* 线程的实现可以分为两类：

  * 用户级线程：不需要内核支持而在**用户程序中实现的线程**，其不依赖于操作系统核心，在语言层面利用线程库提供创建、同步、调度和管理线程的函数来控制用户线程。**不需要用户态/内核态切换，速度快，操作系统内核不知道多线程的存在，因此一个线 程阻塞将使得整个进程（包括它的所有线程）阻塞**。由于这里的**处理器时间片分配是以进程为基本单位，所以每个线程执行的时间相对减少**
  * 内核线线程：又称为内核支持的线程或轻量级进程，所以线程切换时需要进入到内核态

* **同一进程中线程资源共享情况**
  * 线程共享的资源包括：**进程代码段、进程的公有数据**(利用这些共享的数据，线程很容易的实现相互之间的通讯)、**进程打开的文件描述符**、**信号的处理函数**、**进程的当前目录和进程用户ID与进程组ID**
  * 线程不共享的资源包括：
    * **线程ID**：每个线程都有自己的线程ID，这个ID在本进程中是唯一的。进程用此来标识线程
    * **寄存器组的值**：由于线程间是并发运行的，**每个线程有自己不同的运行线索**，当从一个线程切换到另一个线程上 时，必须将原有的线程的寄存器集合的状态保存，以便将来该线程在被重新切换到时能得以恢复
    * **线程的堆栈**：堆栈是保证线程独立运行所必须的。线程函数可以调用函数，而被调用函数中又是可以层层嵌套的，所以线程必须拥有自己的函数堆栈，使得函数调用可以正常执行，不受其他线程的影响
    * **错误返回码(errno)**：由于同一个进程中有很多个线程在同时运行，可能某个线程进行系统调用后设置了errno值，而在该线程还没有处理这个错误，另外一个线程就在此时被调度器投入运行，这样错误值就有可能被修改。所以，不同的线程应该拥有自己的错误返回码变量
    * **线程的信号屏蔽码**：由于**每个线程所感兴趣的信号不同**，所以**线程的信号屏蔽码应该由线程自己管理**。**但所有的线程都共享同样的信号处理器**
    * **线程的优先级**：由于线程需要像进程那样能够被调度，那么就必须要有可供调度使用的参数，这个参数就是线程的优先级
  
* 线程的优缺点

  * 优点：
    * 一个进程中可以同时存在多个线程，这些线程共享该进程的资源。**进程间的通信必须请求操作系统服务**（因为 CPU 要切换到内核态），开销很大。而同进程下的线程间通信，无需操作系统干预，开销更小。不过，需要注意的是：**从属于不同进程的线程间通信，也必须请求操作系统服务**
    * **线程间的并发比进程的开销更小**，**系统并发性提升**。同样，需要注意的是：**从属于不同进程的线程间切换，它是会导致进程切换的，所以开销也大**
  * 缺点：
    * 当进程中的一个线程奔溃时，会导致其所属进程的所有线程奔溃。举个例子，**对于游戏的用户设计，就不应该使用多线程的方式，否则一个用户挂了，会影响其他同个进程的线程**

* **进程和线程的区别**
  * 拥有资源
    * 进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源
  * 调度
    * 线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换
  * 系统开销
      * 进程在创建、切换和销毁时开销比较大，而线程比较小。进程创建的时候需要分配系统资源，而销毁的的时候需要释放系统资源。**进程切换需要分两步**：**切换页目录、刷新TLB以使用新的地址空间**；**切换内核栈和硬件上下文（寄存器）**；**而同一进程的线程间逻辑地址空间是一样的，线程切换时不需要切换页目录、刷新TLB，只需保存和设置少量寄存器内容、堆栈指针，开销较小**
    * **进程在创建、销毁时开销比较大，而线程比较小**。进程创建的时候需要分配**虚拟地址空间、IO设备**等系统资源，而**销毁的的时候需要释放系统资源**；线程只需要**创建栈，栈指针，程序计数器，通用目的寄存器和条件码**等，**不需要创建独立的虚拟地址空间**等系统资源
  * 通信方面
    * **线程间可以通过直接读写同一进程中的数据进行通信**，但是进程通信需要借助 IPC
  
* 多进程和多线程

  * 多线程
    * **多线程就是指一个进程中同时有多个线程正在执行**
    * 多线程原因
      * 在一个程序中，**有很多的操作是非常耗时的**，如**数据库读写操作，IO操作**等，如果使用单线程，那么程序就必须等待这些操作执行完成之后才能执行其他操作。**使用多线程，可以在将耗时任务放在后台继续执行的同时，同时执行其他操作**，可以提高程序的效率
    * 多线程优点
      * 创建速度快，方便高效的数据共享
      * **共享数据**：多线程间可以共享同一虚拟地址空间；多进程间的数据共享就需要用到共享内存、信号量等IPC技术
      * **较轻的上下文切换开销**：**不用切换地址空间(页表)**，不用更改CR3寄存器，**不用刷新TLB**
      * **提供非均质的服务**：如果全都是计算任务，但每个任务的耗时不都为1s，而是1ms-1s之间波动；这样，多线程相比多进程的优势就体现出来，它能有效降低“简单任务被复杂任务压住”的概率
    * 多线程的缺点
      * **使用太多线程，是很耗系统资源，因为线程需要开辟内存。更多线程需要更多内存**
      * **影响系统性能，因为操作系统需要在线程之间来回切换**
      * 需要考虑线程操作对程序的影响，如线程挂起，中止等操作对程序的影响，**某个线程的崩溃会导致整个程序崩溃**
    * 多线程是异步的，但这不代表多线程真的是几个线程是在同时进行，实际上是**系统不断地在各个线程之间来回的切换**（因为系统切换的速度非常的快，所以给我们在同时运行的错觉）
    * 适用场景
      * **线程间有数据共享**，并且数据是需要修改的（不同任务间需要大量共享数据或频繁通信时）
      * 提供**非均质的服务**（有优先级任务处理）事件响应有优先
      * **单任务并行计算**，在非CPU Bound的场景下提高响应速度，降低时延
      * 与人**有IO交互的应用**，良好的用户体验（键盘鼠标的输入，立刻响应)
  * 多进程
    * 多进程就是指**计算机同时执行多个进程**，一般是同时运行多个软件
    * 优点
      * 编程相对容易，通常不需要考虑锁和同步资源的问题
      * 更强的容错性：比起多线程的一个好处是一个进程崩溃了不会影响其他进程
      * 有内核保证的隔离：数据和错误隔离
      * 对于使用如C/C++这些语言编写的本地代码，错误隔离是非常有用的：**采用多进程架构的程序一般可以做到一定程度的自恢复**；（如Nginx，master守护进程监控所有worker进程，发现进程挂掉后将其重启）
  * 应用场景
    * 多进程模型的优势是CPU
    * 多线程模型主要优势为**线程间切换代价较小**，因此**适用于I/O密集型的工作场景**，因此I/O密集型的工作场景经常会**由于I/O阻塞导致频繁的切换线程**。同时，**多线程模型也适用于单机多核分布式场景**
    * 多进程模型，**适用于CPU密集型**。同时，**多进程模型也适用于多机分布式场景中，易于多机扩展**
    * 进程线程间创建的开销不足作为选择的依据，因为一般我们都是使用线程池或者进程池，在系统启动时就创建了固定的线程或进程，不会频繁的创建和销毁
    * 首先，根据工作集（需要共享的内存）的大小来定；**如果工作集较大，就用多线程，避免cpu cache频繁的换入换出**；比如memcached缓存系统
    * 其次，选择的依据根据以上多线程适用的场景来对比自身的业务场景，是否有这样场景需求：**数据共享、提供非均质的服务，单任务拆散并行化等**；
    * 如果没有必要，或者多进程就可以很好的胜任，就**多用多进程，享受单线程编程带来便利**
  
* 高并发

  * 高并发指的是是一种系统运行过程中遇到的一种“**短时间内遇到大量操作请求**”的情况，主要发生在web系统集中大量访问或者socket端口集中性收到大量请求（例如：12306的抢票情况；天猫双十一活动）。该情况的发生会导致系统在这段时间内执行大量操作，例如对资源的请求，数据库的操作等。如果高并发处理不好，不仅仅降低了用户的体验度（请求响应时间过长），同时可能导致系统宕机，严重的甚至导致OOM异常，系统停止工作等

* 多线程与高并发的联系

  * 多线程只是在同/异步角度上解决高并发问题的其中的一个方法手段，是**在同一时刻利用计算机闲置资源的一种方式**
  * 多线程在高并发问题中的作用就是**充分利用计算机资源**，**使计算机的资源在每一时刻都能达到最大的利用率**，不至于浪费计算机资源使其闲置

* 操作系统的设计，**从进程和线程的角度来说**，可以归结为三点：

  - **以多进程形式，允许多个任务同时运行**
  - **以多线程形式，允许单个任务分成不同的部分运行**
  - **提供协调机制，一方面防止进程之间和线程之间产生冲突，另一方面允许进程之间和线程之间共享资源**


## 协程

* 基本概念：**协程，英文Coroutines，是一种比线程更加轻量级的存在。**正如一个进程可以拥有多个线程一样，一个线程也可以拥有多个协程

  <img src="imgs/os/corotines.png" alt="corotines" style="zoom:60%;" />

* 进程，线程，协程的上下文切换

  * 进程的切换者是操作系统，切换时机是根据操作系统自己的切换策略，用户是无感知的。进程的切换内容包括**页全局目录、内核栈、硬件上下文，切换内容保存在内存**中。进程切换过程是由“**用户态到内核态到用户态**”的方式，**切换效率低**
  * 线程的切换者是操作系统，切换时机是根据操作系统自己的切换策略，用户无感知。线程的切换内容**包括内核栈和硬件上下文**。线程切换内容保存在内核栈中。线程切换过程是由“用户态到内核态到用户态”， **切换效率中等**
  * 协程的切换者是用户（编程者或应用程序），**切换时机是用户自己的程序所决定的**。协程的**切换内容是硬件上下文**，**切换内存保存在用户自己的变量**（用户栈或堆）中。**协程的切换过程只有用户态，即没有陷入内核态，因此切换效率高**
  * **协程是轻量级线程，拥有自己的寄存器上下文和栈**。**协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈**
  * 协程能保留上一次调用时的状态，即所有局部状态的一个特定组合，每次过程重入时，就相当于进入上一次调用的状态

* 协程相比进程和线程的优势

  * 协程拥有极高的执行效率。因为**子程序切换不是线程切换，协程不是被操作系统内核所管理，而是由程序自身完全控制(完全运行在用户态)，因此，没有线程切换的开销**，和多线程比，线程数量越多，协程的性能优势就越明显
  * 不需要多线程的锁机制，因为**只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多**

* 协程分类：

  * **按照控制传递机制**

    - **非对称式协程**：通过yield, 将控制权返回给调用方, 如达夫设备 就是一种非对称式协程，这种协程更像是一个可以返回多次的子例程(函数)，因此代码可读性会较高

    - **对称式协程**：通过resum, 将控制权交给任意协程, 这种协程更像goto 可以任意的跳转 返回，如果滥用会导致代码可读性较低

  * **按调实现分类**

    - **stackfull 有栈协程**：**每个协程都拥有自己的栈，协程上下文保存在自己的栈中**，切换协程就是切换栈然后恢复栈中的上下文，这种方法实现的协程更像是用户态的线程

    - **stackcopy 共享栈协程**：stackfull 的缺点显而易见，**十分浪费内存，当协程数量过多时会导致内存开销过大**。stackcopy 就是用来解决此问题的，**所有协程公用一个运行栈，当协程发生切换的时候，将协程数据copy到自身的独立栈中，独立栈可以进行动态的扩充**

    - **stackless 无栈协程**：stackless 协程公用一个栈，但是与stackcopy 不同，**协程切换的时候仅会将所需的上下文保存在堆中**, 可以将部分无用局部变量提前释放，通常这需要编译器的支持。stackless 协程通常只有顶层例程可以被挂起

* **应用场景**

  - I/O 密集型任务
    - 这一点与多线程有些类似，**但协程调用是在一个线程内进行的，是单线程，切换的开销小，因此效率上略高于多线程**
    - 当程序在执行 I/O 时操作时，CPU 是空闲的，此时可以充分利用 CPU 的时间片来处理其他任务。在单线程中，一个函数调用，一般是从函数的第一行代码开始执行，结束于 return 语句、异常或者函数执行（也可以认为是隐式地返回了 None ）
    - **有了协程，我们在函数的执行过程中，如果遇到了耗时的 I/O 操作，函数可以临时让出控制权，让 CPU 执行其他函数，等 I/O 操作执行完毕以后再收回控制权**
  - 当今无数的 Web 服务和互联网服务，**本质上大部分都是 IO 密集型服务**，什么是 IO 密集型服务？意思是处理的任务大多是和**网络连接或读写相关的高耗时任务**，高耗时是相对 CPU 计算逻辑处理型任务来说，两者的处理时间差距不是一个数量级的
    - **IO 密集型服务的瓶颈不在 CPU 处理速度，而在于尽可能快速的完成高并发、多连接下的数据读写**
  - **以前有两种解决方案：**
    -  如果用多线程，**高并发场景的大量 IO 等待会导致多线程被频繁挂起和切换**，非常消耗系统资源，同时多线程访问共享资源存在竞争问题
    -  如果用多进程，不仅存在频繁调度切换问题，同时还会存在每个进程资源不共享的问题，需要**额外引入进程间通信机制来解决**

  * **协程出现给高并发和 IO 密集型服务开发提供了另一种选择。**当然，世界上没有技术银弹，在这里我想把协程这把钥匙交到你手中，但是它也不是万能钥匙，最好的解决方案是贴合自身业务类型做出最优选择，不一定就选择一种模型，有时候是几种模型的组合，比如**多线程搭配协程是常见的组合**

* 因为协程是在一个线程执行，那怎么利用多核CPU呢？最简单的方法是**多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能**

* python协程完成生产者-消费者问题例子（Python对协程的支持还非常有限，用在generator中的**yield**可以一定程度上实现协程）

  ```python
  import time


  def consumer():
      r = ""
      while True:
          n = yield r  # 使用 yield 接收生产者发送的数据并返回结果
          if not n:
              return
          print("[CONSUMER] Consuming %s..." % n)
          time.sleep(1)
          r = "200 OK"


  def produce(c):
      c.send(None)  # 启动 consumer 协程
      n = 0
      while n < 5:
          n = n + 1
          print("[PRODUCER] Producing %s..." % n)
          r = c.send(n)  # 发送数据给 consumer 并接收结果
          print("[PRODUCER] Consumer return: %s" % r)
      c.close()


  if __name__ == "__main__":
      c = consumer()
      produce(c)

  ```

  注意到consumer函数是一个generator（生成器），把一个consumer传入produce后：

  1. 首先调用c.next()启动生成器；
  2. 然后，一旦生产了东西，通过c.send(n)切换到consumer执行；
  3. consumer通过yield拿到消息，处理，又通过yield把结果传回；
  4. produce拿到consumer处理的结果，继续生产下一条消息；
  5. produce决定不生产了，通过c.close()关闭consumer，整个过程结束。

  整个流程**无锁**，由一个线程执行，produce和consumer**协作完成任务**，所以称为“协程”，而非线程的抢占式多任务

* 支持协程的编程语言

  * **Lua语言**
  * **Python语言**
  * **Go语言**
  * **Java语言(Kilim框架)**

## 同步互斥

* [详见1](https://www.jianshu.com/p/6526078a1fab)

* [详见2](https://blog.csdn.net/qicheng777/article/details/77432129)

* 生产者-消费者问题(C++11实现)

  ```c++
  #include <thread>
  #include <mutex>
  #include <condition_variable>
  #include <queue>
  #include <cstdlib>
  #include <iostream>
  
  std::mutex mtx;
  std::condition_variable prodCond;
  std::condition_variable consCond;	
  const int QSIZE = 50;
  std::queue<int> blockQueue;
  volatile bool isClose = false;
  
  void producer(int id){
      while(!isClose) {
          long item = 1 + rand() % 99;  // produce item in range [1,100] 
          std::unique_lock<std::mutex> locker(mtx);
          while(blockQueue.size() >= QSIZE)
              prodCond.wait(locker);		// 释放锁，等待，醒来时获得锁
          std::cout<<"Producer " << id <<" produces item "<< item <<std::endl;
          blockQueue.push(item);	// insert item
          locker.unlock();
          consCond.notify_all();
      }
      std::cout<<"Producer " << id <<" finished!"<<std::endl;
  }
  
  void consumer(int id) {
      while(!isClose){
          std::unique_lock<std::mutex> locker(mtx);
          while(blockQueue.size() == 0)
              consCond.wait(locker);	
          int item = blockQueue.front();	// consumes item
          std::cout<<"Consumer " << id <<" cosumes item "<< item << std::endl;
          blockQueue.pop();			// remove item
          locker.unlock();
          prodCond.notify_all();
      }
      std::cout<<"Consumer " << id <<" finished!"<<std::endl;
  }
  
  int main(int argc, char * argv[]){
      const int num = 2;
      std::vector<std::thread> producers(num);
      std::vector<std::thread> consumers(num);
      
      for(int i = 0; i < num; i++){
          producers[i] = std::thread(producer, i+1);
          consumers[i] = std::thread(consumer, i+1);
      }
    
      sleep(1);
      
        isClose = true;
      
      for(int i = 0; i < num; i++){
          producers[i].join();
          consumers[i].join();
      }
      
      return 0;
  }
  ```

* 读者-写者问题

  ```c++
  #include <thread>
  #include <mutex>
  #include <iostream>
  
  std::mutex mtx;
  std::mutex cntMtx;
  
  size_t readCount = 0;  // std::atomic<size_t> readCount;
  
  volatile bool isClose = false;
  
  void reader(int id){
    while(!isClose){
          std::unique_lock<std::mutex> cntLock(cntMtx);	// 用于读者互斥计数
          readCount++;
          if(readCount == 1)
            mtx.lock();			// 第一个读者，加锁
        cntLock.unlock();
          
          std::cout<<"Reader " << id <<" reads "<< item <<std::endl;
          
          cntLock.lock();
          readCount--;
          if(readCount == 0)		// 已无读者，解锁唤醒写者
            mtx.unlock();
          cntLock.unlock();
      }
      std::cout<<"Reader " << id <<" finished!"<<std::endl;
  }
  
  void writer(int id){
    while(!isClose){
          mtx.lock();		// 读写互斥锁
          
          std::cout<<"Writer " << id <<" writes "<< item << std::endl;
          
            mtx.unlock();	// 解锁
      }
      std::cout<<"Writer " << id <<" finished!"<<std::endl;
  }
  
  int main(int argc, char * argv[]){
      const int num = 2;
      std::vector<std::thread> writers(num);
      std::vector<std::thread> readers(num);
      
      for(int i = 0; i < num; i++){
          writers[i] = std::thread(writer, i+1);
        readers[i] = std::thread(reader, i+1);
      }
    
      sleep(1);
      
        isClose = true;
      
      for(int i = 0; i < num; i++){
          writers[i].join();
            readers[i].join();
      }
    
      return 0;
  }
  ```

## 死锁

* 死锁

  * 死锁是多线程中最差的一种情况，**多个线程相互占用对方的资源的锁，而又相互等对方释放锁**，此时若无外力干预，这些线程则一直处理阻塞的假死状态，形成死锁

* 死锁检测与避免

  * **产生死锁的四大必要条件**

    * **资源互斥/资源不共享**：每个资源要么已经分配给了一个进程，要么是可用的，只有这两种状态，资源不可以被共享使用，所以所谓的互斥是指：资源不共享，如果被使用，只能被一个进程使用
    * **占有和等待/请求并保持**：已经得到资源的进程还能继续请求新的资源
    * **资源不可剥夺**：当一个资源分配给了一个进程后，其它需要该资源的进程不能强制性获得该资源，除非该资源的当前占有者显示地释放该资源
    * **环路等待**：死锁发生时，系统中一定有由两个或两个以上的进程组成的一条环路，环路上的每个进程都在等待下一个进程所占有的资源

  * 编程中避免死锁：

    * 避免多次锁定。**尽量避免同一个线程对多个 Lock 进行锁定**。例如上面的死锁程序，主线程要对 A、B 两个对象的 Lock 进行锁定，副线程也要对 A、B 两个对象的 Lock 进行锁定，这就埋下了导致死锁的隐患。
    * **具有相同的加锁顺序**。如果多个线程需要对多个 Lock 进行锁定，则应该保证它们以相同的顺序请求加锁。比如上面的死锁程序，主线程先对 A 对象的 Lock 加锁，再对 B 对象的 Lock 加锁；而副线程则先对 B 对象的 Lock 加锁，再对 A 对象的 Lock 加锁。这种加锁顺序很容易形成嵌套锁定，进而导致死锁。如果让主线程、副线程按照相同的顺序加锁，就可以避免这个问题。
    * **使用定时锁**。程序在调用 acquire() 方法加锁时可指定 timeout 参数，该参数指定超过 timeout 秒后会自动释放对 Lock 的锁定，这样就可以解开死锁了。
    * 死锁检测。死锁检测是一种依靠算法机制来实现的死锁预防机制，它主要是针对那些不可能实现按序加锁，也不能使用定时锁的场景的。
    * **无锁编程**：cas、原子变量、原子操作等

  * 预防死锁

    * 预防死锁的发生**只需破坏死锁产生的四个必要条件之一**即可
    * 下面的方法开销非常之大，目前没有一个操作系统可以实现
      * **破坏互斥条件**：如果允许系统资源都能共享使用，则系统不会进入死锁状态； **缺点**：有些资源根本不能同时访问，如打印机等临界资源只能互斥使用。所以，**破坏互斥条件而预防死锁的方法不太可行**，而且在有的场合应该保护这种互斥性
      * **破坏请求并保持条件**：釆用**预先静态分配**方法，即**进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前，不把它投入运行**。一旦投入运行后，这些资源就一直归它所有，也不再提出其他资源请求，这样就可以保证系统不会发生死锁。**缺点**：**系统资源被严重浪费**，其中有些资源可能仅在运行初期或运行快结束时才使用，甚至根本不使用。而且还会**导致“饥饿”**现象，**当由于个别资源长期被其他进程占用时，将致使等待该资源的进程迟迟不能开始运行**
      * **破坏不可剥夺条件**：当一个已保持了某些不可剥夺资源的进程，**请求新的资源而得不到满足时**，它**必须释放已经保持的所有资源，待以后需要时再重新申请**。这意味着，一个进程已占有的资源会被暂时释放，或者说是被剥夺了，或从而破坏了不可剥夺条件。**缺点**：该策略**实现起来比较复杂**，**释放已获得的资源可能造成前一阶段工作的失效，反复地申请和释放资源会增加系统开销，降低系统吞吐量**。这种方法**常用于状态易于保存和恢复的资源**，如CPU的寄存器及内存资源，一般不能用于打印机之类的资源
      * **破坏循环等待条件**：为了**破坏循环等待条件**，可釆用**顺序资源分配法**。首先**给系统中的资源编号**，规定每个进程，必须**按编号递增的顺序请求资源，同类资源一次申请完**。也就是说，只要进程提出申请分配资源Ri，则该进程在以后的资源申请中，只能申请编号大于Ri的资源。**缺点**： 这种方法存在的问题是，编号必须相对稳定，这就限制了新类型设备的增加；尽管在为资源编号时已考虑到大多数作业实际使用这些资源的顺序，但也经常会发生作业使用资源的顺序与系统规定顺序不同的情况，造成资源的浪费；此外，这种**按规定次序申请资源的方法，也必然会给用户的编程带来麻烦**
    * 因此，目前使用的方法是避免死锁，而不是预防死锁

  * 避免死锁的算法

    * 判断“**系统安全状态**”法：**在进行系统资源分配之前，先计算此次资源分配的安全性**。若此次分配不会导致系统进入不安全状态，则将资源分配给**进程； 否则，让进程**等待

      ![safe_status](imgs/os/safe_status.png)

      * **图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数**。从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得**所有进程都能成功运行**，因此可以称图 a 所示的状态是安全的
      * 定义：**如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的**
      * 安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比

    * 银行家算法

      * 申请的贷款额度不能超过银行现有的资金总额
      * 分批次向银行提款，但是贷款额度不能超过一开始最大需求量的总额
      * 暂时不能满足客户申请的资金额度时，在有限时间内给予贷款
      * 客户要在规定的时间内还款

    * 单个资源银行家算法

      * 一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，**算法要做的是判断对请求的满足是否会进入不安全状态**，如果是，就拒绝请求；否则予以分配

        ![bank](imgs/os/bank.png)

        上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态

    * 多个资源银行家算法

      ![multi_bank](imgs/os/multi_bank.png)

      * 上图中有**五个进程，四个资源**。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：**总资源、已分配资源以及可用资源**，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0
      * 检查一个状态是否安全的算法如下：
        * **查找右边的矩阵是否存在一行小于等于向量 A**。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的
        * 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中
        * 重复以上两步，直到所有进程都标记为终止，则状态是安全的
      * 如果一个状态不是安全的，需要拒绝进入这个状态

* 活锁

  * 活锁恰恰与死锁相反，死锁是大家都拿不到资源都占用着对方的资源，而活锁是拿到资源却又相互释放不执行。**当多线程中出现了相互谦让**，都主动将资源释放给别的线程使用，这样这个资源在多个线程之间跳动而又得不到执行，这就是活锁

* 饥饿

  * 优先级高的线程能够插队并优先执行，这样如果**优先级高的线程一直抢占优先级低线程的资源，导致低优先级线程无法得到执行**，这就是饥饿。当然还有一种饥饿的情况，**一个线程一直占着一个资源不放而导致其他线程得不到执行**，与死锁不同的是饥饿在以后一段时间内还是能够得到执行的，如那个占用资源的线程结束了并释放了资源

* 无锁

  * 无锁，即没有对资源进行锁定，即所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。**无锁典型的特点就是一个修改操作在一个循环内进行，线程会不断的尝试修改共享资源，如果没有冲突就修改成功并退出否则就会继续下一次循环尝试。所以，如果有多个线程修改同一个值必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功**

## CAS技术

* 概念

  * 比较并交换(compare and swap, CAS)，是原子操作的一种。**在多线程没有锁的状态下，可以保证多个线程对同一个值的更新**。CAS可用于在多线程编程中实现不被打断的数据交换操作，从而避免多线程同时改写某一数据时由于执行顺序不确定性以及中断的不可预知性，产生的数据不一致问题。该操作通过将内存中的值与指定数据进行比较，当数值一样时将内存中的数据替换为新的值

* 原理
  * 执行函数：CAS(V，E，N) ，CAS有3个操作数，内存值`V`，旧的期望值 `E`，要修改的新值 `N`。当且仅当预期值`E`和内存值`V`相同时（比较），它就认为这个期间没有人来访问过这个贡献资源，所以就把`V`值改为新值`N`（交换）
  * **如果多个线程同时使用CAS操作一个变量的时候，只有一个线程能够修改成功。其余的线程提供的期望值已经与共享变量的值不一样了，所以均会失败**
  * 由于CAS操作属于乐观派，它总是认为自己能够操作成功，所以操作失败的线程将会再次发起操作，而不是被OS挂起。所以说，即使CAS操作没有使用同步锁，其它线程也能够知道对共享变量的影响
  * 因为其它线程没有被挂起，并且将会再次发起修改尝试，所以无锁操作即CAS操作天生免疫死锁
  * **CAS是系统原语，CAS操作是一条CPU的原子指令（cmpxchg），这个指令是给数据总线进行加锁，所以不会有线程安全问题**

* 特点

  * CAS结合`volatile`可以实现无锁并发，**适用于线程数少，多核CPU场景下**(线程数不要超过CPU核数)
  * CAS是**基于乐观锁实现**（本身并无锁，区别于synchronized）
  * CAS体现的是**无锁并发、无阻塞并发**
    * CAS的原子性 + `volatile`的可见性，不断的【比较与交换】保证线程安全
    * 没有用锁来保证线程安全，所以不会阻塞
    * 如果竞争激烈，会导致**重试**频繁发生，效率下降

* 自旋–比较和交换

  * **自旋：** 就是不停的判断比较，看能否将值交换

  * 多个线程在访问共享资源的时候，会产生同步问题，所以需要加锁来保证安全。但是，一旦加了锁，同一时刻只能有一个线程获取锁对象，效率自然变低了

  * 不加锁的情况下来修改值，CAS是怎么自旋如下图

    <img src="imgs/os/cas.png" alt="cas" style="zoom: 67%;" />

  * 现在`Data`中存放的是`num=0`，线程A将`num=0`拷贝到自己的工作内存中计算（做+1操作）`E=0`，计算的结果为`V=1`

  * 由于是在多线程不加锁的场景下操作，所以可能此时`num`会被别的线程修改为其他值。此时需要再次读取`num`看其是否被修改，记再次读取的值为`N`

  * 如果被修改，即`E != N`，说明被其他线程修改过。那么此时工作内存中的E已经和主存中的`num`不一致了，根据EMSI协议，保证安全需要重新读取`num`的值。直到`E = N`才能修改

  * 如果没被修改，即`E = N`，说明没被其他线程修改过。那么将工作内存中的`E=0`改为`E=1`，同时写回主存。将`num=0`改为`num=1`

* CAS三大问题

  * **ABA问题**
    * CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。这就是CAS的ABA问题
    * 常见的解决思路是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么`A-B-A` 就会变成`1A-2B-3A`，由于每个过程值都会有对应的版本，所以我们在修改过程中需要传入期望版本和当前的值，数据库的多版本并发控制也类似
    * 添加时间戳：添加世时间戳也可以解决。查询的时候把时间戳一起查出来，对的上才修改并且更新值的时候一起修改更新时间，这样也能保证，方法很多但是跟版本号都是异曲同工之妙
  * 无限循环问题（自旋）
    * 如果CAS不成功，则会原地自旋，如果长时间自旋会**给CPU带来非常大且没必要的开销**
    * 可以使用java8中的LongAdder，分段CAS和自动分段迁移
    * 自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率
  * **只能保证一个共享变量的原子操作**
    * 只能保证一个共享变量的原子操作。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是**把多个共享变量合并成一个共享变量来操作**。比如有两个共享变量 i=2，j=a，合并一下 ij=2a，然后用CAS来操作
    * 可以用AtomicReference (java)，这个是封装自定义对象的，多个变量可以放一个自定义对象里，然后他会检查这个对象的引用是不是同一个。如果多个线程同时对一个对象变量的引用进行赋值，用AtomicReference的CAS操作可以解决并发冲突问题

## [IPC](https://mp.weixin.qq.com/s/b6HLr348-v7ibntuWs1yRA)

* 进程间通信(IPC)，[详见](https://www.cnblogs.com/zgq0/p/8780893.html)


### 管道

* 通常指无名管道，是 UNIX 系统IPC最古老的形式

* 它是**半双工**的（即数据只能在一个方向上流动），具有固定的读端和写端
* 它只能用于**具有亲缘关系的进程之间的通信**（也是父子进程或者兄弟进程之间）
* 它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并**不属于其他任何文件系统**，并且**只存在于内存**中
* 原型

```c
1 #include <unistd.h>
2 int pipe(int fd[2]);    // 返回值：若成功返回0，失败返回-1
```

### FIFO

* 也称为命名管道，它是一种文件类型

* FIFO可以在无关的进程之间交换数据，与无名管道不同
* FIFO有路径名与之相关联，它以一种**特殊设备文件形式存在于文件系统**中
* FIFO的通信方式类似于在进程中使用文件来传输数据，只不过FIFO类型文件同时具有管道的特性。**在数据读出时，FIFO管道中同时清除数据，并且“先进先出”**
* 原型

```c
1 #include <sys/stat.h>
2 // 返回值：成功返回0，出错返回-1
3 int mkfifo(const char *pathname, mode_t mode);
```

* 其中的` mode `参数与`open`函数中的 `mode `相同。一旦创建了一个 FIFO，就可以用一般的文件I/O函数操作它

  * 当 open 一个FIFO时，是否设置非阻塞标志（`O_NONBLOCK`）的区别：
    * 若没有指定`O_NONBLOCK`（默认），只读 open 要阻塞到某个其他进程为写而打开此 FIFO。类似的，只写 `open` 要阻塞到某个其他进程为读而打开它
    * 若指定了`O_NONBLOCK`，则只读` open `立即返回。而只写` open `将出错返回 -1 如果没有进程已经为读而打开该 FIFO，其`errno`置`ENXIO`。


### 消息队列

* **是消息的链接表，存放在内核中**。一个消息队列由一个标识符（即队列ID）来标识

* 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级
  * 消息队列独立于发送与接收进程。**进程终止时，消息队列及其内容并不会被删除**
  * **消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取,也可以按消息的类型读取**
  * 原型

```c
#include <sys/msg.h>
// 创建或打开消息队列：成功返回队列ID，失败返回-1
int msgget(key_t key, int fslag);
// 添加消息：成功返回0，失败返回-1
int msgsnd(int msqid, const void *ptr, size_t size, int flag);
// 读取消息：成功返回消息数据的长度，失败返回-1
int msgrcv(int msqid, void *ptr, size_t size, long type,int flag);
// 控制消息队列：成功返回0，失败返回-1
int msgctl(int msqid, int cmd, struct msqid_ds *buf);
```

* 在以下两种情况下，`msgget`将创建一个新的消息队列：

  - 如果没有与键值key相对应的消息队列，并且flag中包含了`IPC_CREAT`标志位。
  - key参数为`IPC_PRIVATE`。

  * 函数`msgrcv`在读取消息队列时，`type`参数有下面几种情况：
    * `type == 0`，返回队列中的第一个消息
    * `type > 0`，返回队列中消息类型为 `type` 的第一个消息
    * `type < 0`，返回队列中消息类型值小于或等于` type `绝对值的消息，如果有多个，则取类型值最小的消息
  * 可以看出，type值非 0 时用于以非先进先出次序读消息。也可以把` type` 看做优先级的权值

### [信号(signal)](https://blog.csdn.net/h___q/article/details/84245317)

* 信号是一种比较复杂的通信方式，**用于通知接收进程某个事件已经发生**

* 程序不可捕获、阻塞或忽略的信号有：**SIGKILL(9)，SIGSTOP(19)**

  - 它们向超级用户提供一种使进程终止或停止的可靠方法
  - 如果忽略某些由硬件异常产生的信号（例如非法存储访问或除以0），则进程的行为是未定义的

* 常见信号表

  ![signal_tab](imgs/os/signal_tab.png)

* 信号产生方式

  * [信号可以通过六个函数产生](https://www.jianshu.com/p/e4ce1f6488af):

    - **kill函数**
    - **raise函数**
    - **sigqueue函数**
    - **alarm函数**
    - **setitimer函数**
    - **abort函数**
    
  * 键盘产生
  
    * 如ctrl+c，ctrl+z，ctrl+/等
  
  * 程序异常
  
    * 除0错误。除0错误会导致硬件错误
    * core dumped（核心转储）：**当进程异常退出时，操作系统会将该进程发生异常退出之前在内存中的数据存储至硬盘上**
    * **2、9号信号不会产生core文件**
  
  * 使用kill命令
  
    * **kill 在无指定时默认发送2号信号，可将指定程序终止**。若仍无法终止该程序，可使用 SIGKILL(9) 信息尝试强制删除程序。程序或工作的编号可利用 ps 指令或 jobs 指令查看
  
    ```shell
    kill [-s <信息名称或编号>][程序]　或　
    kill [-l <信息编号>]
    
    -l <信息编号> 　若不加<信息编号>选项，则 -l 参数会列出全部的信息名称
    -s <信息名称或编号> 　指定要送出的信息
    [程序] 　[程序]可以是程序的PID或是PGID，也可以是工作编号
    
    最常用的信号是：
    1 (HUP)：重新加载进程
    9 (KILL)：杀死一个进程
    15 (TERM)：正常停止一个进程
    ```
  
  * 通过系统调用接口给特定进程发送信号
  
    ```c++
    #include<signal.h>
    
    int kill(pid_t pid, int signo);
    //向特定进程发送特定信号;成功返回0;失败返回-1
    
    int raise(int signo);
    //向当前进程发送特定信号;成功返回0;失败返回-1
    
    #include<stdlib.h>
    void abort(void);
    //使当前进程收到信号而异常终止；就像exit()函数一样，abort()函数总是会成功的，所以没有返回值
    ```
  
  * 由软件条件发送信号
  
    * SIGPIPE：SIGPIPE是一种由软件条件产生的信号，**当一个管道的读端被关闭时，这时候操作系统就会检测到该管道中写入的数据不会在有人来管道内读文件了，操作系统会认为该管道的存在会造成内存资源的极大浪费，则操作系统就会向写端对应的目标进程发送SIGPIPE信号**
  
    * 定时器
  
      ```c++
      #include<unistd.h>
      unsigned int alarm(unsigned int seconds);
      //调用alarm函数可以对当前进程设置一个闹钟，也就是告诉操作系统在seconds秒之后对当前进程发送SIGALRM信号，该信号的默认处理动作是终止当前进程
      ```
  
* **信号集操作函数**

  ```c++
  #include<signal.h>
  
  //注意：在使用sigset_t类型的变量前，一定要调用sigemptyset或sigfillset进行初始化，使信号集处于某种确定的状态，初始化之后就可以调用sigaddset或sigdelset在信号集中添加或删除某种有效信号
  
  int sigemptyset(sigset_t *set);
  //初始化set所指向的信号集，使其中所有信号对应的比特位清零，表示该信号集不包含任何信号
  
  int sigfillset(sigset_t *set);
  //初始化set所指向的信号集，将其中所有信号对应的比特位置1，表示该信号集的有效信号包括系统支持的所有信号
  
  int sigaddset(sigset_t *set, int signo);
  //表示将set所指向的信号集中的signo信号置1
  
  int sigdelset(sigset_t *set, int signo);
  //表示将set所指向的信号集中的signo信号清零
  
  int sigismember(const sigset_t *set, int signo);
  //用来判断set所指向的信号集的有效信号中是否包含signo信号，包含返回1，不包含返回0，出错返回-1
  
  int sigpending(sigset_t *set);
  // 获取进程的pending信号集
  // 成功返回0；失败返回-1
  ```

* **设置/修改进程的信号屏蔽字（block表）**

  ```c++
  #include<signal.h>
  
  int sigprocmask(int how, const sigset_t *set, sigset_t *oset);
  
  /*
    int how：
        SIG_BLOCK：set包含了用户希望添加到当前信号屏蔽字的信号，即就是在老的信号屏蔽字中添加上新的信号。相当于：mask=mask|set
        SIG_UNBLOCK：set包含了用户希望从当前信号屏蔽字中解除阻塞的信号，即就是在老的信号屏蔽字中取消set表中的信号。相当于：mask=mask&~set
        SIG_SETMASK：设置当前进程的信号屏蔽字为set所指向的信号集。相当于：mask=set
    const sigset_t *set：
        将要设置为进程block表的信号集
    sigset_t *oset：
        用来保存进程旧的block表
        若无需保存进程旧的block表，传递空指针即可
  */
  ```

* **自定义信号处理方式**

  ```c++
  #include<signal.h>
  
  struct sigaction
  {
      void (*sa_handler)(int);	//指向信号处理对应的函数
      void (*sa_sigaction)(int, siginfo_t *, void *);
      sigset_t sa_mask; //当在处理所收到信号时，想要附带屏蔽的其他普通信号，当不需要屏蔽其他信号时，需要使用sigemptyset初始化sa_mask
      int sa_flags;
      void (*sa_restorer)(void);
  };
  
  int sigaction(int signo, const struct sigaction *act, struct sigaction *oact);
  /*
  int signo：
    指定的信号编号
  const struct sigaction *act：
    若该act指针非空，则根据act指针来修改进程收到signo信号的处理动作
  struct sigaction *oact：
    若oact指针非空，则使用oact来保存信号旧的处理动作
  */
  ```

* **信号处理过程**

  <img src="imgs/os/sig_cap.png" alt="sig_cap" style="zoom:80%;" />

* 信号接收

  * **接收信号的任务是由内核代理的，但内核接收到信号后，会将其放到对应进程的PCB的未决信号集中，同时向进程发送一个中断，使其陷入内核态**
  
* **此时信号只是在未决信号集中，对进程来说是不知道信号到来的**
  
* 信号的检测

  * 进程陷入内核后，**有两种场景会对信号集进行检测**：
    * 进程**从内核态返回到用户态前进行信号检测**
    * 进程在内核态中，**从睡眠状态被唤醒的时候进行信号检测**
  * 当发现有新信号后，便会进入下一步，信号处理

* 信号的处理

  * 如果用户**未注册信号处理函数**，则内核按照信号的**默认处理方式**处理
  * **如果用户注册了信号处理函数，则信号处理函数是运行在用户态的**，调用处理函数前，**内核会将当前内核栈的内容备份拷贝到用户栈上，并且修改指令寄存器(eip)将其指向信号处理函数**
  * **接下来进程返回到用户态中，执行相应的信号处理函数**
  * **信号处理函数执行完成后，还需要返回内核态，检查是否还有其他信号未处理**
  * **如果所有信号都处理完成了，就会将内核栈回复(从用户栈的备份拷贝回来)，同时恢复指令寄存器(eip)将其指向中断前的运行位置，最后回到用户态继续执行进程**
  * 如果同时有多个信号到达，处理流程为上面1，2，3，4步骤间重复进行，直到所有信号处理完毕

* **处理信号的时机**

  * 进程收到一个信号时，**并不会立即就去处理这个信号，而是先将收到的信号保存下来，并在合适的时候对信号进行处理**，**操作系统会在进程进入了内核态并从内核态返回用户态时，检测进程中可以进行处理的信号，并进行处理**

* 用户写好的代码会在什么情况下进入内核态呢？

  - 调用系统调用接口
  - 异常
  - 中断

### 信号量

* 与已经介绍过的 IPC 结构不同，它是**一个计数器**。信号量**用于实现进程间的互斥与同步，而不是用于存储进程间通信数据**

* 信号量用于进程间同步，若要在进程间传递数据需要结合共享内存
  * 信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作
  
  * 每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数
  
  * 支持信号量组
  
  * 原型
  
    ```c
    #include <sys/sem.h>
    // 创建或获取一个信号量组：若成功返回信号量集ID，失败返回-1
    int semget(key_t key, int num_sems, int sem_flags);
    // 对信号量组进行操作，改变信号量的值：成功返回0，失败返回-1
    int semop(int semid, struct sembuf semoparray[], size_t numops);  
    // 控制信号量的相关信息
    int semctl(int semid, int sem_num, int cmd, ...);
    ```
  
* 当`semget`创建新的信号量集合时，必须指定集合中信号量的个数（即`num_sems`），通常为1； 如果是引用一个现有的集合，则将`num_sems`指定为 0 。在`semop`函数中，`sembuf`结构的定义如下：

  ```
  struct sembuf 
  {
      short sem_num; // 信号量组中对应的序号，0～sem_nums-1
      short sem_op;  // 信号量值在一次操作中的改变量
      short sem_flg; // IPC_NOWAIT, SEM_UNDO
  }
  ```

* 其中` sem_op` 是一次操作中的信号量的改变量：

  - 若`sem_op > 0`，表示进程释放相应的资源数，将 sem_op 的值加到信号量的值上。如果有进程正在休眠等待此信号量，则换行它们
    - 若`sem_op < 0`，请求 `sem_op `的绝对值的资源
      - 如果相应的资源数可以满足请求，则将该信号量的值减去sem_op的绝对值，函数成功返回。
      - 当相应的资源数不能满足请求时，这个操作与`sem_flg`有关
        - `sem_flg `指定`IPC_NOWAIT`，则semop函数出错返回`EAGAIN`
        - `sem_flg` 没有指定`IPC_NOWAIT`，则将该信号量的`semncnt`值加1，然后进程挂起直到下述情况发生：
          1. 当相应的资源数可以满足请求，此信号量的`semncnt`值减1，该信号量的值减去sem_op的绝对值。成功返回；
          2. 此信号量被删除，函数`smeop`出错返回`EIDRM`；
          3. 进程捕捉到信号，并从信号处理函数返回，此情况下将此信号量的`semncnt`值减1，函数`semop`出错返回`EINTR`
    - 若`sem_op == 0`，进程阻塞直到信号量的相应值为0：
      - 当信号量已经为0，函数立即返回。
      - 如果信号量的值不为0，则依据`sem_flg`决定函数动作：
        - `sem_flg`指定`IPC_NOWAIT`，则出错返回`EAGAIN`。
        - `sem_flg`没有指定`IPC_NOWAIT`，则将该信号量的`semncnt`值加1，然后进程挂起直到下述情况发生：
          1. 信号量值为0，将信号量的`semzcnt`的值减1，函数`semop`成功返回；
          2. 此信号量被删除，函数`smeop`出错返回`EIDRM`；
          3. 进程捕捉到信号，并从信号处理函数返回，在此情况将此信号量的`semncnt`值减1，函数`semop`出错返回`EINTR`

  - 在`semctl`函数中的命令有多种，这里就说两个常用的：
    - `SETVAL`：用于初始化信号量为一个已知的值。所需要的值作为联合`semun`的`val`成员来传递。在信号量第一次使用之前需要设置信号量。
    - `IPC_RMID`：删除一个信号量集合。如果不删除信号量，它将继续在系统中存在，即使程序已经退出，它可能在你下次运行此程序时引发问题，而且信号量是一种有限的资源。

### 共享内存

* 指两个或多个进程共享一个给定的存储区

* **共享内存是最快的一种 IPC，因为进程是直接对内存进行存取**

* **因为多个进程可以同时操作，所以需要进行同步**

* **信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问**

* **共享内存实现原理**：共享内存是通过**把同一块内存分别映射到不同的进程空间**中实现进程间通信。而共享内存本身不带任何互斥与同步机制，但当多个进程同时对同一内存进行读写操作时会破坏该内存的内容，所以，在实际中，同步与互斥机制需要用户来完成

* 在**/proc/sys/kernel/**目录下，记录着共享内存的一些限制，如一个共享内存区的**最大字节数shmmax**，系统范围内最大共享内存区标识符数shmmni等，可以手工对其调整，但不推荐这样做

* 共享内存使用
  * 进程必须首先分配它
  * 随后需要访问这个共享内存块的每一个进程都必须将这个共享内存绑定到自己的地址空间中
  * 当完成通信之后，所有进程都将脱离共享内存，并且由一个进程释放该共享内存块

* 原型

  ```c
  #include <sys/shm.h>
  // 创建或获取一个共享内存：成功返回共享内存ID，失败返回-1
  int shmget(key_t key, size_t size, int flag);
  // 连接共享内存到当前进程的地址空间：成功返回指向共享内存的指针，失败返回-1
  void *shmat(int shm_id, const void *addr, int flag);
  // 断开与共享内存的连接：成功返回0，失败返回-1
  int shmdt(void *addr); 
  // 控制共享内存的相关信息：成功返回0，失败返回-1
  int shmctl(int shm_id, int cmd, struct shmid_ds *buf);
  ```

* 当用`shmget`函数创建一段共享内存时，必须指定其 size；而如果引用一个已存在的共享内存，则将 size 指定为0 
  * **当一段共享内存被创建以后，它并不能被任何进程访问。必须使用`shmat`函数连接该共享内存到当前进程的地址空间，连接成功后把共享内存区对象映射到调用进程的地址空间，随后可像本地空间一样访问**
  * `shmdt`函数是用来断开`shmat`建立的连接的。注意，**这并不是从系统中删除该共享内存，只是当前进程不能再访问该共享内存而已**
  * `shmctl`函数可以对共享内存执行多种操作，根据参数 cmd 执行相应的操作。常用的是`IPC_RMID`（从系统中删除该共享内存）

* **mmap实现共享内存**
  
  * mmap系统调用并不是完全为了用于共享内存而设计的。它本身提供了不同于一般对普通文件的访问方式，进程可以像读写内存一样对普通文件的操作。而Posix或系统V的共享内存IPC则纯粹用于共享目的，**当然mmap()实现共享内存也是其主要应用之一**
  * **mmap系统调用使得进程之间通过映射同一个普通文件实现共享内存**。普通文件被映射到进程地址空间后，进程可以像访问普通内存一样对文件进行访问，不必再调用read()，write（）等操作。
  * mmap并不分配空间，只是**将文件映射到调用进程的地址空间里**，然后你就可以用memcpy等操作写文件，而不用write()了。写完后用msync()同步一下，你所写的内容就保存到文件里了。 **不过这种方式没办法增加文件的长度**，**因为要映射的长度在调用mmap()的时候就决定了**
  * 简单说就是把一个文件的内容在内存里面做一个映像，内存比磁盘快些



#### 2.4 fork，vfork，clone

守护进程怎么创建
