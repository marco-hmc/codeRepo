## c++的多线程

### 1. 多线程的创建和管理手段

#### 1.1 thread

  - **特点**
    - **直接控制**：`std::thread` 提供了对线程的直接控制，可以精细地管理线程的创建、执行和销毁。
    - **手动管理**：需要手动管理线程的生命周期，包括创建、等待（`join`）和分离（`detach`）线程。
    - **无返回值**：`std::thread` 无法直接返回任务的结果，需要使用其他同步机制（如 `std::promise` 和 `std::future`）来获取结果。

  - **应用场景**
    - **复杂线程管理**：适用于需要复杂线程管理的场景，如需要精细控制线程的创建和销毁。
    - **高灵活性需求**：适用于需要高灵活性的场景，可以手动控制线程的执行方式和调度。

  - **`join`定义**
    - 当你调用 `join` 时，它会等待被调用线程执行完毕，然后再继续执行主线程。换句话说，`join` 使得主线程等待被调用线程的完成。
    - 使用 `join` 可以确保在主线程继续执行之前，被调用线程的任务已经完成。这对于需要等待线程执行结果的情况很有用。

  - **`detach`定义**
    - 当你调用 `detach` 时，它使得被调用线程成为后台线程，与主线程分离。主线程不再等待被调用线程的完成。
    - 使用 `detach` 可以使得主线程在后台线程运行的同时继续执行，而不必等待后台线程完成。这对于一些异步任务或长时间运行的任务很有用。

#### 1.2 async

`std::async` 是一个强大的工具，用于在 C++ 中启动异步任务。通过合理使用 `std::async` 和选择适当的启动策略，可以提高程序的并发性能和响应速度。是 C++11 中引入的一个用于启动异步任务的函数。其原型如下：

`std::async`是一个高级工具,它自动处理线程的创建和销毁,使得异步编程变得更简单.如果你只需要在后台运行一个任务并获取其结果,那么`std::async`通常是最好的选择.

  - **特点**
    - * **自动管理**：`std::async` 提供了一个简单的接口来启动异步任务，并自动管理线程的生命周期。
    - * **返回 `std::future`**：`std::async` 返回一个 `std::future` 对象，通过这个对象可以获取异步任务的结果。
    - * **启动策略**：可以指定启动策略（`std::launch::async` 或 `std::launch::deferred`），决定任务是立即异步执行还是延迟到调用 `get` 时执行。

  - **应用场景**
    - * **简单异步任务**：适用于简单的异步任务，不需要复杂的线程管理。
    - * **自动管理需求**：适用于希望自动管理线程生命周期的场景，减少手动管理的复杂性。

  ```cpp
    template <class Fn, class... Args>
    std::future<typename std::result_of<Fn(Args...)>::type>
        async(std::launch policy, Fn&& f, Args&&... args);
  ```

  - **参数及其意义**

    1. **`policy`**：异步任务的启动策略，是一个 `std::launch` 类型的枚举值。可能的值有：
      - `std::launch::async`：异步执行任务，可能会在新的线程中执行。
      - `std::launch::deferred`：
        延迟执行任务，直到调用 `std::future` 对象的 `get` 或 `wait` 函数时执行，可能在当前线程执行。
      - `std::launch::async | std::launch::deferred`：由系统自行选择执行方式，可能异步也可能延迟。
    2. **`f`**：要异步执行的函数或可调用对象。
    3. **`args...`**：传递给函数 `f` 的参数列表。

  - **返回值**
    `std::async` 返回一个 `std::future` 对象，通过这个对象可以获取异步任务的结果。`std::future` 是一个轻量级的异步结果管理器，提供了对异步任务的状态查询（是否完成/是否有异常等）以及获取最终结果的功能。

  - **注意事项**
    - 使用 `std::async` 可以方便地在后台执行任务，而调用 `get` 函数时，如果任务尚未完成，主线程会等待直到任务完成。这有助于充分利用多核系统的性能，将计算密集型任务分配到不同的线程中执行。
    - 在使用 `std::async` 时，需要小心选择适当的启动策略，以避免不必要的线程创建和上下文切换。

#### 1.3 packaged_task

`std::packaged_task` 是 C++11 中引入的一个类模板，用于将一个可调用对象（`task`，如函数、lambda 表达式或函数对象）包装成任务，并将其结果存储在一个 `std::future` 对象中，以便稍后获取。

  * **特点**
      - **任务包装**：`std::packaged_task` 将一个可调用对象（如函数、lambda 表达式或函数对象）包装成任务，并将其结果存储在一个 `std::future` 对象中。
      - **灵活性和控制**：提供了更多的灵活性，但也需要更多的管理工作。需要自己创建一个 `std::thread` 并将 `std::packaged_task` 对象传递给它。
      - **与 `std::future` 关联**：`std::packaged_task` 自动与 `std::future` 关联，简化了结果获取的过程。

  * **应用场景**
      - **复杂任务管理**：适用于需要将任务与 `std::future` 关联的复杂场景。
      - **线程池实现**：适用于实现线程池等需要精细控制任务调度和执行的场景。

  - **主要特点**
    1. **任务包装**：
      - `std::packaged_task` 只是对一个任务类型的包装。经过包装之后的 `packaged_task` 返回值为 `future` 类型。
      - `future` 是对结果的一个包装，只有调用 `future::get()` 方法时，任务才会真正执行并返回结果。
    2. **灵活性和控制**：
      - `std::packaged_task` 提供了更多的灵活性，但也需要更多的管理工作。
      - 它只是将一个任务和一个 `std::future` 对象关联起来，并不创建线程。需要自己创建一个 `std::thread` 并将 `std::packaged_task` 对象传递给它。
      - 这使得可以更精细地控制线程的创建和销毁，以及任务的调度。例如，可以将任务提交给一个线程池，或者在特定的时间点启动线程。
    3. **与 `std::async` 的比较**：
      - `std::async` 会自动创建线程，如果只是在简单的场景中使用异步编程，通常是最好的选择。
      - 如果需要更精细的控制，或者正在实现一个线程池，那么 `std::packaged_task` 可能是更好的选择。

#### 1.4 总结

  - **`std::thread`**：提供了对线程的直接控制，适用于需要复杂线程管理和高灵活性的场景。
  - **`std::async`**：提供了简单的接口来启动异步任务，并自动管理线程的生命周期，适用于简单异步任务和自动管理需求的场景。
  - **`std::packaged_task`**：将可调用对象包装成任务，并与 `std::future` 关联，提供了更多的灵活性和控制，适用于复杂任务管理和线程池实现的场景。

### 2. 多线程间的通信、同步手段

相较于进程，线程是共享同一进程的地址空间的，线程间的通信将会很容易，直接就可以通过全局变量来交换数据。但这种访问的便利性也带来了一些风险，通常当有多个线程访问相同的共享数据时需要**同步**或**互斥锁**等等手段。

#### 2.1 互斥锁

##### 2.1.1 c++标准库直接支持的锁类型

  - **`std::mutex`**：基本的互斥锁。
  - **`std::recursive_mutex`**：递归互斥锁，允许同一线程多次获取锁。
  - **`std::shared_mutex`**：读写锁，允许多个线程同时读取，但写入时需要独占锁。
  - **`std::timed_mutex`**：带有超时功能的互斥锁。
  - **`std::shared_timed_mutex`**：带有超时功能的共享互斥锁。

##### 2.1.2 锁策略/锁管理/上锁方式

- **`std::unique_lock`**
  - **功能**：提供更多灵活性和控制的锁管理类，可以延迟锁定、手动锁定和解锁、传递锁的所有权。
  - **特点**：适用于复杂的锁定需求，支持延迟锁定和手动解锁。
  - **使用场景**：适用于需要灵活控制锁定和解锁的场景，如需要在不同函数间传递锁的所有权。
  - **如何使用**：
  - 创建 `std::unique_lock` 对象时可以选择立即锁定或延迟锁定互斥锁。
  - 可以手动调用 `lock` 和 `unlock` 方法来控制锁定和解锁。
  - 可以将 `std::unique_lock` 对象传递给其他函数，传递锁的所有权。

- **`std::lock_guard`**
  - **功能**：简单的 RAII 风格的锁管理类，在构造时自动锁定互斥锁，在析构时自动解锁互斥锁。
  - **特点**：适用于基本的锁定需求，确保在作用域结束时自动释放锁。
  - **使用场景**：适用于简单的临界区保护，确保在函数退出时自动释放锁。
  - **如何使用**：
  - 创建 `std::lock_guard` 对象时传入互斥锁，自动锁定互斥锁。
  - 在作用域结束时，`std::lock_guard` 会自动解锁互斥锁。

- **`std::scoped_lock`**
  - **功能**：同时锁定多个互斥锁，并在作用域结束时自动解锁。
  - **特点**：RAII 风格的锁管理器，确保在作用域结束时自动释放锁，避免死锁和资源泄漏。
  - **使用场景**：适用于需要同时锁定多个互斥锁的场景，确保线程安全。
  - **如何使用**：
  - 创建 `std::scoped_lock` 对象时传入多个互斥锁。
  - 在作用域结束时，`std::scoped_lock` 会自动解锁所有互斥锁。

- **`std::lock`**
  - **功能**：一个函数模板，用于使用死锁避免算法锁定多个可锁对象。
  - **特点**：确保多个锁按顺序锁定，避免死锁。
  - **使用场景**：适用于需要同时锁定多个互斥锁的场景，确保线程安全。
  - **如何使用**：
  - 调用 `std::lock` 函数时传入多个互斥锁，使用死锁避免算法锁定所有互斥锁。
  - 在锁定成功后，可以使用 `std::unique_lock` 或 `std::lock_guard` 管理这些锁。

- **`std::try_lock`**
  - **功能**：一个函数模板，尝试获取多个互斥锁的所有权，如果无法获取则返回。
  - **特点**：用于尝试锁定多个互斥锁，而不会阻塞线程。
  - **使用场景**：适用于需要尝试锁定多个互斥锁的场景，避免线程阻塞。
  - **如何使用**：
  - 调用 `std::try_lock` 函数时传入多个互斥锁，尝试获取所有互斥锁的所有权。
  - 如果成功获取所有互斥锁，返回 -1；如果无法获取某个互斥锁，返回该互斥锁的索引。

##### 2.1.3 未支持的锁类型/其他锁概念
  - **自旋锁（Spinlock）**
    - **功能**：自旋锁在等待锁时会不断循环检查锁的状态，而不是阻塞线程。
    - **特点**：适用于高频率锁定和解锁的场景，避免线程上下文切换的开销。
    - **使用场景**：适用于锁持有时间短、频繁加锁解锁的场景，如短时间的临界区保护。
    - **如何实现**：通常使用原子操作（如 `std::atomic_flag`）实现，通过不断尝试获取锁来实现自旋。

  - **分段锁（Segmented Locks）**
    - **功能**：将资源分割成多个部分，并对每个部分使用单独锁的机制，以减少锁竞争。
    - **特点**：通过分段锁减少锁竞争，提高并发性能。
    - **使用场景**：适用于需要对大块资源进行并发访问的场景，如哈希表、缓存等。
    - **如何实现**：将资源分割成多个部分，每个部分使用单独的锁，线程只锁定需要访问的部分。

  - **票据锁（Ticket Locks）**
    - **功能**：先来先服务的锁机制，通过发放票据来控制对资源的访问顺序。
    - **特点**：确保公平性，先请求锁的线程先获得锁。
    - **使用场景**：适用于需要严格控制访问顺序的场景，确保公平性。
    - **如何实现**：使用两个计数器，一个表示下一个可用票据，一个表示当前服务的票据，线程获取票据后等待其票据号被服务。

  - **悲观锁（Pessimistic Lock）**
    - **功能**：假设并发冲突会频繁发生，在访问资源前先加锁，确保资源的独占访问。
    - **特点**：通过加锁避免并发冲突，确保数据一致性。
    - **使用场景**：适用于高冲突的场景，如数据库事务、文件系统等。
    - **如何实现**：就是常见的互斥锁。

  - **乐观锁（Optimistic Lock）**
    - **功能**：假设并发冲突不会频繁发生，在访问资源时不加锁，而是在提交修改时检查冲突，如果发生冲突则重试。
    - **特点**：通过减少锁的使用提高并发性能，适用于低冲突的场景。
    - **使用场景**：适用于低冲突的场景，如数据库读操作、缓存等。
    - **如何实现**：CAS+版本号，在提交修改时检查版本号或时间戳是否变化，如果发生冲突则重试。

#### 2.2 condition_variable
条件变量是一种“事件通知机制”，它本身不提供、也不能够实现“互斥”的功能。因此，条件变量通常（也必须）配合互斥量来一起使用，其中互斥量实现对“共享数据”的互斥（即同步），而条件变量则去执行 “通知共享数据状态信息的变化”的任务。比如通知队列为空、非空，或任何其他需要由线程处理的共享数据的状态变化。可以说，条件变量是程序用来等待某个状态为真的机制。而这个状态必须得是线程安全的，因此需要搭配互斥量使用。

在c++中，条件变量的关键词是`std::condition_variable`。它可以用来在多线程环境中实现复杂的同步模式。以下是一些常见的用法:
  1.  **等待通知**:一个线程可以使用`std::condition_variable::wait`或`wait_for`/`wait_until`方法来等待另一个线程的通知。当`wait`被调用时，当前线程将被阻塞，直到另一个线程调用`std::condition_variable::notify_one`或`notify_all`方法。
  2.  **条件等待**:`std::condition_variable::wait`方法还可以接受一个谓词(返回`bool`的函数或函数对象).只有当这个谓词返回`true`时，`wait`才会返回.这可以用来实现条件等待:线程等待某个条件成立。
  3.  **唤醒一个或多个线程**:可以使用`std::condition_variable::notify_one`方法唤醒一个等待的线程，或者使用`std::condition_variable::notify_all`方法唤醒所有等待的线程。

#### 2.3 atomic

std::call_once 和 std::once_flag：
这些用于确保某个函数或操作只被调用一次，即使在多线程环境中也不会被重复执行。

- 解决多线程下共享变量的问题(i++，指令重排问题)：对于共享变量的访问进行加锁，加锁可以保证对临界区的互斥访问，
- C++11 提供了一些原子变量与原子操作解决用户加锁操作麻烦或者容易出错的问题
- C++11 标准在标准库 atomic 头文件提供了模版 std::atomic<>来定义原子量，而对于大部分内建类型，C++11 提供了一些特化，如，std::atomic_int (std::atomic<int>)等
- 自定义类型变成原子变量的条件是该类型必须为**Trivially Copyable 类型**(简单的判断标准就是这个类型可以用 std::memcpy 按位复制)
- atomic 有一个成员函数 is_lock_free，这个成员函数可以告诉我们到底这个类型的原子量是使用了原子 CPU 指令实现了无锁化，还是依然使用的加锁的方式来实现原子操作

#### 2.4 promise/ future

future 是表示未来能够得到的值,具体什么时候能够得到,依赖于承诺对象的实现;什么是承诺对象?
promise 和 packaged_task 就是承诺对象,但这些承诺对象 set_value 的时候,就可以执行 future.get()

关于 future,promise,packaged_task,async 的理解,以下表述对吗?
promise 和 packaged_task 都是还没有给出具体值的承诺对象,当给出具体数值的时候,就表示承诺实现,可以用于计算.
而 async 是表示会开一个异步线程进行计算,返回的是一个 future 的值,如果 future 的值计算好之后,就可以通过 future.get()得到.

所以说,在一个异步计算中,promise 和 packaged_task 是输入端的,async 是输出端的.

##### 2.4.1 shared_future

`std::future`对象的设计是唯一所有权的,也就是说,一旦你从一个`std::future`对象中获取了值,这个`std::future`对象就不能再被用来获取值.这是因为`std::future::get`方法会移动(而不是复制)值或异常,这样可以避免不必要的复制,但也意味着你只能从一个`std::future`对象中获取值一次.

因此,如果你需要在多个线程中共享同一个值,你不能直接使用`std::future`,而应该使用`std::shared_future`.`std::shared_future`对象可以被多次拷贝和读取,这意味着你可以在多个线程中共享同一个值.

在你的代码中,你创建了一个`std::shared_future<int> sf`对象,并将它传递给了三个异步操作.这三个异步操作都可以通过`sf.get()`获取到同一个值.如果你试图直接使用`std::future<int> f`来做同样的事情,你会得到一个编译错误,因为`std::future`对象不能被拷贝.

- shared_future 可以直接对一个 promise 变量使用 get_future 方法吗

不可以.`std::promise`的`get_future`方法只能返回一个`std::future`对象,而不是`std::shared_future`对象.如果你想要一个`std::shared_future`对象,你需要首先从`std::promise`获取一个`std::future`对象,然后调用`std::future`的`share`方法来获取一个`std::shared_future`对象.例如:

```cpp
std::promise<int> p;
std::future<int> f = p.get_future();
std::shared_future<int> sf = f.share();
```

在这段代码中,`sf`是一个`std::shared_future`对象,它与`f`共享同一个状态,也就是说,它们都可以获取到同一个值.

#### 2.5 semaphore

`semaphore.h` 是一个头文件，提供信号量相关的功能，用于控制对共享资源的访问。C++20 标准库引入了信号量类 `std::counting_semaphore` 和 `std::binary_semaphore`，提供了类似 `semaphore.h` 的功能。通过使用 C++ 标准库中的信号量类，可以实现对共享资源的同步控制，解决多线程编程中的同步问题。

  * 信号量可以决定线程当前是继续运行还是等待

  * 信号量代表某一类资源，其值表示系统中该资源的数量。因此它是一个非负数的值

  * 信号量是一个受保护的变量，只能通过三种操作来访问：

    * 初始化
    * P操作（申请资源）
      * 当进行P操作时，它会去**判断当前信号量的值是否大于0**，**若是，则申请P操作的任务继续运行，同时信号量的值减一**。**若否，则阻塞**
    * V操作（释放资源）
      * V操作则是**先让信号量的值加一**，**再判断当前是否有正在等待资源的任务以让它继续运行**


#### 2.6 barrier
屏障主要用于多个线程之间的并行工作的协调。**屏障允许每个线程等待，直到所有的合作线程都达到某个点，然后从该点继续执行**


### 99. quiz

#### 1. `std::lock_guard`和`std::unique_lock`有什么不同？

`std::lock_guard` 和 `std::unique_lock` 都是 RAII（Resource Acquisition Is Initialization）风格的互斥锁包装器，它们在构造时自动锁定互斥锁，在析构时自动解锁互斥锁。这种设计可以确保在函数退出（无论是正常退出还是异常退出）时自动释放锁，从而避免因忘记解锁而导致的死锁。

`std::lock_guard`和`std::unique_lock`的主要区别在于:

1.  **延迟锁定**：
    - `std::unique_lock` 可以在创建时不立即锁定互斥锁，然后在需要的时候再锁定。
    - `std::lock_guard` 则在创建时必须立即锁定互斥锁。
2.  **所有权传递**：
    - `std::unique_lock` 是可移动的，这意味着你可以将锁的所有权从一个 `std::unique_lock` 对象转移到另一个。
    - `std::lock_guard` 则不可移动。
3.  **手动锁定和解锁**：
    - `std::unique_lock` 提供了 `lock` 和 `unlock` 方法，允许你在任何时候手动锁定和解锁互斥锁。
    - `std::lock_guard` 则不提供这些方法。

使用选择上

- **`std::unique_lock`**：

  - 适用于需要更多控制的场景，例如延迟锁定、所有权传递或手动锁定和解锁。
  - 提供更大的灵活性，但相对开销也更大。

- **`std::lock_guard`**：
  - 适用于简单的锁定和解锁场景。
  - 更简单，且开销更小。

#### 2. `std::unique_lock`提供的锁策略参数是什么？

`std::adopt_lock`/`std::defer_lock` 和 `std::try_to_lock` 都是 `std::unique_lock` 的构造函数可以接受的锁策略参数,它们的含义和使用场景如下:

1.  **std::adopt_lock**:这个策略表示互斥锁在构造锁对象时已经被锁定.当你已经手动锁定了一个互斥锁,然后想要将它的管理权交给 `std::unique_lock` 时,可以使用 `std::adopt_lock`.这样,`std::unique_lock` 在构造时就不会再次尝试锁定互斥锁,而是直接接管已经被锁定的互斥锁.

2.  **std::defer_lock**:这个策略表示在构造 `std::unique_lock` 时不锁定互斥锁.你可以稍后手动调用 `std::unique_lock::lock` 方法来锁定互斥锁.这个策略在你需要延迟锁定互斥锁的情况下很有用.

3.  **std::try_to_lock**:这个策略表示在构造 `std::unique_lock` 时尝试锁定互斥锁,如果互斥锁已经被锁定,则立即返回,不会阻塞.你可以检查 `std::unique_lock::owns_lock` 方法的返回值,来判断是否成功锁定了互斥锁.

#### 3. C++11 的 thread_local 是什么？

`thread_local`是 C++11 引入的一个关键字，用于声明线程局部存储（Thread Local Storage，TLS）。
当一个变量被声明为`thread_local`时，每个线程都会有这个变量的一个副本，每个线程对其副本的修改都不会影响其他线程的副本。
这对于多线程编程非常有用，因为它可以让每个线程拥有自己的全局变量或静态变量的副本，避免了多线程之间的数据竞争。

以下是一个简单的例子：

```cpp
#include <thread>

thread_local int tls_var = 0;

void worker() {
    tls_var++; // 对tls_var的修改不会影响其他线程的tls_var
}

int main() {
    std::thread t1(worker);
    std::thread t2(worker);

    t1.join();
    t2.join();

    return 0;
}
```

在这个例子中，每个线程都有自己的`tls_var`副本，它们对`tls_var`的修改不会相互影响。

#### 4. 不使用 `join` 也不使用 `detach`，会发生什么
  - **问题**：
    - 在主线程退出时，可能会导致一些未定义行为，因为线程对象将被销毁，但线程本身可能仍在运行。

  - **可能发生的情况**：
    1. **程序可能终止，但线程可能仍在运行**：
    - 如果主线程退出，而被创建的线程仍在运行，可能导致程序终止，但线程继续执行。这可能导致线程无法正确完成其任务，因为主线程已经退出。
    2. **程序可能会崩溃**：
    - 这是由于线程对象的销毁可能涉及到一些资源的释放，而线程本身仍在访问这些资源，导致未定义行为。
    3. **资源泄漏**：
    - 如果线程分配了一些资源（例如内存），但在线程执行完毕前这些资源没有被释放，可能会导致资源泄漏。
