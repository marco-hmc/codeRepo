# 负载均衡

负载均衡使我们能够将传入的网络流量分配到多个资源上，确保高可用性和可靠性，只将请求发送到在线资源。这提供了根据需求添加或减少资源的灵活性。

![负载均衡](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/load-balancer.png)

为了增加可扩展性和冗余性，我们可以尝试在系统的每一层进行负载均衡：

![负载均衡层](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/load-balancer-layers.png)

## 为什么需要负载均衡？

现代高流量网站必须处理成千上万甚至数百万的并发用户或客户端请求。为了以成本效益的方式扩展以满足这些高流量需求，现代计算的最佳实践通常要求添加更多服务器。

负载均衡器可以位于服务器前面，并以最大化速度和容量利用率的方式将客户端请求路由到所有能够满足这些请求的服务器。这确保了没有单个服务器过载，从而避免性能下降。如果单个服务器宕机，负载均衡器会将流量重定向到剩余的在线服务器。当新服务器添加到服务器组时，负载均衡器会自动开始向其发送请求。

## 工作负载分配

这是负载均衡器提供的核心功能，有几种常见的变体：

- **基于主机**：根据请求的主机名分配请求。
- **基于路径**：使用整个 URL 分配请求，而不仅仅是主机名。
- **基于内容**：检查请求的消息内容。这允许基于内容（如参数值）进行分配。

## 层次

一般来说，负载均衡器在以下两个层次之一操作：

### 网络层

这是在网络传输层工作的负载均衡器，也称为第 4 层。它基于网络信息（如 IP 地址）进行路由，无法执行基于内容的路由。这些通常是专用的硬件设备，可以高速运行。

### 应用层

这是在应用层工作的负载均衡器，也称为第 7 层。负载均衡器可以读取整个请求并执行基于内容的路由。这允许基于对流量的全面理解来管理负载。

## 类型

让我们看看不同类型的负载均衡器：

### 软件

软件负载均衡器通常比硬件版本更容易部署。它们也往往更具成本效益和灵活性，通常与软件开发环境一起使用。软件方法使我们能够根据环境的具体需求配置负载均衡器。灵活性的提升可能需要更多的工作来设置负载均衡器。与提供更多封闭盒子方法的硬件版本相比，软件负载均衡器使我们能够更自由地进行更改和升级。

软件负载均衡器被广泛使用，可以作为需要配置和管理的可安装解决方案或作为托管云服务提供。

### 硬件

顾名思义，硬件负载均衡器依赖于物理的本地硬件来分配应用程序和网络流量。这些设备可以处理大量流量，但通常价格昂贵且灵活性有限。

硬件负载均衡器包括专有固件，需要在发布新版本和安全补丁时进行维护和更新。

### DNS

DNS 负载均衡是配置域名系统 (DNS) 中的域名，以便将客户端请求分配到一组服务器机器上的做法。

不幸的是，DNS 负载均衡存在固有问题，限制了其可靠性和效率。最显著的是，DNS 不检查服务器和网络中断或错误。即使服务器宕机或无法访问，它总是返回域名的一组 IP 地址。

## 路由算法

现在，让我们讨论常用的路由算法：

- **轮询**：请求按顺序分配到应用服务器。
- **加权轮询**：在简单轮询技术的基础上，考虑不同服务器特性（如计算和流量处理能力），使用管理员通过 DNS 记录分配的权重。
- **最少连接**：新请求发送到当前与客户端连接最少的服务器。每个服务器的相对计算能力被考虑在内，以确定哪个服务器连接最少。
- **最少响应时间**：将请求发送到通过结合最快响应时间和最少活动连接选择的服务器。
- **最少带宽**：此方法以每秒兆比特 (Mbps) 测量流量，将客户端请求发送到流量最少的服务器。
- **哈希**：基于我们定义的键（如客户端 IP 地址或请求 URL）分配请求。

## 优点

负载均衡在防止停机方面也起着关键作用，其他优点包括：

- 可扩展性
- 冗余性
- 灵活性
- 效率

## 冗余负载均衡器

正如你可能已经猜到的，负载均衡器本身可能成为单点故障。为了解决这个问题，可以使用第二个或 [`N`](command:_github.copilot.openSymbolFromReferences?%5B%22%22%2C%5B%7B%22uri%22%3A%7B%22scheme%22%3A%22file%22%2C%22authority%22%3A%22%22%2C%22path%22%3A%22%2Fhome%2Fmarco%2FgitRepo%2FcodeRepo%2F1_notes%2F1_%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2Fxxx.md%22%2C%22query%22%3A%22%22%2C%22fragment%22%3A%22%22%7D%2C%22pos%22%3A%7B%22line%22%3A80%2C%22character%22%3A122%7D%7D%5D%2C%22f68ba875-7195-4c28-afe1-debe78e8147b%22%5D "Go to definition") 个负载均衡器以集群模式运行。

如果有故障检测并且_活动_负载均衡器失败，另一个_被动_负载均衡器可以接管，这将使我们的系统更具容错性。

![冗余负载均衡](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/redundant-load-balancer.png)

## 功能

以下是一些常见的负载均衡器功能：

- **自动扩展**：根据需求条件启动和关闭资源。
- **粘性会话**：能够将相同用户或设备分配到相同资源，以保持资源上的会话状态。
- **健康检查**：确定资源是否宕机或性能不佳，以便将其从负载均衡池中移除。
- **持久连接**：允许服务器与客户端建立持久连接，如 WebSocket。
- **加密**：处理加密连接，如 TLS 和 SSL。
- **证书**：向客户端展示证书并验证客户端证书。
- **压缩**：压缩响应。
- **缓存**：应用层负载均衡器可能提供缓存响应的能力。
- **日志记录**：请求和响应元数据的日志记录可以作为重要的审计跟踪或分析数据来源。
- **请求跟踪**：为每个请求分配唯一 ID 以进行日志记录、监控和故障排除。
- **重定向**：基于请求路径等因素重定向传入请求的能力。
- **固定响应**：为请求返回静态响应，如错误消息。

## 示例

以下是一些常用的负载均衡解决方案：

- [Amazon Elastic Load Balancing](https://aws.amazon.com/elasticloadbalancing)
- [Azure Load Balancing](https://azure.microsoft.com/en-in/services/load-balancer)
- [GCP Load Balancing](https://cloud.google.com/load-balancing)
- [DigitalOcean Load Balancer](https://www.digitalocean.com/products/load-balancer)
- [Nginx](https://www.nginx.com)
- [HAProxy](http://www.haproxy.org)

# 集群

从高层次来看，计算机集群是一组两个或多个计算机或节点，它们并行运行以实现共同目标。这允许由大量单独的、可并行化任务组成的工作负载在集群中的节点之间分配。因此，这些任务可以利用每台计算机的组合内存和处理能力来提高整体性能。

要构建计算机集群，单个节点应连接到网络以启用节点间通信。然后可以使用软件将节点连接在一起并形成集群。它可能有一个共享存储设备和/或每个节点上的本地存储。

![集群](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/cluster.png)

通常，至少一个节点被指定为领导节点，作为集群的入口点。领导节点可能负责将传入工作委派给其他节点，并在必要时汇总结果并返回响应给用户。

理想情况下，集群应像单一系统一样运行。访问集群的用户不需要知道系统是集群还是单个机器。此外，集群应设计为最小化延迟并防止节点间通信中的瓶颈。

## 类型

计算机集群通常可以分为三种类型：

- 高可用性或故障转移
- 负载均衡
- 高性能计算

## 配置

最常用的高可用性 (HA) 集群配置有两种：主动-主动和主动-被动。

### 主动-主动

![主动-主动](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/active-active.png)

主动-主动集群通常由至少两个节点组成，这两个节点同时运行相同类型的服务。主动-主动集群的主要目的是实现负载均衡。负载均衡器在所有节点之间分配工作负载，以防止任何单个节点过载。由于有更多节点可用来提供服务，吞吐量和响应时间也会有所改善。

### 主动-被动

![主动-被动](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/active-passive.png)

与主动-主动集群配置类似，主动-被动集群也由至少两个节点组成。然而，正如_主动-被动_名称所暗示的，并非所有节点都将处于活动状态。例如，在两个节点的情况下，如果第一个节点已经处于活动状态，则第二个节点必须处于被动或待机状态。

## 优点

集群计算的四个关键优点如下：

- 高可用性
- 可扩展性
- 性能
- 成本效益

## 负载均衡 vs 集群

负载均衡与集群共享一些共同特征，但它们是不同的过程。集群提供冗余并提高容量和可用性。集群中的服务器彼此了解并共同工作以实现共同目标。但在负载均衡中，服务器彼此不了解。相反，它们对从负载均衡器接收到的请求做出反应。

我们可以将负载均衡与集群结合使用，但它也适用于涉及独立服务器的情况，这些服务器共享一个共同目标，例如运行网站、业务应用程序、Web 服务或其他 IT 资源。

## 挑战

集群带来的最明显的挑战是安装和维护的复杂性增加。操作系统、应用程序及其依赖项必须在每个节点上安装和更新。

如果集群中的节点不均匀，这将变得更加复杂。还必须密切监控每个节点的资源利用情况，并聚合日志以确保软件正常运行。

此外，存储管理变得更加困难，共享存储设备必须防止节点相互覆盖，分布式数据存储必须保持同步。

## 示例

集群在行业中被广泛使用，许多技术通常提供某种集群模式。例如：

- 容器（例如 [Kubernetes](https://kubernetes.io)，[Amazon ECS](https://aws.amazon.com/ecs)）
- 数据库（例如 [Cassandra](https://cassandra.apache.org/_/index.html)，[MongoDB](https://www.mongodb.com)）
- 缓存（例如 [Redis](https://redis.io/docs/manual/scaling)）

# 代理

代理服务器是位于客户端和后端服务器之间的中间硬件/软件。它接收来自客户端的请求并将其转发到源服务器。通常，代理用于过滤请求、记录请求或有时转换请求（通过添加/删除头、加密/解密或压缩）。

## 类型

代理有两种类型：

### 正向代理

正向代理，通常称为代理、代理服务器或 Web 代理，是位于一组客户端计算机前面的服务器。当这些计算机向互联网上的网站和服务发出请求时，代理服务器拦截这些请求，然后代表这些客户端与 Web 服务器通信，就像中间人一样。

![forward-proxy](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/proxy/forward-proxy.png)

**优点**

以下是正向代理的一些优点：

- 阻止访问某些内容
- 允许访问[地理限制](https://en.wikipedia.org/wiki/Geo-blocking)的内容
- 提供匿名性
- 避免其他浏览限制

尽管代理提供了匿名性的好处，但它们仍然可以跟踪我们的个人信息。设置和维护代理服务器可能成本高昂且需要配置。

### 反向代理

反向代理是位于一个或多个 Web 服务器前面的服务器，拦截来自客户端的请求。当客户端向网站的源服务器发送请求时，这些请求会被反向代理服务器拦截。

正向代理和反向代理之间的区别微妙但重要。一个简化的总结是，正向代理位于客户端前面，确保没有源服务器直接与特定客户端通信。另一方面，反向代理位于源服务器前面，确保没有客户端直接与源服务器通信。

![reverse-proxy](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/proxy/reverse-proxy.png)

引入反向代理会增加复杂性。单个反向代理是单点故障，配置多个反向代理（即故障转移）会进一步增加复杂性。

**优点**

以下是使用反向代理的一些优点：

- 提高安全性
- 缓存
- SSL 加密
- 负载均衡
- 可扩展性和灵活性

## 负载均衡器 vs 反向代理

等等，反向代理和负载均衡器不是很相似吗？其实不然，因为负载均衡器在我们有多个服务器时很有用。通常，负载均衡器将流量路由到一组执行相同功能的服务器，而反向代理即使只有一个 Web 服务器或应用服务器也很有用。反向代理也可以充当负载均衡器，但反过来则不行。

## 示例

以下是一些常用的代理技术：

- [Nginx](https://www.nginx.com)
- [HAProxy](http://www.haproxy.org)
- [Traefik](https://doc.traefik.io/traefik)
- [Envoy](https://www.envoyproxy.io)

# 可用性

可用性是指系统在特定时间段内保持运行以执行其所需功能的时间。它是衡量系统、服务或机器在正常条件下保持运行的时间百分比的简单指标。

## 可用性的九个等级

可用性通常通过服务可用时间（或停机时间）作为百分比来量化。通常以几个 9 来衡量。

$$
Availability = \frac{Uptime}{(Uptime + Downtime)}
$$

如果可用性为 99.00%，则称其为“两个 9”的可用性，如果为 99.9%，则称其为“三个 9”，依此类推。

| 可用性（百分比）       | 年停机时间         | 月停机时间       | 周停机时间         |
| --------------------- | ------------------ | ---------------- | ------------------ |
| 90%（一个 9）         | 36.53 天           | 72 小时          | 16.8 小时          |
| 99%（两个 9）         | 3.65 天            | 7.20 小时        | 1.68 小时          |
| 99.9%（三个 9）       | 8.77 小时          | 43.8 分钟        | 10.1 分钟          |
| 99.99%（四个 9）      | 52.6 分钟          | 4.32 分钟        | 1.01 分钟          |
| 99.999%（五个 9）     | 5.25 分钟          | 25.9 秒          | 6.05 秒            |
| 99.9999%（六个 9）    | 31.56 秒           | 2.59 秒          | 604.8 毫秒         |
| 99.99999%（七个 9）   | 3.15 秒            | 263 毫秒         | 60.5 毫秒          |
| 99.999999%（八个 9）  | 315.6 毫秒         | 26.3 毫秒        | 6 毫秒             |
| 99.9999999%（九个 9） | 31.6 毫秒          | 2.6 毫秒         | 0.6 毫秒           |

## 串行 vs 并行中的可用性

如果一个服务由多个容易出故障的组件组成，服务的整体可用性取决于这些组件是串行还是并行。

### 串行

当两个组件是串行时，整体可用性降低。

$$
Availability \space (Total) = Availability \space (Foo) * Availability \space (Bar)
$$

例如，如果 [`Foo`](command:_github.copilot.openSymbolFromReferences?%5B%22%22%2C%5B%7B%22uri%22%3A%7B%22scheme%22%3A%22file%22%2C%22authority%22%3A%22%22%2C%22path%22%3A%22%2Fhome%2Fmarco%2FgitRepo%2FcodeRepo%2F1_notes%2F1_%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2Fxxx.md%22%2C%22query%22%3A%22%22%2C%22fragment%22%3A%22%22%7D%2C%22pos%22%3A%7B%22line%22%3A274%2C%22character%22%3A51%7D%7D%5D%2C%227cd939ef-6d67-4676-97e9-e0ce2f376c05%22%5D "Go to definition") 和 [`Bar`](command:_github.copilot.openSymbolFromReferences?%5B%22%22%2C%5B%7B%22uri%22%3A%7B%22scheme%22%3A%22file%22%2C%22authority%22%3A%22%22%2C%22path%22%3A%22%2Fhome%2Fmarco%2FgitRepo%2FcodeRepo%2F1_notes%2F1_%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2Fxxx.md%22%2C%22query%22%3A%22%22%2C%22fragment%22%3A%22%22%7D%2C%22pos%22%3A%7B%22line%22%3A274%2C%22character%22%3A79%7D%7D%5D%2C%227cd939ef-6d67-4676-97e9-e0ce2f376c05%22%5D "Go to definition") 的可用性都是 99.9%，它们串行的总可用性将是 99.8%。

### 并行

当两个组件是并行时，整体可用性增加。

$$
Availability \space (Total) = 1 - (1 - Availability \space (Foo)) * (1 - Availability \space (Bar))
$$

例如，如果 [`Foo`](command:_github.copilot.openSymbolFromReferences?%5B%22%22%2C%5B%7B%22uri%22%3A%7B%22scheme%22%3A%22file%22%2C%22authority%22%3A%22%22%2C%22path%22%3A%22%2Fhome%2Fmarco%2FgitRepo%2FcodeRepo%2F1_notes%2F1_%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2Fxxx.md%22%2C%22query%22%3A%22%22%2C%22fragment%22%3A%22%22%7D%2C%22pos%22%3A%7B%22line%22%3A274%2C%22character%22%3A51%7D%7D%5D%2C%227cd939ef-6d67-4676-97e9-e0ce2f376c05%22%5D "Go to definition") 和 [`Bar`](command:_github.copilot.openSymbolFromReferences?%5B%22%22%2C%5B%7B%22uri%22%3A%7B%22scheme%22%3A%22file%22%2C%22authority%22%3A%22%22%2C%22path%22%3A%22%2Fhome%2Fmarco%2FgitRepo%2FcodeRepo%2F1_notes%2F1_%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2Fxxx.md%22%2C%22query%22%3A%22%22%2C%22fragment%22%3A%22%22%7D%2C%22pos%22%3A%7B%22line%22%3A274%2C%22character%22%3A79%7D%7D%5D%2C%227cd939ef-6d67-4676-97e9-e0ce2f376c05%22%5D "Go to definition") 的可用性都是 99.9%，它们并行的总可用性将是 99.9999%。

## 可用性 vs 可靠性

如果一个系统是可靠的，它就是可用的。然而，如果它是可用的，它不一定是可靠的。换句话说，高可靠性有助于高可用性，但即使在不可靠的系统中也可以实现高可用性。

## 高可用性 vs 容错

高可用性和容错都适用于提供高正常运行时间的方法。然而，它们实现目标的方式不同。

容错系统没有服务中断，但成本显著更高，而高可用系统有最小的服务中断。容错需要完全的硬件冗余，因为如果主系统失败，没有正常运行时间的损失，另一个系统应该接管。

# 可扩展性

可扩展性是衡量系统通过添加或删除资源来响应变化的能力。

![scalability](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/scalability/scalability.png)

让我们讨论不同类型的扩展：

## 垂直扩展

垂直扩展（也称为向上扩展）通过向现有机器添加更多功能来扩展系统的可扩展性。换句话说，垂直扩展是指通过增加硬件容量来提高应用程序的能力。

### 优点

- 实现简单
- 易于管理
- 数据一致

### 缺点

- 高停机风险
- 升级困难
- 可能成为单点故障

## 水平扩展

水平扩展（也称为向外扩展）通过添加更多机器来扩展系统的规模。它通过向现有服务器池中添加更多实例来提高服务器的性能，从而使负载分布更加均匀。

### 优点

- 增加冗余
- 更好的容错
- 灵活高效
- 升级更容易

### 缺点

- 增加复杂性
- 数据不一致
- 增加下游服务的负载

# 存储

存储是一种使系统能够暂时或永久保留数据的机制。在系统设计的背景下，这个话题通常被忽略，但了解一些常见的存储技术有助于我们优化存储组件。让我们讨论一些重要的存储概念：

## RAID

RAID（独立磁盘冗余阵列）是一种将相同数据存储在多个硬盘或固态硬盘（SSD）上的方法，以在驱动器故障的情况下保护数据。

有不同的 RAID 级别，并非所有级别都旨在提供冗余。让我们讨论一些常用的 RAID 级别：

- **RAID 0**：也称为条带化，数据均匀分布在阵列中的所有驱动器上。
- **RAID 1**：也称为镜像，至少两个驱动器包含一组数据的精确副本。如果一个驱动器故障，其他驱动器仍然可以工作。
- **RAID 5**：带有奇偶校验的条带化。需要至少 3 个驱动器，像 RAID 0 一样将数据分布在多个驱动器上，但也在驱动器上分布奇偶校验。
- **RAID 6**：带有双奇偶校验的条带化。RAID 6 类似于 RAID 5，但奇偶校验数据写入两个驱动器。
- **RAID 10**：结合 RAID 0 和 RAID 1 的条带化和镜像。通过在次级驱动器上镜像所有数据提供安全性，同时在每组驱动器上使用条带化以加快数据传输。

### 比较

让我们比较不同 RAID 级别的所有特性：

| 特性                 | RAID 0   | RAID 1               | RAID 5               | RAID 6                      | RAID 10                                  |
| -------------------- | -------- | -------------------- | -------------------- | --------------------------- | ---------------------------------------- |
| 描述                 | 条带化   | 镜像                 | 带奇偶校验的条带化   | 带双奇偶校验的条带化        | 条带化和镜像                             |
| 最少磁盘数           | 2        | 2                    | 3                    | 4                           | 4                                        |
| 读取性能             | 高       | 高                   | 高                   | 高                          | 高                                       |
| 写入性能             | 高       | 中                   | 高                   | 高                          | 中                                       |
| 成本                 | 低       | 高                   | 低                   | 低                          | 高                                       |
| 容错                 | 无       | 单驱动器故障         | 单驱动器故障         | 双驱动器故障                | 每个子阵列最多一个驱动器故障             |
| 容量利用率           | 100%     | 50%                  | 67%-94%              | 50%-80%                     | 50%                                      |

## 卷

卷是磁盘或磁带上的固定存储量。卷这个术语通常用作存储本身的同义词，但单个磁盘可能包含多个卷，或者一个卷可能跨越多个磁盘。

## 文件存储

文件存储是一种将数据存储为文件并以分层目录结构呈现给最终用户的解决方案。主要优点是提供用户友好的解决方案来存储和检索文件。要在文件存储中定位文件，需要文件的完整路径。它经济且易于结构化，通常在硬盘上找到，这意味着它们对用户和硬盘看起来完全相同。

示例：[Amazon EFS](https://aws.amazon.com/efs)，[Azure 文件](https://azure.microsoft.com/en-in/services/storage/files)，[Google Cloud Filestore](https://cloud.google.com/filestore) 等。

## 块存储

块存储将数据分成块（块）并将其作为单独的部分存储。每个数据块都有一个唯一标识符，这使得存储系统可以将较小的数据块放置在最方便的位置。

块存储还将数据与用户环境分离，使数据可以跨多个环境分布。这创建了多个数据访问路径，使用户能够快速检索数据。当用户或应用程序从块存储系统请求数据时，底层存储系统会重新组装数据块并将数据呈现给用户或应用程序。

示例：[Amazon EBS](https://aws.amazon.com/ebs)。

## 对象存储

对象存储，也称为基于对象的存储，将数据文件分解成称为对象的部分。然后将这些对象存储在一个可以跨多个网络系统分布的单一存储库中。

示例：[Amazon S3](https://aws.amazon.com/s3)，[Azure Blob Storage](https://azure.microsoft.com/en-in/services/storage/blobs)，[Google Cloud Storage](https://cloud.google.com/storage) 等。

## NAS

网络附加存储 (NAS) 是连接到网络的存储设备，允许授权网络用户从中央位置存储和检索数据。NAS 设备是灵活的，这意味着当我们需要额外存储时，可以添加到现有存储中。它更快、成本更低，并提供现场公共云的所有好处，使我们能够完全控制。

## HDFS

Hadoop 分布式文件系统 (HDFS) 是一种设计用于在商品硬件上运行的分布式文件系统。HDFS 高度容错，设计用于在低成本硬件上部署。HDFS 提供对应用数据的高吞吐量访问，适用于具有大数据集的应用程序。它与现有的分布式文件系统有许多相似之处。

HDFS 设计用于可靠地在大型集群中的机器上存储非常大的文件。它将每个文件存储为一系列块，文件中的所有块（除了最后一个块）大小相同。为了容错，文件的块会被复制。