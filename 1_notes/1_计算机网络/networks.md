---
title: "计算机网络中的开发需知"
layout: post
author: "Marco"
header-style: text
hidden: true
tags:
  - 计算机网络
---
![alt text](_imgs/image.png)
**封装**
上层协议发送到下层协议. 通过封装实现, 层与层之间传输的时候, 加上自己的头部信息.
被TCP封装的数据成为 `TCP报文段`
- 内核部分发送成功后删除数据

被UDP封装的数据成为 `UDP数据报`
- 发送后即删除

再经IP封装后成为`IP数据报`
最后经过数据链路层封装后为 `帧`

以太网最大数据帧1518字节 抛去14头部 帧尾4校验
MTU: 帧的最大传输单元 一般为1500字节
MSS: TCP数据包最大的数据载量 1460字节 = 1500字节 - 20Ip头-20TCP头 还有额外的40字节可选部分


**ARP**
ARP协议能实现任意网络层地址到任意物理地址的转换

![alt text](_imgs/image-2.png)

## 计算机网络

### 1. 基本概念

- ***计算机网络有哪几层?***
  - 应用层:负责向用户提供应用程序,应用层为操作系统或网络应用程序提供访问网络服务的接口,比如HTTP/FTP/Telnet/DNS/SMTP等
  - 传输层:负责对报文进行分组和重组,传输层是第一个端到端,即主机到主机的层次,传输层负责将上层数据分段并提供端到端的/可靠的或不可靠的传输,传输层还要处理端到端的差错控制和流量控制问题,数据的单位称为数据段(segment),并以TCP或UDP协议格式封装报文
  - 网络层:负责路由以及把分组报文发送给目标网络或主机,网络层负责对子网间的数据包进行路由选择,还可以实现拥塞控制/网际互连等功能,数据的单位称为数据包(packet)
  - 链路层:负责封装和解封装IP报文,物理地址寻址/数据的成帧/流量控制/数据的检错/重发等,发送和接受ARP/RARP报文等

> 网络层只把分组发送到目的主机,但是真正通信的并不是主机而是主机中的进程.
> 传输层提供了进程间的逻辑通信,传输层向高层用户屏蔽了下面网络层的核心细节,使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道.

- ***网络为什么要分层?***
  网络分层的主要原因是为了降低网络设计的复杂性,提高网络的可扩展性和可维护性.以下是一些具体的原因:

  1. **模块化设计**:每一层都有特定的功能,这使得设计和实现网络协议变得更加简单.如果需要改进或替换某一层的协议,只需要修改那一层,而不会影响到其他层.

  2. **易于理解和教学**:分层模型使得网络的工作原理更容易理解和教学.每一层都有明确的职责,可以单独学习和理解.

  3. **兼容性和互操作性**:分层模型使得不同的硬件和网络协议可以一起工作.只要每一层都遵循相同的接口和协议,就可以在不同的网络环境中互相通信.

  4. **可扩展性**:分层模型使得网络可以更容易地扩展和适应新的技术.例如,当新的传输协议被开发出来时,只需要在传输层实现这个新协议,而不需要改变其他层.

  5. **错误隔离**:如果某一层出现问题,分层模型可以帮助隔离错误,防止错误影响到其他层.

  一个网络数据包,必须是一个健全的数据包,跑起来才能快过刘翔.数据包无论经过那个设备都必须是完整,所以当一个请求从终端发起的时候(应用层)发起的时候,例如http请求.
  应用层: 这个请求的正文就会被包上一个http头;
  传输层: 然后就会给到下一层传输层,传输层就会给数据包上tcp的头,tcp就会记录下源端口号和目的端口号.
  网络层: 紧接着发给ip层(网络层)网络层就会给你包上ip头,记录源ip地址和目标ip地址.
  链路层: 紧接着就会发到mac层(数据链路层),mac层就会给数据包包上mac头,记录源mac地址和目的mac地址.(还要看目标mac地址是不是知道的,知道就直接加上去,不知道就吼一下(通过一定的协议处理).)

  所以通过上面我们知道,每一层都需要工作,而且这是一个复杂的程序,每一层都有不同的处理方式,所以这是一个层层封装的概念,如果没有层层封装,整个数据包我们认为是不完整的.

### 2. 应用层

- ***应用层有哪些?***

  计算机网络的应用层有许多协议,常见的包括:

  - HTTP(超文本传输协议):用于在Web浏览器和Web服务器之间传输超文本文档.
  - FTP(文件传输协议):用于在客户端和服务器之间传输文件.
  - SMTP(简单邮件传输协议):用于在邮件客户端和邮件服务器之间传输电子邮件.
  - DNS(域名系统):用于将域名解析为IP地址.
  - SSH(安全外壳协议):用于在网络上安全地远程登录到远程计算机.
  - Telnet(远程终端协议):用于在网络上远程登录到远程计算机.
  - POP3(邮局协议版本3):用于从邮件服务器接收电子邮件.
  - IMAP(互联网消息访问协议):用于从邮件服务器接收和管理电子邮件.

### 3. 传输层

- ***传输层有哪些协议?***
计算机网络的传输层主要有以下几种协议:

  - TCP(传输控制协议):它是一种面向连接的/可靠的/基于字节流的传输层通信协议.TCP确保了数据包按照其发送顺序到达.

  - UDP(用户数据报协议):它是一种无连接的/不可靠的/基于数据报的传输层协议.UDP不保证数据包的到达顺序,因此它的速度通常比TCP快.

  - SCTP(流控制传输协议):它提供了TCP所缺少的一些特性,例如多流传输和多路径传输.

  - DCCP(数据报拥塞控制协议):它是一种面向消息的传输协议,提供了UDP的一些特性,同时还提供了拥塞控制.

  这些都是传输层的主要协议,每种协议都有其特定的用途和特性.

### 4. 网络层

- ***网络层有哪些协议?***
  计算机网络的网络层主要有以下几种协议:

  - IP(互联网协议):它是网络层的主要协议,负责将数据包从源主机发送到目标主机.IP协议有两个版本,IPv4和IPv6.

  - ICMP(互联网控制消息协议):它用于在IP主机和路由器之间传输控制消息.

  - IGMP(互联网组管理协议):它用于在局域网内实现多播.

  - ARP(地址解析协议):它用于将网络层的IP地址映射到数据链路层的物理地址.

  - RARP(反向地址解析协议):它用于将数据链路层的物理地址映射到网络层的IP地址.

  这些都是网络层的主要协议,每种协议都有其特定的用途和特性.
### 5. 链路层

- ***链路层有哪些协议?***
  计算机网络的链路层(也被称为数据链路层或网络接口层)主要有以下几种协议:

  - ARP(地址解析协议):这是一种用于将IP地址映射到MAC地址的协议.

  - Ethernet(以太网协议):这是最常见的局域网技术,使用MAC地址进行通信.

  - Wi-Fi(无线局域网协议):这是一种无线网络协议,基于IEEE 802.11标准.

  - PPP(点对点协议):这是一种用于建立直接连接的协议,常用于拨号和DSL连接.

  - VLAN(虚拟局域网协议):这是一种在物理网络上创建逻辑网络的协议.

  - Frame Relay(帧中继协议):这是一种高性能的WAN协议.

  - ATM(异步传输模式):这是一种用于电话和数据网络的协议.

  这些都是链路层的主要协议,每种协议都有其特定的用途和特性.
  
# 网络各层协议及功能

<img src="imgs/network/protocols.png" alt="protocols" style="zoom: 67%;" />

* https://www.jianshu.com/p/bb363a41afcf
* 四层模型
  * 应用层:负责向用户提供应用程序,应用层为操作系统或网络应用程序提供访问网络服务的接口,比如HTTP/FTP/Telnet/DNS/SMTP等
  * 传输层:负责对报文进行分组和重组,传输层是第一个端到端,即主机到主机的层次,传输层负责将上层数据分段并提供端到端的/可靠的或不可靠的传输,传输层还要处理端到端的差错控制和流量控制问题,数据的单位称为数据段(segment),并以TCP或UDP协议格式封装报文
  * 网络层:负责路由以及把分组报文发送给目标网络或主机,网络层负责对子网间的数据包进行路由选择,还可以实现拥塞控制/网际互连等功能,数据的单位称为数据包(packet)
  * 链路层:负责封装和解封装IP报文,物理地址寻址/数据的成帧/流量控制/数据的检错/重发等,发送和接受ARP/RARP报文等

# 应用层协议常用端口

|       应用       | 应用层协议 | 端口号  | 传输层协议 |            备注             |
| :--------------: | :--------: | :-----: | :--------: | :-------------------------: |
|     域名解析     |    DNS     |   53    |  UDP/TCP   | 长度超过 512 字节时使用 TCP |
| 动态主机配置协议 |    DHCP    |  67/68  |    UDP     |                             |
| 简单网络管理协议 |    SNMP    | 161/162 |    UDP     |                             |
|   文件传送协议   |    FTP     |  20/21  |    TCP     |  控制连接 21,数据连接 20   |
|   远程终端协议   |   TELNET   |   23    |    TCP     |                             |
|       ssh        |    ssh     |   22    |    TCP     |                             |
|  超文本传送协议  |    HTTP    |   80    |    TCP     |                             |
| 简单邮件传送协议 |    SMTP    |   25    |    TCP     |                             |
|   邮件读取协议   |    POP3    |   110   |    TCP     |                             |
| 网际报文存取协议 |    IMAP    |   143   |    TCP     |                             |

# TCP

<img src="imgs/network/tcp_header.png" alt="tcp_header" style="zoom:67%;" />

## TCP状态转换图

<img src="imgs/network/tcp.png" alt="tcp" style="zoom: 67%;" />

## TCP计时器

TCP使用的四种计时器:

1. 重传计时器
   * 当TCP发送报文段时,就创建该特定报文段的重传计时器
   * 若在计时器截止时间到(通常60秒)之前收到了对此特定报文段的确认,则撤销此计时器
   * 若在计时器截止时间之前没有收到对此特定报文的确认,则就认为该报文丢失,需要重传此报文段,并将计时器复位

2. 坚持计时器
   * **假设TCP收到了一个窗口大小为0报文段,发送TCP就停止传送报文段,直到接收TCP发送一个非零的窗口大小**.但是这个确认有可能丢失,若确认丢了,接收TCP并不会知道,而是认为他已经完成任务了.但是发送TCP由于没有收到确认,就会一直等待接收方发送确认来通知窗口的大小.双方的TCP这时就会造成死锁,所以要使用一个计时器来避免死锁的发送
   * **当TCP收到一个窗口大小为0的确认时,就要启动坚持计时器**.当坚持计时器期限到时,发送TCP就发送一个特殊的探测报文,这个探测报文段只有一个字节数据,它有一个序号,但是它的序号永远不需要确认.探测报文段提醒对端,确认已丢失,必须重传
   * 坚持计时器的值设置为重传时间的数值.**若没有收到从接收端来的响应,需要发送一个探测报文,并将坚持计时器的值加倍和复位,直到这个值增大到门限值(通常60秒)为止**.在这以后,发送端每隔60秒发送一个探测报文,直到窗口重新打开

3. 保活计时器
   * 保活计时器用来防止两个TCP之间的连续出现长时间的空闲
   * 假定客户已主动与服务器建立了TCP链接.然后这个客户端出现故障.在这种情况下,这个链接就会永远的处于打开状态.而服务器维护一个链接,也是要耗费一定的资源的,所以必须采取措施,使服务器不能白白等下去
   * 要解决这种问题,就要对服务器设置保活计时器.每当服务器收到客户的信息,就将计时器复位,保活时间通常设置为2小时.若服务器过了两小时还没有收到客户的信息,他就发送一个探测报文,以后每隔75秒就发一次,连续发送10个探测报文后客户端仍然没有响应,服务器就认为客户端出现了故障,接着就关闭这个链接

4. 时间等待计时器
   * 当客户端进入TIME-WAIT/CLOSE-WAIT状态的时候,链接还没有释放掉,必须等待2倍的MSL(最长报文段寿命)后,客户端才能关闭连接.在时间等待期间,链接还处于一种过渡状态.这就可以使重复的FIN报文段(若果有的话)可以到达目的站因而可将其丢弃

## TCP流量控制和拥塞控制的实现?

* 流量控制:TCP采用大小可变的滑动窗口进行流量控制.**窗口大小的单位是字节**,在TCP报文段首部的窗口字段写入的数值就是当前给对方设置的发送窗口数值的上限,发送窗口在连接建立时由双方商定.但在通信的过程中,**接收端可根据自己的资源情况,随时动态地调整对方的发送窗口上限值**

* **拥塞控制**:**网络拥塞现象是指到达通信子网中某一部分的分组数量过多,使得该部分网络来不及处理,以致引起这部分乃至整个网络性能下降的现象**.严重时甚至会导致网络通信业务陷入停顿,即出现死锁现象.拥塞控制是处理网络拥塞现象的一种机制

  * 方法:有一个叫**慢启动门限** `ssthresh` (slow start threshold)状态变量,一般来说 `ssthresh` 的大小是 `65535` 字节

    * 慢开始( slow-start ):当 `cwnd` < `ssthresh` 时,使用慢启动算法,每当收到一个 ACK 时,指数级增长`cwnd`,如1,2,4,8...
    * 拥塞避免( congestion avoidance ):当 `cwnd` >= `ssthresh` 时,就会使用拥塞避免算法,线性增长`cwnd`,每当收到一个 ACK 时,`cwnd` 增加 `1/cwnd`.一直增长着,网络就会慢慢进入了拥塞的状况了,于是就会**出现丢包现象**,这时就需要对丢失的数据包进行重传.**当触发了重传机制,也就进入了'拥塞发生算法'**
    * 超时重传:`ssthresh` 设为 `cwnd/2` ,`cwnd` 重置为 1,**重新开始慢开始算法**
    * 快重传( fast retransmit ):当接收方发现丢了一个中间包的时候,**发送三次前一个包的 ACK**,于是**发送端就会快速地重传**,不必等待超时再重传.**TCP 认为这种情况不严重,因为大部分没丢**,只丢了一小部分,则 `ssthresh` 和 `cwnd` 变化如下:`cwnd` = `cwnd/2` ,也就是设置为原来的一半;`ssthresh` = `cwnd `;**进入快恢复算法**
    * 快恢复( fast recovery ):拥塞窗口 `cwnd` = `ssthresh` + 3( 3 的意思是确认有 3 个数据包被收到了)
      * 重传丢失的数据包
      * 如果再收到重复的 ACK,那么` cwnd` 增加 1
      * 如果收到新数据的 ACK 后,把 `cwnd `设置为第一步中的 `ssthresh `的值,原因是该 ACK 确认了新的数据,说明从 duplicated ACK 时的数据都已收到,该恢复过程已经结束,可以回到恢复之前的状态了,也即**再次进入拥塞避免状态**

    <img src="imgs/network/block_ctrl.png" alt="block_ctrl" style="zoom: 50%;" />

    <img src="imgs/network/fast_restransmit.png" alt="fast_restransmit" style="zoom:50%;" />

    <img src="imgs/network/flow_diag.png" alt="flow_diag" style="zoom:50%;" />

## TCP重传机制

* 滑动窗口机制,确立收发的边界,能让发送方知道**已经发送了多少/尚未确认的字节数/尚待发送的字节数**;**让接收方知道已经确认收到的字节数**
* 选择性重传,用于对传输出错的序列进行重传
* 重复确认和快速重传

## 三次握手过程

* 主动建立连接方A的TCP向主机B发出连接请求报文段,其首部中的`SYN`(同步)标志位应置为1,表示想与目标主机B进行通信,并发送一个同步序列号`x`进行同步,**表明在后面传送数据时的第一个数据字节的序号**是`x + 1`.`SYN`同步报文会指明客户端使用的端口以及TCP连接的初始序号,A进入`SYN_SENT`状态
* 接收连接方B的TCP收到连接请求报文段后,如同意则发回确认.在确认报中应将`ACK`位和`SYN`位置1,表示客户端的请求被接受.确认号应为`x + 1`,同时也为自己选择一个序号`y`,B进入`SYN_RCVD`状态
* 主动方A的TCP收到目标主机B的确认后要向目标主机B给出确认,其`ACK`置1,确认号为`y +1`,而自己的序号为`x + 1`,A进入`ESTABLISHED状态`,B收到报文后也进入`ESTABLISHED`状态

## 四次挥手过程

* 主动关闭主机A的应用进程先向其TCP发出连接释放请求,并且不再发送数据.TCP通知对方要释放从A到B这个方向的连接,将发往主机B的TCP报文段首部的终止比特`FIN`置1,**其序号x等于前面已传送过的数据的最后一个字节的序号加1**
* 被动关闭主机B的TCP收到释放连接通知后即发出确认,其序号为`y`,**确认号为`x + 1`**,同时通知高层应用进程,这样,从A到B的连接就释放了,**连接处于半关闭状态**.但**若主机B还有一些数据要发送主机A,则可以继续发送**.主机A只要正确收到数据,仍应向主机B发送确认
* **若主机B不再向主机A发送数据,其应用进程就通知TCP释放连接**.主机B发出的连接释放报文段必须**将终止位`FIN`和确认位`ACK`置1**,**并使其序号仍为`y`,但还必须重复上次已发送过的`ACK` = `x + 1`**
* **主机A必须对此发出确认,将`ACK`置1,`ACK `= `y + 1`,而自己的序号是`x + 1`**.这样才把从B到A的反方向的连接释放掉.主机A的TCP再向其应用进程报告,整个连接已经全部释放

## 为什么要三次握手?

* 三次握手的目的是**建立可靠的通信信道**,说到通讯,简单来说就是数据的发送与接收,而**三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的**
* **经典场景**:客户端发送了第一个请求连接并且没有丢失,只是因为在**网络结点中滞留的时间太长**了
  - 由于TCP的客户端迟迟没有收到确认报文,以为服务器没有收到,此时**重新向服务器发送这条报文**,此后客户端和服务器经过两次握手完成连接,传输数据,然后关闭连接
  - 此时此前滞留的那一次请求连接,网络通畅了到达服务器,**这个报文本该是失效的**,但是,**两次握手的机制将会让客户端和服务器再次建立连接,这将导致不必要的错误和资源的浪费**
  - **如果采用的是三次握手,就算是那一次失效的报文传送过来了,服务端接受到了那条失效报文并且回复了确认报文,但是客户端不会再次发出确认.由于服务器收不到确认,就知道客户端并没有请求连接**
* **避免资源浪费**
    * 如果客户端的 `SYN` 阻塞了,**重复发送多次** `SYN` 报文,那么服务器在**收到请求后就会建立多个冗余的无效链接,造成不必要的资源浪费**

## TCP三次握手中,最后一次回复丢失,会发生什么?

* 如果最后一次ACK在网络中丢失,那么**Server端(服务端)该TCP连接的状态仍为SYN_RECV**,并且**根据 TCP的超时重传机制依次等待3秒/6秒/12秒后重新发送 SYN+ACK 包**,以便 **Client(客户端)重新发送ACK包** 
* **如果重发指定次数后,仍然未收到ACK应答**,那么一段时间后,**Server(服务端)自动关闭这个连接** .**当失败时服务器并不会重传ACK报文,而是直接发送RTS报文段,进入CLOSED状态.这样做的目的是为了`防止SYN洪泛攻击`**
* **但是Client(客户端)认为这个连接已经建立**,如果Client(客户端])端向Server(服务端)发送数据,**Server端(服务端)将以RST包(Reset,标示复位,用于异常的关闭连接)响应**,此时,**客户端知道第三次握手失败**

## TCP的三次握手是否都可以携带数据

* 第一次和第二次是不可以携带数据的,但是第三次是可以携带数据的
* 假如第一次握手可以携带数据的话,那对于服务器是不是太危险了,有人如果恶意攻击服务器,每次都在第一次握手中的SYN报文中放入大量数据.而且频繁重复发SYN报文,**服务器会花费很多的时间和内存空间去接收这些报文**
* 第三次握手,**此时客户端已经处于ESTABLISHED状态**.**对于客户端来说,他已经建立起连接了,并且已经知道服务器的接收和发送能力是正常的.所以也就可以携带数据了**

## TCP是如何保证可靠传输的?

* **三次握手建立连接**(标志位):通信前确认通信实体存在,并且双方可以正确发送和接收对方的信息
* **序号机制**(序号/确认号):确保了数据是按序/完整到达
* **数据校验**(校验和):**CRC校验全部数据,保证数据完整性和正确性**
* **超时重传**(定时器):保证因链路故障未能到达数据能够被多次重发
* **窗口机制**(窗口):提供**流量控制**,避免过量发送
* **拥塞控制**:使用拥塞窗口机制,控制发送窗口大小,减少网络拥塞,避免因网络拥塞导致频繁丢包

## 为什么TCP挥手每两次中间有一个 FIN-WAIT2等待时间?

* 主动关闭的一端调用完close以后(即发FIN给被动关闭的一端, 并且收到其对FIN的确认ACK)则进入FIN_WAIT_2状态.**如果这个时候因为网络突然断掉/被动关闭的一段宕机等原因,导致主动关闭的一端不能收到被动关闭的一端发来的FIN(防止对端不发送关闭连接的FIN包给本端)**,这个时候就需要FIN_WAIT_2定时器, **如果在该定时器超时的时候,还是没收到被动关闭一端发来的FIN,那么直接释放这个链接,进入CLOSE状态**

## TIME-WAIT

* 为什么还有个TIME-WAIT的时间等待?
  * **保证客户端发送的最后一个ACK报文能够到达服务器**,因为这个ACK报文可能丢失,服务器已经发送了FIN+ACK报文,请求断开,客户端却没有回应,于是服务器又会重新发送一次,而客户端就能在这个2MSL时间段内收到这个重传的报文,接着给出回应报文,并且会重启2MSL计时器
  * 防止类似与"三次握手"中提到了的"已经失效的连接请求报文段"出现在本连接中.客户端发送完最后一个确认报文后,在这个2MSL时间中,就可以**使本连接持续的时间内所产生的所有报文段(被动关闭方延时到来的FIN报文)都从网络中消失(指的是在路由器的缓存失效),这样新的连接中不会出现旧连接的请求报文**
  * 2MSL,**最大报文生存时间**,linux中,一个MSL 30 秒,2MSL = 60s

* TIME-WAIT 状态过多会产生什么后果?怎样处理?
  * **在高并发短连接的TCP服务器上,当服务器处理完请求后主动请求关闭连接**,这样服务器上会有大量的连接处于TIME_WAIT状态,**服务器维护每一个连接需要一个socket,也就是每个连接会占用一个文件描述符,而文件描述符的使用是有上限的,如果持续高并发,会导致一些连接失败**
  * 作为服务器,短时间内关闭了大量的Client连接,就会造成服务器上出现大量的TIME_WAIT连接,**占据大量的fd,严重消耗着服务器的资源**,此时部分客户端就会显示连接不上
  * 作为客户端,短时间内大量的短连接,会大量消耗的Client机器的端口,毕竟端口只有65535个,端口被耗尽了,后续就无法在发起新的连接了 
  * **解决方法**:  
    * **用负载均衡来抗这些高并发的短请求** 
    * **可以通过修改`/etc/sysctl.conf`配置文件中`TIME_WAIT`时间来减少此情况**
    * 服务器可以设置 **SO_REUSEADDR 套接字选项来重用 TIME_WAIT状态端口**,TIME_WAIT 状态可以通过优化服务器参数得到解决,**因为发生TIME_WAIT的情况是服务器自己可控的,要么就是对方连接的异常,要么就是自己没有迅速回收资源,总之不是由于自己程序错误导致的** 
    * **利用SO_LINGER选项(设置 l_onoff为1,l_linger为0)的强制关闭方式,发送 RST 包越过TIMEWAIT状态,直接进入CLOSED状态**
    * 修改内核参数
      * 修改`/etc/sysctl.conf`,`net.ipv4.tcp_max_tw_buckets`对应的是**系统同时保持的TIME_WAIT的最大数量**,**超过此数量时,系统会立即清理出多余的TIME_WAIT连接**,系统日志中会出现TCP: time wait bucket table overflow的警告信息,最终该状态连接不会超出设置的值
      * `net.ipv4.tcp_max_tw_buckets`可设置的最大值为`262144` (硬件限制)这种方法虽然可以很快把TIME_WAIT状态数量降低至设定值以下,使用短连接连接方式的高并发状态下,TIME_WAIT产生速度非常快,当TIME_WAIT连接数达到设置值之后系统会以其产生速度相同的速度去销毁正常的TIME_WAIT连接,这时就可能出现前面说过的跳过TIME_WAIT连接状态可能会出现的结果,部分连接异常或者新的连接建立失败
      * `net.ipv4.tcp_max_tw_buckets`的值应该依据官方建议,不宜设置过小
    * 启用快速回收
      * 快速回收机制是系统对tcp连接通过一种方式进行快速回收的机制,对应内核参数中的`net.ipv4.tcp_tw_recycle`
      * **当timestamp和tw_recycle两个选项同时开启的情况下,开启per-host的PAWS机制.从而能快速回收处于TIME-WAIT状态的TCP流**
    * 开启重用机制
      * 开启重用用机制`net.ipv4.tcp_tw_reuse`,**允许将TIME-WAIT sockets重新用于新的TCP连接**,默认为0,表示关闭

      * **要开启重用机制需要依赖tcp_timestamps的功能,重用TIME_WAIT的条件是收到最后一个包后超过1s**
      * 优点:**配合tcp_timestamps可以在协议上安全的前提下对TIME_WAIT连接用于新的TCP连接,1s相比默认的60s时间还是极大的缩短了**

      * 缺点:**该机制只对"客户端"有效,即主动发起连接的一方**.比如一台web服务器,客户端发来请求时,web服务器时服务端,但web服务器又需要去连接后台数据库,这时候,web服务器又同时作为了客户端,只有主动发起连接一方主动断开所产生的TIME_WAIT该参数才生效

## CLOSE-WAIT状态过多原因后果及解决办法?

* 原因及后果:close_wait状态出现的原因是**被动关闭方未关闭socket造成**,可能会产生"Too many open files"的fd用尽错误
* 解决办法:
  * 设置定时器关闭超时无响应的socket连接,`read/recv`返回0,或者客户端连接socket发生`EPOLLRDHUP`事件时,关闭socket
  * 修改`/proc/sys/fs/file-max` 增大整个系统可以打开的文件数的限制
  * 修改`/etc/sysctl.conf`或`/proc/sys/net/ipv4/tcp_keepalive_time`,将keepalive的时间调小

## TCP收到RST包的几种情况

* **访问不存在的端口**
  * **试图与不被监听的端口建立连接,则直接返回RST**,同时RST报文接收通告窗口大小为0
  * 客户端向服务器的某个端口发起连接,如果端口被**处于TIME_WAIT 状态的连接占用时**,客户端也会收到RST
* **异常终止连接**
  * 一方直接发送RST报文,表示异常终止连接.**一旦发送方发送复位报文段,发送端所有排队等待发送的数据都被丢弃**.应用程序可以通过socket选项`SO_LINGER`(设置 `l_onoff`为1,`l_linger`为0)来发送RST复位报文
* **处理半打开连接**(**如果一方已经关闭或异常终止连接而另一方却还不知道,我们将这样的 TCP 连接称为半打开**(Half-Open))
    * 如A与B通信,**A关闭了连接,B却没有收到结束报文**(如网络故障),此时**B还维持着原来的连接**.而A即使重启,也没有该连接的任何信息.**这种状态就叫做半打开连接**.而此时**B往处于半打开状态的连接写数据,则对方回应RST复位报文**

## 心跳包机制

* 心跳包之所以叫心跳包是因为:它**像心跳一样每隔固定时间发一次,以此来告诉服务器,这个客户端还活着**.事实上这是为了保持长连接,至于这个包的内容,是没有什么特别规定的,不过一般都是很小的包,或者只包含包头的一个空包.也有的心跳包中会携带一些需要定期更新的信息
* 在TCP的机制里面,**本身是存在有心跳包的机制的**,也就是TCP的选项:SO_KEEPALIVE.**系统默认是设置的2小时的心跳频率**.但是它**检查不到机器断电/网线拔出/防火墙这些断线**.而且逻辑层处理断线可能也不是那么好处理,而且这个**时间间隔默认太长**.另外,**SO_KEEPALIVE一旦设置会对系统所有的socket产生影响,可能会浪费大量流量**
* **心跳包一般来说都是在逻辑层发送空的echo包来实现的**.*下一个定时器,在一定时间间隔下发送一个空包给客户端,然后客户端反馈一个同样的空包回来,服务器如果在一定时间内收不到客户端发送过来的反馈包,那就只有认定说掉线了*
* 其实,要判定掉线,**只需要send或者recv一下,如果结果为零,则为掉线**.但是,**在长连接下,有可能很长一段时间都没有数据往来**.理论上说,这个连接是一直保持连接的,但是实际情况中,如果中间节点出现什么故障是难以知道的.**更要命的是,有的节点(防火墙)会自动把一定时间之内没有数据交互的连接给断掉**.在这个时候,就需要我们的心跳包了,**用于维持长连接,保活**
* 心跳包实现思路
  * 客户端连接上服务端以后,服务端维护一个**在线用户字典**,**客户端每隔一段时间,向服务器发送一个心跳包,服务器接收到包以后,字典数据的值都会更新为0**;**一旦服务端超过规定时间没有接收到客户端发来的包,字典数据将会递增加一,当字典数据的值累计大于等于三,则视为掉线**

## TCP keep-alive和http keep-alive的区别

* **http Keep-Alive模式**:
  * Http协议采用"请求-应答"模式,当使用普通模式,即非Keep-Alive模式时,每个请求/应答,客户端和服务器都要新建一个连接,完成之后立即断开连接;当使用Keep-Alive模式时,Keep-Alive功能使客户端到服务器端的连接持续有效,当出现对服务器的后继请求时,Keep-Alive功能避免了建立或者重新建立连接
    
  * http1.0中默认是关闭的,需要在http头加入"Connection: Keep-Alive",才能启用Keep-Alive
    
  * http 1.1中默认启用Keep-Alive,如果加入"Connection: close "才关闭.目前大部分浏览器都是用http1.1协议,也就是说默认都会发起Keep-Alive的连接请求了,所以是否能完成一个完整的Keep- Alive连接就看服务器设置情况
    
  * 优点:Keep-Alive模式更加高效,因为避免了连接建立和释放的开销
    
  * 缺点:长时间的Tcp连接容易导致系统资源无效占用,浪费系统资源

  * Keep-Alive timeout
      * Httpd守护进程,一般都提供了keep-alive timeout时间设置参数.比如nginx的keepalive_timeout,和Apache的KeepAliveTimeout.这个keepalive_timout时间值意味着:**一个http产生的tcp连接在传送完最后一个响应后,还需要hold住keepalive_timeout秒后,才开始关闭这个连接**
      * 当httpd守护进程发送完一个响应后,理应马上主动关闭相应的tcp连接,设置 keepalive_timeout后,httpd守护进程会想说:"再等等吧,看看浏览器还有没有请求过来",这一等,便是keepalive_timeout时间.**如果守护进程在这个等待的时间里,一直没有收到浏览器发过来http请求,则关闭这个http连接**
  
* **Tcp的Keep-alive**
  * 连接建立之后,如果客户端一直不发送数据,或者隔很长时间才发送一次数据,当连接很久没有数据报文传输时如何去确定对方还在线,到底是掉线了还是确实没有数据传输,连接还需不需要保持,这种情况在TCP协议设计中是需要考虑到的
  * TCP协议通过一种巧妙的方式去解决这个问题,**当超过一段时间之后,TCP自动发送一个数据为空的报文(侦测包)给对方,如果对方回应了这个报文,说明对方还在线,连接可以继续保持,如果对方没有报文返回,并且重试了多次之后则认为链接丢失,没有必要保持连接**
  * tcp keep-alive是TCP的一种检测TCP连接状况的保鲜机制.tcp keep-alive保鲜定时器,支持三个系统内核配置参数:
    * net.ipv4.tcp_keepalive_intvl = 15
    * net.ipv4.tcp_keepalive_probes = 5
    * net.ipv4.tcp_keepalive_time = 7200
  * keepalive是TCP保鲜定时器,当网络两端建立了TCP连接之后,闲置(双方没有任何数据流发送往来)了tcp_keepalive_time后,服务器就会尝试向客户端发送侦测包,来判断TCP连接状况(有可能客户端崩溃/强制关闭了应用/主机不可达等等)
  * 如果没有收到对方的回答(ack包),则会在tcp_keepalive_intvl后再次尝试发送侦测包,直到收到对方的ack,如果一直没有收到对方的ack,一共会尝试 tcp_keepalive_probes次,每次的间隔时间在这里分别是15s, 30s, 45s, 60s, 75s.如果尝试tcp_keepalive_probes,依然没有收到对方的ack包,则会丢弃该TCP连接.**TCP连接默认闲置时间是2小时,一般设置为30分钟足够了**

## 当保持长连接时,如何判断一次请求已经完成?

* Content-Length:表示实体内容的长度.浏览器通过这个字段来判断当前请求的数据是否已经全部接收.所以,当浏览器请求的是一个静态资源时,即服务器能明确知道返回内容的长度时,可以设置Content-Length来控制请求的结束.**但当服务器并不知道请求结果的长度时,如一个动态的页面或者数据,Content-Length就无法解决上面的问题,这个时候就需要用到Transfer-Encoding字段**
* Transfer-Encoding:**指传输编码**,在上面的问题中,当服务端无法知道实体内容的长度时,就可以通过指定Transfer-Encoding: chunked来告知浏览器当前的编码是将数据分成一块一块传递的.当然, 还可以指定`Transfer-Encoding: gzip, chunked`表明实体内容不仅是gzip压缩的,还是分块传递的.最后,**当浏览器接收到一个长度为0的chunked时**, 知道当前请求内容已全部接收

## [**TCP性能调优**](https://zhuanlan.zhihu.com/p/170582219?utm_source=wechat_session)

## 粘包

* 什么是粘包现象?

  * 粘包是TCP特有现象,UDP是不存在粘包一说.TCP是面向字节流传输的,发送方引起的粘包是由TCP协议本身造成的,TCP为提高传输效率,发送方往往要收集到足够多的数据后才发送一个TCP段.若连续几次需要send的数据都很少,通常TCP会根据块的合并优化算法(Nagle)把这些数据合成一个TCP段后一次发送出去,这样接收方就收到了粘包数据.对于ssh等需要实时通信的应用,可以设置SO_NODELAY,使小包也能马上发出
  * UDP是无连接的,面向消息的,提供高效率服务.不会使用块的合并优化算法, 由于UDP支持的是一对多的模式,所以接收端的**skbuff**(套接字缓冲区)采用了链式结构来记录每一个到达的UDP包,在每个UDP包中就有了消息头(消息来源地址,端口等信息),这样,对于接收端来说,就容易进行区分处理了. **即面向消息的通信是有消息保护边界的**
* 粘包发生场景
  * 第一种:发送端需要**等缓冲区满才发送出去**,造成粘包(发送数据时间间隔很短,**数据了很小,会合到一起,产生粘包**)
  * 第二种:接收方**不及时接收缓冲区的包**,造成多个包接收(客户端发送了一段数据,服务端只收了一小部分,服务端下次再收的时候还是从缓冲区拿上次遗留的数据,产生粘包)
* 粘包解决方法
  * 粘包问题的根源在于,**接收端不知道发送端将要传送的字节流的长度**,所以解决粘包的方法就是围绕,**如何让发送端在发送数据前,把自己将要发送的字节流总大小让接收端知晓,然后接收端来一个死循环接收完所有数据**
  * 设计一个报头模块(可以是struct结构体),该模块的作用就是记录要发送的真实数据的详细信息(如数据长度等)
  * 发送时,先发报头长度,再编码报头内容然后发送,最后发真实数据内容
  * 接收时,先收报头长度,根据取出的长度收取报头内容,然后解码,从解码的结果中取出待取数据的详细信息,然后去取真实的数据内容
  * https://www.zhihu.com/question/20210025/answer/1982654161

## SYN洪泛攻击(SYN Flood,半开放攻击),怎么解决?

* SYN Flood利用TCP协议缺陷,**发送大量伪造的TCP连接请求,常用假冒的IP或IP号段发来海量的请求连接的第一个握手包(SYN包)**,被攻击服务器回应第二个握手包(SYN+ACK包),**因为对方是假冒IP,对方永远收不到包且不会回应第三个握手包**.**导致被攻击服务器保持大量SYN_RECV状态的"半连接"**,并且会**重试默认5次**回应第二个握手包,**大量随机的恶意syn占满了未完成连接队列,导致正常合法的syn排不上队列,让正常的业务请求连接不进来**(服务器端的资源分配是在二次握手时分配的,而客户端的资源是在完成三次握手时分配的,所以服务器容易受到SYN洪泛攻击)
* 检测:检测 SYN 攻击非常的方便,**当你在服务器上看到大量的半连接状态时,特别是源IP地址是随机的,基本上可以断定这是一次SYN攻击**(在 Linux/Unix 上可以使用系统自带的 netstat 命令来检测 SYN 攻击)
* 解决:
  * 缩短超时(SYN Timeout)时间,减少重传次数
  * 增加最大半连接数(扩大syn队列)
  * 过滤网关防护
  * **SYN cookies技术**:
    * **当服务器接受到 SYN 报文段时,不直接为该 TCP 分配资源**,而只是打开一个半开的套接字.接着会使用 SYN 报文段的源 Id,目的 Id,端口号以及只有服务器自己知道的一个秘密函数**生成一个 cookie,并把 cookie 作为序列号响应给客户端**
    * **如果客户端是正常建立连接,将会返回一个确认字段为 cookie + 1 的报文段**.接下来服务器会根据确认报文的源 Id,目的 Id,端口号以及秘密函数计算出一个结果,**如果结果的值 + 1 等于确认字段的值,则证明是刚刚请求连接的客户端,这时候才为该 TCP 分配资源**
  * 负载均衡,cdn,反向代理服务器

## TCP和UDP是否可以绑定同一端口进行通信?

* 网络中可以被命名和寻址的通信端口,是操作系统可分配的一种资源
* 按照OSI七层协议的描述,传输层与网络层在功能上的最大区别是传输层提供进程通信能力.从这个意义上讲,网络通信的最终地址就不仅仅是主机地址了,还包括可以描述进程的某种标识符.为此,TCP/IP协议提出了协议端口(protocol  port,简称端口)的概念,用于标识通信的进程
* **端口是一种抽象的软件结构(包括一些数据结构和I/O缓冲区)**.应用程序(即进程)通过系统调用与某端口建立连接(binding)后,传输层传给该端口的数据都被相应进程所接收,相应进程发给传输层的数据都通过该端口输出.**在TCP/IP协议的实现中,端口操作类似于一般的I/O操作,进程获取一个端口,相当于获取本地唯一的I/O文件,可以用一般的读写原语访问之**
* **类似于文件描述符,每个端口都拥有一个叫端口号(port  number)的整数型标识符,用于区别不同端口**.**由于TCP/IP传输层的两个协议TCP和UDP是完全独立的两个软件模块,因此各自的端口号也相互独立,如TCP有一个255号端口,UDP也可以有一个255号端口,二者并不冲突**
* 端口号的分配是一个重要问题.**有两种基本分配方式**:
  * 第一种叫全局分配,这是一种集中控制方式,由一个公认的中央机构根据用户需要进行统一分配,并将结果公布于众
  * 第二种是本地分配,又称动态连接,即进程需要访问传输层服务时,向本地操作系统提出申请,操作系统返回一个本地唯一的端口号,进程再通过合适的系统调用将自己与该端口号联系起来(绑扎)
* TCP/IP端口号的分配中综合了上述两种方式.TCP/IP将端口号分为两部分,少量的作为保留端口,以全局方式分配给服务进程.因此,每一个标准服务器都拥有一个全局公认的端口(即周知口,well-known  port),即使在不同机器上,其端口号也相同.剩余的为自由端口,以本地方式进行分配.TCP和UDP均规定,小于256的端口号才能作保留端口

## TCP和UDP的区别及适用场景

* 区别
  * **是否面向连接**
    * TCP是面向连接的,即发送数据前需要与目标主机建立连接
    * UDP面向无连接的,发送数据前不需要建立连接
  * 服务对象
    * TCP 是**一对一**的两点服务,即一条连接只有两个端点
    * UDP 支持**一对一/一对多/多对多的交互通信**
  * 传输方式
    * TCP 是**流式传输**,没有边界,但保证顺序和可靠
    * UDP 是一个包一个包的发送,是**有边界的**,但可能会**丢包和乱序**
  * **是否提供可靠交付**
    * TCP在传输数据之前,需要三次握手来建立连接,并且通过**数据校验/拥塞控制/重传控制/滑动窗口和确认应答**等机制来**实现可靠交付**.数据传输过程中,数据无丢失,无重复,无乱序
    * UDP**不提供可靠交付**,只有通过检验和去丢弃那些不完整的报文,尽最大努力来保证交付的可靠性
  * **分片不同**
    * TCP 的数据大小如果大于 MSS 大小,则会**在传输层进行分片**,目标主机收到后,也同样**在传输层组装 TCP 数据包**,如果中途丢失了一个分片,只需要传输丢失的这个分片
    * UDP 的数据大小如果大于 MTU 大小,则会**在 IP 层进行分片**,目标主机收到后,在 **IP 层组装完数据,接着再传给传输层**,但是**如果中途丢了一个分片,则就需要重传所有的数据包,这样传输效率非常差,所以通常 UDP 的报文应该小于 MTU**
  * 首部开销
    * TCP 首部长度较长,会有一定的开销,**首部在没有使用'选项'字段时是 20 个字节**,如果使用了'选项'字段则会变长的
    * UDP 首部只有 **8 个字节**,并且是**固定不变**的,开销较小
  * **工作效率**
    * 前面提到TCP传输数据的控制非常多,这也导致了TCP网络开销大,工作效率相对低下,对系统的资源要求也比较高
    * UDP传输控制简单,因此工作效率相对高,对系统资源的要求偏低
  * **实时性**
    * TCP传输数据的控制程序较多,大幅度降低了数据传输的实时性
    * UDP协议简单,数据实时性较高
  * **安全性**
    * TCP传输机制多,容易被利用,例如DOS/DDOS攻击,因此在安全性上,不如UDP
    * UDP没有TCP这么多机制,被利用的机会就会少很多,但UDP不是绝对安全,也会被攻击
* 适用场景
  * TCP
    * **对数据传输的质量有较高要求,但对实时性要求不高**.比如HTTP,HTTPS,FTP等传输文件的协议以及POP,SMTP等邮件传输的协议,应选用TCP协议
  * UDP
    * **只对数据传输的实时性要求较高,但不对传输质量有要求**.比如**视频传输/实时通信**等,应选用UDP协议

# UDP



#　IP

* IP协议在MAC帧中的协议号为`0x0800`

* IP首部

  <img src="imgs/network/IP.png" alt="IP" style="zoom: 50%;" />

* **什么是IP分片**

  * IP协议在传输数据包时会将数据报文分成若干片进行传输,并在目标系统中进行重组.这以过程就成为分片

* **为什么要进行IP分片**

  * 如果IP数据报加上数据帧头部后大于MTU,数据报文就会分成若干片进行传输.那么什么是MTU呢?每一种物理网络都会规定链路层数据帧的最大长度,称为链路层MTU.**在以太网的环境中可传输的最大IP报文为1500字节**.如果要传输的数据帧的大小超过1500字节,即IP数据报的长度大于1472(1500-20-8=1472,UDP)字节,需要分片之后进行传输

* IP分片如何组装

  * 在IP头里面有16bit的**识别号唯一记录了一个IP包的ID**,以确定这几个分片是否属于同一个包,具有同一个ID的IP分片将会从新组装.**13bit的片偏移记录了一个IP分片相对于整个包的位置**.**3bit的标志位记录了该分片后面是否还有新的分片**.这三个分片组成了IP分片的所有的信息

# ICMP

* ICMP 全称是 Internet Control Message Protocol,也就是互联网控制报文协议,**其协议号为**`1`

* ICMP 主要的功能包括:

  * **确认 IP 包是否成功送达目标地址**
  * **报告发送过程中 IP 包被废弃的原因**和**改善网络设置**等

* 在 IP 通信中如果某个 IP 包因为某种原因未能达到目标地址,那么这个具体的原因将由 ICMP 负责通知

* ICMP 大致可以分为两大类:

  * 一类是**用于诊断**的查询消息,也就是'**查询报文类型**'
  * 另一类是**通知出错原因**的错误消息,也就是'**差错报文类型**'

  <img src="imgs/network/icmp.png" alt="icmp" style="zoom:50%;" />

* 查询报文类型

  * 回送消息 __ 类型 `0` 和` 8`

  * 回送消息用于进行通信的主机或路由器之间,**判断所发送的数据包是否已经成功到达对端的一种消息**,` ping` 命令就是利用这个消息实现的

  * 可以向对端主机**发送回送请求的消息**( `ICMP Echo Request Message` ,类型` 8 `),也可以接收对端主机发回来的回送应答消息( `ICMP Echo Reply Message` ,类型` 0` )

    <img src="imgs/network/icmp_echo_reply.png" alt="icmp_echo_reply" style="zoom:67%;" />

* 差错报文类型

  * 目标不可达消息 __ 类型 为` 3`

    * IP 路由器无法将 IP 数据包发送给目标地址时,会给发送端主机返回一个目标不可达的 ICMP 消息,并在这个消息中显示不可达的具体原因,原因记录在 ICMP 包头的代码字段.由此,根据 ICMP 不可达的具体消息,发送端主机也就可以了解此次发送不可达的具体原因

    * 举例 6 种常见的目标不可达类型的代码:

      <img src="imgs/network/icmp_unreachable.png" alt="icmp_unreachable" style="zoom:50%;" />

    * 网络不可达

      * IP 地址是分为网络号和主机号的,所以当路由器中的路由器表匹配不到接收方 IP 的网络号,就通过ICMP 协议以网络不可达( `Network Unreachable `)的原因告知主机

    * 主机不可达

      * 当路由表中没有该主机的信息,或者该主机没有连接到网络,那么会通过 ICMP 协议以主机不可达( `Host Unreachable `)的原因告知主机

    * 协议不可达

      * 当主机使用 TCP 协议访问对端主机时,能找到对端的主机了,可是**对端主机的防火墙已经禁止 TCP 协议访问**,那么会通过 ICMP 协议以协议不可达的原因告知主机

    * 需要进行分片但设置了不分片位

      * 发送端主机发送 IP 数据报时,**将 IP 首部的分片禁止标志位设置为1** .**根据这个标志位,途中的路由器遇到超过 MTU 大小的数据包时,不会进行分片,而是直接抛弃**

    * 端口不可达

      * 当主机访问对端主机 8080 端口时,这次能找到对端主机了,防火墙也没有限制,可是发现**对端主机没有进程监听 8080 端口**,那么会通过 ICMP 协议以端口不可达的原因告知主机

  * 原点抑制消息 __ 类型 `4`

    * 在使用低速广域线路的情况下,**连接 WAN 的路由器可能会遇到网络拥堵的问题**,`ICMP` 原点抑制消息的目的就是为了缓和这种拥堵情况
    * 当路由器向低速线路发送数据时,其发送队列的缓存变为零而无法发送出去时,可以向 IP 包的源地址发送一个 ICMP 原点抑制消息
    * 收到这个消息的主机借此了解在整个线路的某一处发生了拥堵的情况,从而**增大 IP 包的传输间隔,减少网络拥堵的情况**
    * 然而,**由于这种 ICMP 可能会引起不公平的网络通信,一般不被使用**

  * 重定向消息 __ 类型 `5`

    * 如果**路由器发现发送端主机使用了'不是最优'的路径发送数据,那么它会返回一个 ICMP 重定向消息给这个主机**
    * 在这个消息中包含了**最合适的路由信息和源数据**.这主要发生在路由器持有更好的路由信息的情况下
    * **路由器会通过这样的 ICMP 消息告知发送端,让它下次发给另外一个路由器**

  * 超时消息 __ 类型 `11`

    * IP 包中有一个字段叫做 `TTL` ( `Time To Live `,生存周期),它的值随着**每经过一次路由器就会减1,直到减到 0 时该 IP 包会被丢弃**
    * 此时,**路由器将会发送一个 ICMP 超时消息给发送端主机,并通知该包已被丢弃**
    * 设置 IP 包生存周期的主要目的,是为了在**路由控制遇到问题发生循环状况时,避免 IP 包无休止地在网络上被转发**

# ping

# traceroute

# ARP

## ARP欺骗

* **ARP欺骗**(英语:**ARP spoofing**),又称**ARP毒化**(**ARP poisoning**,网络上多译为**ARP病毒**)或**ARP攻击**,是针对以太网地址解析协议(ARP)的一种攻击技术.此种攻击可让攻击者获取局域网上的数据包甚至可篡改数据包,且可让网络上特定计算机或所有计算机无法正常连线
* 运作机制
  * ARP欺骗的运作原理是由攻击者发送假的ARP数据包到网上,尤其是送到网关上.其目的是要让送至特定的IP地址的流量被错误送到攻击者所取代的地方.因此攻击者可将这些流量另行转送到真正的网关(被动式数据包嗅探,passive sniffing)或是篡改后再转送([中间人攻击](https://baike.baidu.com/item/中间人攻击/1739730),man-in-the-middle attack).攻击者亦可将ARP数据包导到不存在的MAC地址以达到阻断服务攻击的效果,例如netcut软件
  * 例如某一的IP地址是192.168.0.254,其MAC地址为00-11-22-33-44-55,网络上的计算机内ARP表会有这一笔ARP记录.攻击者发动攻击时,会大量发出已将192.168.0.254的MAC地址篡改为00-55-44-33-22-11的ARP数据包.那么网络上的计算机若将此伪造的ARP写入自身的ARP表后,计算机若要透过网上网关连到其他计算机时,数据包将被导到00-55-44-33-22-11这个MAC地址,因此攻击者可从此MAC地址截收到数据包,可篡改后再送回真正的网关,或是什么也不做,让网上无法连线.
* **简单案例分析**:这里用一个最简单的案例来说明ARP欺骗的核心步骤.假设在一个LAN里,只有三台主机A/B/C,且C是攻击者
  1. 攻击者聆听局域网上的MAC地址.它只要收到两台主机洪泛的ARP Request,就可以进行欺骗活动.
  2. 主机A/B都洪泛了ARP Request.攻击者现在有了两台主机的IP/MAC地址,开始攻击.
  3. 攻击者发送一个ARP Reply给主机B,把此包protocol header里的sender IP设为A的IP地址,sender mac设为攻击者自己的MAC地址.
  4. 主机B收到ARP Reply后,更新它的ARP表,把主机A的MAC地址(IP_A, MAC_A)改为(IP_A, MAC_C).
  5. 当主机B要发送数据包给主机A时,它根据ARP表来封装数据包的Link报头,把目的MAC地址设为MAC_C,而非MAC_A.
  6. 当交换机收到B发送给A的数据包时,根据此包的目的MAC地址(MAC_C)而把数据包转发给攻击者C.
  7. 攻击者收到数据包后,可以把它存起来后再发送给A,达到偷听效果.攻击者也可以篡改数据后才发送数据包给A,造成伤害
* 防制方法
  * 最理想的防制方法是网上内的每台计算机的ARP一律改用静态的方式,不过这在大型的网上是不可行的,因为需要经常更新每台计算机的ARP表
  * 另外一种方法,例如[DHCP snooping](https://baike.baidu.com/item/DHCP snooping),网上设备可借由[DHCP](https://baike.baidu.com/item/DHCP)保留网络上各计算机的MAC地址,在伪造的ARP数据包发出时即可侦测到.此方式已在一些厂牌的网上设备产品所支持
  * 有一些软件可监听网络上的ARP回应,若侦测出有不正常变动时可发送邮箱通知管理者.例如UNIX平台的[Arpwatch](https://baike.baidu.com/item/Arpwatch)以及Windows上的XArp v2或一些网上设备的Dynamic ARP inspection功能

# DNS

* **DNS占用53号端口,同时使用TCP和UDP协议**.那么DNS在什么情况下使用这两种协议?
  * 在两种情况下会使用 TCP 进行传输:
    - 如果返回的响应超过的 512 字节(UDP 最大只支持 512 字节的数据)
    - 区域传送(区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据)
  * 其他时候使用UDP协议.大多数情况下 DNS 使用 UDP 进行传输,这就**要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性**
* **DNS区域传输的时候使用TCP协议**
  * 辅域名服务器会定时(一般3小时)向主域名服务器进行查询以便了解数据是否有变动.如有变动,会执行一次区域传送,进行数据同步.**区域传送使用TCP而不是UDP,因为数据同步传送的数据量比一个请求应答的数据量要多得多**
  * TCP是一种可靠连接,保证了数据的准确性
* **域名解析时使用UDP协议:**
  * 客户端向DNS服务器查询域名,一般返回的内容都不超过512字节,用UDP传输即可.**不用经过三次握手,这样DNS服务器负载更低,响应更快**.理论上说,客户端也可以指定向DNS服务器查询时用TCP,但事实上,很多DNS服务器进行配置的时候,仅支持UDP查询包

* **DNS劫持**
  * 域名劫持是互联网攻击的一种方式,通过**攻击域名解析服务器**,或**伪造域名解析服务器**的方法,**把目标网站域名解析到错误的IP地址**从而实现用户无法访问目标网站的目的或者蓄意或恶意要求用户访问指定IP地址(网站)的目的
  * 常见三种情况
    * **错误域名解析到纠错导航页面**,导航页面存在广告.判断方法:访问的域名是错误的,而且跳转的导航页面也是官方的,如电信的114,联通移网域名纠错导航页面
    * **错误域名解析到非正常页面**,对错误的域名解析到导航页的基础上,有一定几率解析到一些恶意站点,这些恶意站点通过判断你访问的目标HOST/URI/ referrer等来确定是否跳转广告页面,这种情况就有可能导致跳转广告页面(域名输错)或者访问页面被加广告(页面加载时有些元素的域名错误而触发)这种劫持会对用户访问的目标HOST/URI/ referrer等会进行判定来确定是否解析恶意站点地址,不易被发现
    * **直接将特点站点解析到恶意或者广告页面**,这种情况比较恶劣,而且出现这种情况未必就是运营商所为,家里路由器被黑,或者系统被入侵,甚至运营商的某些节点被第三方恶意控制都有可能

# NAT

## NAT穿透/UDP打洞

# [HTTP/HTTPS](https://www.nowcoder.com/discuss/613239?type=2&channel=-1&source_id=discuss_terminal_discuss_hot_nctrack)

## 什么是HTTP

* **TPC/IP协议是传输层协议**,主要解决**数据如何在网络中传输**,而**HTTP是应用层协议**,主要解决**如何包装数据**
* HTTP 是一种 超文本传输协议(Hypertext Transfer Protocol)

## Http 协议的内容

* HTTP报文大致分为报文首部 + 报文主体**,**首部和报文主体由CRLF(一行空格)来区分
* HTTP报文有**请求报文**和**响应报文**两种,HTTP的这两种报文都由三部分组成:开始行/首部行/实体主体
  - **开始行可用于区分两种报文** 
  - **首部行**都是由**首部字段名 和 值**组成,每个首部行在结束地方都有 CRLF 
  - 首部行和实体主体间有 CRLF 
* **HTTP请求**由三部分组成,分别是:**请求行/消息报头/请求正文**
* **HTTP响应**也是由三个部分组成,分别是:**状态行/消息报头/响应正文**
* **Request Body 请求体**:**根据应用场景的不同,HTTP请求的请求体有三种不同的形式**.
  * 请求体是任意类型的,服务器不会解析请求体,请求体的处理需要自己解析**,如 POST JSON 的时候就是这类.例如:**application/json,text/xml
  * 表单提交**:这里的格式要求就是 URL 中 Query String 的格式要求:多个键值对之间用&连接,键与值之间用=连接.**表单的请求头中 `Content-type `默认"application/x-www-form-urlencoded " 对表单数据进行编码,数据以键值对在http请求体重发送给服务器;如果enctype 属性为"multipart/form-data",则以消息的形式发送给服务器
  * 文件分割**:第三种请求体被分成多个部分,**文件上传时会被使用,这种格式最先是被用于邮件传输中,每个字段/文件都被 boundary(Content-Type中指定的)分成单独的段,每段以--加 boundary 开头,然后是该段的描述头,描述头之后空一行接内容,请求结束的标识为 boundary 后面加--;

## HTTP常见方法

<img src="imgs/network/http_method.png" alt="http_method" style="zoom:50%;" />

* GET

  * 获取资源:当前网络请求中,绝大部分使用的是 GET 方法

* HEAD

  * 获取报文首部:和 GET 方法类似,但是**不返回报文实体主体部分**,主要**用于确认 URL 的有效性以及资源更新的日期时间**等

* POST

  * 传输实体主体:POST 主要用来传输数据,而 GET 主要用来获取资源

* PUT

  * 上传文件:由于自身不带验证机制,任何人都可以上传文件,因此存在安全性问题,一般不使用该方法

    ```http
    PUT /new.html HTTP/1.1
    Host: example.com
    Content-type: text/html
    Content-length: 16
    
    <p>New File</p>
    ```

* PATCH

  * 对资源进行部分修改:**PUT 也可以用于修改资源,但是只能完全替代原始资源**,**PATCH 允许部分修改**

    ```http
    PATCH /file.txt HTTP/1.1
    Host: www.example.com
    Content-Type: application/example
    If-Match: "e0023aa4e"
    Content-Length: 100
    
    [description of changes]
    ```

* DELETE

  * 删除文件:与 PUT 功能相反,并且同样不带验证机制

* OPTIONS

  * 查询支持的方法:查询指定的 URL 能够支持的方法.会返回 `Allow: GET, POST, HEAD, OPTIONS` 这样的内容

* CONNECT

  * 要求在与代理服务器通信时建立隧道:使用 SSL(Secure Sockets Layer,安全套接层)和 TLS(Transport Layer Security,传输层安全)协议把通信内容加密后经网络隧道传输

    ```http
    CONNECT www.example.com:443 HTTP/1.1
    ```

    <img src="imgs/network/http_connect.png" alt="http_connect" style="zoom: 80%;" />

* TRACE

  * 追踪路径:服务器会将通信路径返回给客户端.发送请求时,在 Max-Forwards 首部字段中填入数值,每经过一个服务器就会减 1,当数值为 0 时就停止传输.通常不会使用 TRACE,并且它容易受到 XST 攻击(Cross-Site Tracing,跨站追踪)

## GET和POST区别

* GET 请求只能 URL 编码,而 POST 支持多种编码方式
* GET 请求只接受 ASCII 字符的参数,而 POST 则没有限制
* GET 请求的参数通过 URL 传送,而 POST 放在 Request Body 中
* GET 相对于 POST 更不安全,因为参数直接暴露在 URL 中
* GET 请求会被浏览器主动缓存,而 POST 不会(除非自己手动设置)
* GET 请求在 URL 传参有长度限制,而 POST 则没有限制
* GET 产生的 URL 地址可以被收藏,而 POST 不可以
* GET 请求的参数会被完整的保留在浏览器的历史记录里,而 POST 的参数则不会
* GET 在浏览器回退时是无害的,而 POST 会再次提交请求

## HTTP常见状态码

* 1XX 信息

  <img src="imgs/network/1xx.png" alt="1xx"  />
* 2XX 成功

  ![2xx](imgs/network/2xx.png)
* 3XX 重定向

  ![3xx](imgs/network/3xx.png)
* 4XX 客户端错误

  ![4xx](imgs/network/4xx.png)
* 5XX 服务器错误

  ![5xx](imgs/network/5xx.png)

## HTTP首部字段

* HTTP通用首部字段

  ![common_header](imgs/network/common_header.png)

* HTTP请求首部字段

  <img src="imgs/network/requst_header.png" alt="requst_header" style="zoom:80%;" />

  * **If-Modified-Since**

    HTTP 的 If-Modified-Since 使其成为`条件请求`:

    - 返回200,只有在给定日期的最后一次修改资源后,服务器才会以200状态发送回请求的资源.

    - 如果请求从开始以来没有被修改过,响应会返回304并且没有任何响应体

    - If-Modified-Since 通常会与 If-None-Match 搭配使用,If-Modified-Since 用于确认代理或客户端拥有的本地资源的有效性.获取资源的更新日期时间,可通过确认首部字段 `Last-Modified` 来确定

    - 大白话说就是如果在 `Last-Modified` 之后更新了服务器资源,那么服务器会响应200,如果在 `Last-Modified` 之后没有更新过资源,则返回 304

      ```
      If-Modified-Since: Mon, 18 Jul 2016 02:36:04 GMT
      ```

  * **If-None-Match**

    If-None-Match HTTP请求标头使请求成为条件请求.对于 GET 和 HEAD 方法,仅当服务器没有与给定资源匹配的 `ETag` 时,服务器才会以200状态发送回请求的资源.对于其他方法,仅当最终现有资源的`ETag`与列出的任何值都不匹配时,才会处理请求.

    ```
    If-None-Match: "c561c68d0ba92bbeb8b0fff2a9199f722e3a621a"
    ```

  * **Referer**

    HTTP Referer 属性是请求标头的一部分,当浏览器向 web 服务器发送请求的时候,一般会带上 Referer,告诉服务器该网页是从哪个页面链接过来的,服务器因此可以获得一些信息用于处理.

    ```
    Referer: https://developer.mozilla.org/testpage.html
    ```

* HTTP响应首部字段

  <img src="imgs/network/response_header.png" alt="response_header" style="zoom:80%;" />

  * **Access-Control-Allow-Origin**

    一个返回的 HTTP 标头可能会具有 Access-Control-Allow-Origin ,`Access-Control-Allow-Origin` 指定一个来源,它告诉浏览器允许该来源进行资源访问.否则-对于没有凭据的请求 `*`通配符,告诉浏览器允许任何源访问资源.例如,要允许源 `https://mozilla.org` 的代码访问资源,可以指定:

    ```
    Access-Control-Allow-Origin: https://mozilla.org
    Vary: Origin
    ```

    如果服务器指定单个来源而不是 `*`通配符的话 ,则服务器还应在 Vary 响应标头中包含 `Origin` ,以向客户端指示 服务器响应将根据原始请求标头的值而有所不同.

  * **Keep-Alive**

    上面我们提到,HTTP 报文标头会分为四种,这其实是按着`上下文`来分类的

    还有一种分类是根据`代理`进行分类,根据代理会分为`端到端头` 和 `逐跳标头`

    而 Keep-Alive 表示的是 Connection 非持续连接的存活时间,如下

    ```
    Connection: Keep-Alive
    Keep-Alive: timeout=5, max=997
    ```

    Keep-Alive 有两个参数,它们是以逗号分隔的参数列表,每个参数由一个标识符和一个由等号 = 分隔的值组成.

    `timeout`:指示空闲连接必须保持打开状态的最短时间(以秒为单位).

    `max`:指示在关闭连接之前可以在此连接上发送的最大请求数.

    上述 HTTP 代码的意思就是限制最大的超时时间是 5s 和 最大的连接请求是 997 个

  * **Transfer-Encoding**

    首部字段 Transfer-Encoding 规定了传输报文主体时采用的编码方式.

    ```
    Transfer-Encoding: chunked
    ```

    HTTP /1.1 的传输编码方式仅对分块传输编码有效

*  HTTP实体首部字段

  ![body_header](imgs/network/body_header.png)
  
* End-to-end 首部和 Hop-by-hop 首部

  HTTP 首部字段将定义成缓存代理和非缓存代理的行为,分成 2 种类型.

  一种是 `End-to-end` 首部 和 `Hop-by-hop` 首部

  * End-to-end(端到端) 首部
    * **这些标头必须发送给消息的最终接收者** : 请求的服务器,或响应的客户端.中间代理必须重新传输未经修改的标头,并且缓存必须存储这些信息

  * Hop-by-hop(逐跳) 首部
    * 分在此类别中的首部**只对单次转发有效**,会因通过缓存或代理而不再转发
    * 下面列举了 HTTP/1.1 中的逐跳首部字段.除这 8 个首部字段之外,其他所有字段都属于端到端首部
    * Connection/Keep-Alive/Proxy-Authenticate/Proxy-Authorization/Trailer/TE/Transfer-Encoding/Upgrade

## Cookie

* 概念

  * HTTP 协议是无状态的,主要是为了让 HTTP 协议尽可能简单,使得它能够处理大量事务.**HTTP/1.1 引入 Cookie 来保存状态信息**
  * **Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据**,**它会在浏览器之后向同一服务器再次发起请求时被携带上,用于告知服务端两个请求是否来自同一浏览器.由于之后每次请求都会需要携带 Cookie 数据,因此会带来额外的性能开销**(尤其是在移动环境下)
  * Cookie 曾一度用于客户端数据的存储,因为当时并没有其它合适的存储办法而作为唯一的存储手段,但现在随着现代浏览器开始支持各种各样的存储方式,**Cookie 渐渐被淘汰**.新的浏览器 API 已经允许开发者直接将数据存储到本地,如使用 Web storage API(本地存储和会话存储)或 IndexedDB

* 用途

  * 会话状态管理(如**用户登录状态/购物车/游戏分数或其它需要记录的信息**)
  * 个性化设置(如用户自定义设置/主题等)
  * 浏览器行为跟踪(如跟踪分析用户行为等)

* 创建过程

  * **服务器发送的响应报文包含 Set-Cookie 首部字段,客户端得到响应报文后把 Cookie 内容保存到浏览器中**

    ```http
    HTTP/1.0 200 OK
    Content-type: text/html
    Set-Cookie: yummy_cookie=choco
    Set-Cookie: tasty_cookie=strawberry
    
    [page content]
    ```

  * 客户端之后对同一个服务器发送请求时,会从浏览器中取出 Cookie 信息并通过 Cookie 请求首部字段发送给服务器

    ```http
    GET /sample_page.html HTTP/1.1
    Host: www.example.org
    Cookie: yummy_cookie=choco; tasty_cookie=strawberry
    ```

* 分类

  * **会话期 Cookie:浏览器关闭之后它会被自动删除,也就是说它仅在会话期内有效**

  * **持久性 Cookie:指定过期时间(Expires)或有效期(max-age)之后就成为了持久性的 Cookie**

    ```http
    Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT;
    ```

* Secure

  * 标记为 Secure 的 Cookie **只能通过被 HTTPS 协议加密过的请求**发送给服务端.**但即便设置了 Secure 标记,敏感信息也不应该通过 Cookie 传输,因为 Cookie 有其固有的不安全性,Secure 标记也无法提供确实的安全保障**

## Session

* 除了可以将用户信息通过 Cookie 存储在用户浏览器中,**也可以利用 Session 存储在服务器端,存储在服务器端的信息更加安全**
* Session 可以存储在服务器上的文件/数据库或者内存中.**也可以将 Session 存储在 Redis 这种内存型数据库中**,效率会更高
* 使用 Session **维护用户登录状态**的过程如下
  * 用户进行登录时,**用户提交包含用户名和密码的表单,放入 HTTP 请求报文中**
  * **服务器验证该用户名和密码,如果正确则把用户信息存储到 Redis 中,它在 Redis 中的 Key 称为 Session ID**
  * **服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID,客户端收到响应报文之后将该 Cookie 值存入浏览器中**
  * **客户端之后对同一个服务器进行请求时会包含该 Cookie 值,服务器收到之后提取出 Session ID,从 Redis 中取出用户信息,继续之前的业务操作**
* 应该注意 Session ID 的安全性问题,不能让它被恶意攻击者轻易获取,那么就不能产生一个容易被猜到的 Session ID 值.此外,还需要**经常重新生成 Session ID**.在对安全性要求极高的场景下,例如转账等操作,**除了使用 Session 管理用户状态之外,还需要对用户进行重新验证,比如重新输入密码,或者使用短信验证码等方式**

* **session和cookie的关系**

  * cookie只是实现session的其中一种方案.虽然是最常用的,但并不是唯一的方法.禁用cookie后还有其他方法存储,比如放在url中
  * 现在大多都是Session + Cookie,但是只用session不用cookie,或是只用cookie,不用session在理论上都可以保持会话状态.可是实际中因为多种原因,一般不会单独使用
  * 用session只需要在客户端保存一个id,**实际上大量数据都是保存在服务端**.如果全部用cookie,数据量大的时候客户端是没有那么多空间的.
  * 如果只用cookie不用session,**那么账户信息全部保存在客户端**,一旦被劫持,全部信息都会泄露.并且客户端数据量变大,网络传输的数据量也会变大


## token

* token 也称作令牌,其认证方式类似于**临时的证书签名**, 并且是一种**服务端无状态的认证方式**
* 组成
  * uid: 用户唯一身份标识
  * time: 当前时间的时间戳
  * sign: 签名, **使用 hash/encrypt 压缩成定长的十六进制字符串**,以防止第三方恶意拼接
  * 固定参数(可选): 将一些常用的固定参数加入到 token 中是为了避免重复查库
* 存放位置:**token在客户端一般存放于local Storage,cookie,或session Storage中**.**在服务器一般存于数据库中**
* token的认证过程(与cookie相似)
  * 用户登录,成功后服务器返回Token给客户端
  * 客户端收到数据后保存在客户端
  * 客户端再次访问服务器,将token放入headers中
  * 服务器端**采用filter过滤器校验**.校验成功则返回请求数据,校验失败则返回错误码
* **token可以抵抗csrf,cookie+session不行**
  * 假如用户正在登陆银行网页,同时登陆了攻击者的网页,并且银行网页未对csrf攻击进行防护.攻击者就可以在网页放一个表单,该表单提交src为`http://www.bank.com/api/transfer`,body为`count=1000&to=Tom`.倘若是session+cookie,用户打开网页的时候就已经转给Tom1000元了.**因为form 发起的 POST 请求并不受到浏览器同源策略的限制**,**因此可以任意地使用其他域的 Cookie 向其他域发送 POST 请求,形成 CSRF 攻击**.在post请求的瞬间,cookie会被浏览器自动添加到请求头中.**但token不同,token是开发者为了防范csrf而特别设计的令牌,浏览器不会自动添加到headers里,攻击者也无法访问用户的token,所以提交的表单无法通过服务器过滤,也就无法形成攻击**

* 分布式情况下的session和token

  * 我们已经知道session是有状态的,一般存于服务器内存或硬盘中,**当服务器采用分布式或集群时**,session就会面对负载均衡问题
    - **负载均衡多服务器的情况,不好确认当前用户是否登录,因为多服务器不共享session**.这个问题也可以将session存在一个服务器中来解决,但是就不能完全达到负载均衡的效果.当今的几种[解决session负载均衡](http://blog.51cto.com/zhibeiwang/1965018)的方法
  * 而token是无状态的,token字符串里就保存了所有的用户信息
    * 客户端登陆传递信息给服务端,服务端收到后把**用户信息加密(token)传给客户端**,客户端将token存放于local Storage等容器中.客户端每次访问都传递token,服务端解密token,就知道这个用户是谁了.**通过cpu加解密,服务端就不需要存储session占用存储空间,就很好的解决负载均衡多服务器的问题了**.这个方法叫做JWT(Json Web Token)

* 总结

  * session存储于服务器,可以理解为一个状态列表,拥有一个唯一识别符号session Id,**通常存放于cookie中**.**服务器收到cookie后解析出session Id,再去session列表中查找,才能找到相应session**.依赖cookie
  * **cookie类似一个令牌,装有session Id,存储在客户端,浏览器通常会自动添加**
  * **token也类似一个令牌,无状态,用户信息都被加密到token中,服务器收到token后解密就可知道是哪个用户**.需要开发者手动添加
  * jwt只是一个跨域认证的方案



#### 慢启动曲线
慢启动,先发一个,可以就发两个,两个可以发四个,如此下去,遇到sshread?那就线性,一个一个加,咦?拥塞了,丢包了?两种方案,快速重传或者将shhresh设为窗口的一半,然后又一个发,两个发,三个发,遇到sshresh的点,就一个一个发,这时就会看见网络卡顿.快速重传就将减半的sshresh+3,然后又一个一个发.
#### 三次握手的具体实现,time_wait原理?
#### tcp以什么保证可靠 
#### tcp数据校验是怎么做的

流量控制是怎么实现的?(滑动窗口)滑动窗口的大小具体是怎么变化的?

* 0.0.0.0是什么网络地址?

在网络编程中,IP地址`0.0.0.0`有特殊的含义,具体取决于上下文.

1. 在服务器编程中,如果一个服务器被告知监听`0.0.0.0`地址,那么它将在该机器的所有IP地址上监听传入的连接.这包括公共IP地址,私有IP地址,以及特殊的环回地址`127.0.0.1`.这样,无论客户端使用服务器的哪个IP地址来连接,服务器都可以接受连接.

2. 在路由表中,`0.0.0.0`通常用作默认路由的地址.这意味着,如果网络包的目标地址在路由表的其他条目中找不到匹配项,那么这个包将被发送到默认路由.

3. 在客户端编程中,`0.0.0.0`通常表示未指定的地址.例如,如果你告诉一个网络客户端连接到`0.0.0.0`,那么它通常会解释为"连接到本地主机".然而,这种行为并不总是一致的,因此通常不推荐这样做.